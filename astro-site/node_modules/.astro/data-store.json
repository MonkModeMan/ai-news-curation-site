[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.9.2","content-config-digest","c2211fbb8f6109dd","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://raisex-llc.github.io/ai-news-curation-site/\",\"compressHTML\":true,\"base\":\"/ai-news-curation-site/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"experimentalDefaultStyles\":true},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":\"prism\",\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"csp\":false},\"legacy\":{\"collections\":false}}","posts",["Map",11,12],"2025-06-20-active-test-time-vision-language-navigation-be7d43",{"id":11,"data":13,"body":23,"filePath":24,"digest":25,"rendered":26,"legacyId":36},{"title":14,"description":15,"pubDate":16,"source":17,"tags":18,"url":22},"Active Test-time Vision-Language Navigation","arXiv:2506.06630v1 Announce Type: cross \nAbstract: Vision-Language Navigation (VLN) policies trained on offline datasets often exhibit degraded task performance when deployed in unfamiliar navigation environments at test time, where agents are typically evaluated without access to external interaction or feedback. Entropy minimization has emerged as a practical solution for reducing prediction uncertainty at test time; however, it can suffer from accumulated errors, as agents may become overconfident in incorrect actions without sufficient contextual grounding. To tackle these challenges, we introduce ATENA (Active TEst-time Navigation Agent), a test-time active learning framework that enables a practical human-robot interaction via episodic feedback on uncertain navigation outcomes. In particular, ATENA learns to increase certainty in successful episodes and decrease it in failed ones, improving uncertainty calibration. Here, we propose mixture entropy optimization, where entropy is obtained from a combination of the action and pseudo-expert distributions-a hypothetical action distribution assuming the agent's selected action to be optimal-controlling both prediction confidence and action preference. In addition, we propose a self-active learning strategy that enables an agent to evaluate its navigation outcomes based on confident predictions. As a result, the agent stays actively engaged throughout all iterations, leading to well-grounded and adaptive decision-making. Extensive evaluations on challenging VLN benchmarks-REVERIE, R2R, and R2R-CE-demonstrate that ATENA successfully overcomes distributional shifts at test time, outperforming the compared baseline methods across various settings.",["Date","2025-06-20T04:00:00.000Z"],"arXiv AI",[19,20,21],"arxiv","ai","research","https://arxiv.org/abs/2506.06630","Computer Science > Robotics\r\n[Submitted on 7 Jun 2025]\r\nTitle:Active Test-time Vision-Language Navigation\r\nView PDF HTML (experimental)Abstract:Vision-Language Navigation (VLN) policies trained on offline datasets often exhibit degraded task performance when deployed in unfamiliar navigation environments at test time, where agents are typically evaluated without access to external interaction or feedback. Entropy minimization has emerged as a practical solution for reducing prediction uncertainty at test time; however, it can suffer from accumulated errors, as agents may become overconfident in incorrect actions without sufficient contextual grounding. To tackle these challenges, we introduce ATENA (Active TEst-time Navigation Agent), a test-time active learning framework that enables a practical human-robot interaction via episodic feedback on uncertain navigation outcomes. In particular, ATENA learns to increase certainty in successful episodes and decrease it in failed ones, improving uncertainty calibration. Here, we propose mixture entropy optimization, where entropy is obtained from a combination of the action and pseudo-expert distributions-a hypothetical action distribution assuming the agent's selected action to be optimal-controlling both prediction confidence and action preference. In addition, we propose a self-active learning strategy that enables an agent to evaluate its navigation outcomes based on confident predictions. As a result, the agent stays actively engaged throughout all iterations, leading to well-grounded and adaptive decision-making. Extensive evaluations on challenging VLN benchmarks-REVERIE, R2R, and R2R-CE-demonstrate that ATENA successfully overcomes distributional shifts at test time, outperforming the compared baseline methods across various settings.\r\nReferences & Citations\r\nBibliographic and Citation Tools\r\nBibliographic Explorer (What is the Explorer?)\r\nConnected Papers (What is Connected Papers?)\r\nLitmaps (What is Litmaps?)\r\nscite Smart Citations (What are Smart Citations?)\r\nCode, Data and Media Associated with this Article\r\nalphaXiv (What is alphaXiv?)\r\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\r\nDagsHub (What is DagsHub?)\r\nGotit.pub (What is GotitPub?)\r\nHugging Face (What is Huggingface?)\r\nPapers with Code (What is Papers with Code?)\r\nScienceCast (What is ScienceCast?)\r\nDemos\r\nRecommenders and Search Tools\r\nInfluence Flower (What are Influence Flowers?)\r\nCORE Recommender (What is CORE?)\r\narXivLabs: experimental projects with community collaborators\r\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\r\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\r\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.","src/content/posts/2025-06-20-active-test-time-vision-language-navigation-be7d43.md","b7876f32403c63c0",{"html":27,"metadata":28},"\u003Cp>Computer Science > Robotics\r\n[Submitted on 7 Jun 2025]\r\nTitle:Active Test-time Vision-Language Navigation\r\nView PDF HTML (experimental)Abstract:Vision-Language Navigation (VLN) policies trained on offline datasets often exhibit degraded task performance when deployed in unfamiliar navigation environments at test time, where agents are typically evaluated without access to external interaction or feedback. Entropy minimization has emerged as a practical solution for reducing prediction uncertainty at test time; however, it can suffer from accumulated errors, as agents may become overconfident in incorrect actions without sufficient contextual grounding. To tackle these challenges, we introduce ATENA (Active TEst-time Navigation Agent), a test-time active learning framework that enables a practical human-robot interaction via episodic feedback on uncertain navigation outcomes. In particular, ATENA learns to increase certainty in successful episodes and decrease it in failed ones, improving uncertainty calibration. Here, we propose mixture entropy optimization, where entropy is obtained from a combination of the action and pseudo-expert distributions-a hypothetical action distribution assuming the agent’s selected action to be optimal-controlling both prediction confidence and action preference. In addition, we propose a self-active learning strategy that enables an agent to evaluate its navigation outcomes based on confident predictions. As a result, the agent stays actively engaged throughout all iterations, leading to well-grounded and adaptive decision-making. Extensive evaluations on challenging VLN benchmarks-REVERIE, R2R, and R2R-CE-demonstrate that ATENA successfully overcomes distributional shifts at test time, outperforming the compared baseline methods across various settings.\r\nReferences &#x26; Citations\r\nBibliographic and Citation Tools\r\nBibliographic Explorer (What is the Explorer?)\r\nConnected Papers (What is Connected Papers?)\r\nLitmaps (What is Litmaps?)\r\nscite Smart Citations (What are Smart Citations?)\r\nCode, Data and Media Associated with this Article\r\nalphaXiv (What is alphaXiv?)\r\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\r\nDagsHub (What is DagsHub?)\r\nGotit.pub (What is GotitPub?)\r\nHugging Face (What is Huggingface?)\r\nPapers with Code (What is Papers with Code?)\r\nScienceCast (What is ScienceCast?)\r\nDemos\r\nRecommenders and Search Tools\r\nInfluence Flower (What are Influence Flowers?)\r\nCORE Recommender (What is CORE?)\r\narXivLabs: experimental projects with community collaborators\r\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\r\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\r\nHave an idea for a project that will add value for arXiv’s community? Learn more about arXivLabs.\u003C/p>",{"headings":29,"localImagePaths":30,"remoteImagePaths":31,"frontmatter":32,"imagePaths":35},[],[],[],{"title":14,"description":15,"pubDate":33,"source":17,"tags":34,"url":22},"Fri, 20 Jun 2025 00:00:00 -0400",[19,20,21],[],"2025-06-20-active-test-time-vision-language-navigation-be7d43.md"]