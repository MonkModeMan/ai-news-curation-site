---
title: 'PhysNav-DG: A Novel Adaptive Framework for Robust VLM-Sensor Fusion in Navigation
  Applications'
description: "arXiv:2505.01881v3 Announce Type: replace-cross \nAbstract: Robust navigation\
  \ in diverse environments and domains requires both accurate state estimation and\
  \ transparent decision making. We present PhysNav-DG, a novel framework that integrates\
  \ classical sensor fusion with the semantic power of vision-language models. Our\
  \ dual-branch architecture predicts navigation actions from multi-sensor inputs\
  \ while simultaneously generating detailed chain-of-thought explanations. A modified\
  \ Adaptive Kalman Filter dynamically adjusts its noise parameters based on environmental\
  \ context. It leverages several streams of raw sensor data along with semantic insights\
  \ from models such as LLaMA 3.2 11B and BLIP-2. To evaluate our approach, we introduce\
  \ the MD-NEX Benchmark, a novel multi-domain dataset that unifies indoor navigation,\
  \ autonomous driving, and social navigation tasks with ground-truth actions and\
  \ human-validated explanations. Extensive experiments and ablations show that PhysNav-DG\
  \ improves navigation success rates by over 20% and achieves high efficiency, with\
  \ explanations that are both highly grounded and clear. This work connects high-level\
  \ semantic reasoning and geometric planning for safer and more trustworthy autonomous\
  \ systems."
pubDate: Mon, 16 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2505.01881
---

Computer Science > Computer Vision and Pattern Recognition
[Submitted on 3 May 2025 (v1), last revised 13 Jun 2025 (this version, v3)]
Title:PhysNav-DG: A Novel Adaptive Framework for Robust VLM-Sensor Fusion in Navigation Applications
View PDF HTML (experimental)Abstract:Robust navigation in diverse environments and domains requires both accurate state estimation and transparent decision making. We present PhysNav-DG, a novel framework that integrates classical sensor fusion with the semantic power of vision-language models. Our dual-branch architecture predicts navigation actions from multi-sensor inputs while simultaneously generating detailed chain-of-thought explanations. A modified Adaptive Kalman Filter dynamically adjusts its noise parameters based on environmental context. It leverages several streams of raw sensor data along with semantic insights from models such as LLaMA 3.2 11B and BLIP-2. To evaluate our approach, we introduce the MD-NEX Benchmark, a novel multi-domain dataset that unifies indoor navigation, autonomous driving, and social navigation tasks with ground-truth actions and human-validated explanations. Extensive experiments and ablations show that PhysNav-DG improves navigation success rates by over 20% and achieves high efficiency, with explanations that are both highly grounded and clear. This work connects high-level semantic reasoning and geometric planning for safer and more trustworthy autonomous systems.
Submission history
From: Trisanth Srinivasan [view email][v1] Sat, 3 May 2025 17:59:26 UTC (351 KB)
[v2] Thu, 12 Jun 2025 05:18:24 UTC (351 KB)
[v3] Fri, 13 Jun 2025 03:36:19 UTC (351 KB)
Current browse context:
cs.CV
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.