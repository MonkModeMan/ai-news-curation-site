---
title: "MOST: MR reconstruction Optimization for multiple downStream Tasks via continual learning"
description: "arXiv:2409.10394v3 Announce Type: replace-cross Abstract: Deep learning-based Magnetic Resonance (MR) reconstruction methods have focused on generating high-quality images but often overlook the impact on downstream tasks (e.g., segmentation) that utilize the reconstructed images. Cascading separately trained reconstruction network and downstream task network has been shown to introduce performance degradation due to error propagation and domain gaps between training datasets. To mitigate this issue, downstream task-oriented reconstruction optimization has been proposed for a single downstream task. Expanding this optimization to multi-task scenarios is not straightforward. In this work, we extended this optimization to sequentially introduced multiple downstream tasks and demonstrated that a single MR reconstruction network can be optimized for multiple downstream tasks by deploying continual learning (MOST). MOST integrated techniques from replay-based continual learning and image-guided loss to overcome catastrophic forgetting. Comparative experiments demonstrated that MOST outperformed a reconstruction network without finetuning, a reconstruction network with na'ive finetuning, and conventional continual learning methods. The source code is available at: https://github.com/SNU-LIST/MOST."
summary: "arXiv:2409.10394v3 Announce Type: replace-cross Abstract: Deep learning-based Magnetic Resonance (MR) reconstruction methods have focused on generating high-quality images but often overlook the impact on downstream tasks (e.g., segmentation) that utilize the reconstructed images. Cascading separately trained reconstruction network and downstream task network has been shown to introduce performance degradation due to error propagation and domain gaps between training datasets. To mitigate this issue, downstream task-oriented reconstruction optimization has been proposed for a single downstream task. Expanding this optimization to multi-task scenarios is not straightforward. In this work, we extended this optimization to sequentially introduced multiple downstream tasks and demonstrated that a single MR reconstruction network can be optimized for multiple downstream tasks by deploying continual learning (MOST). MOST integrated techniques from replay-based continual learning and image-guided loss to overcome catastrophic forgetting. Comparative experiments demonstrated that MOST outperformed a reconstruction network without finetuning, a reconstruction network with na'ive finetuning, and conventional continual learning methods. The source code is available at: https://github.com/SNU-LIST/MOST."
pubDate: "Wed, 25 Jun 2025 00:00:00 -0400"
source: "arXiv AI"
url: "https://arxiv.org/abs/2409.10394"
thumbnail: "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
---

