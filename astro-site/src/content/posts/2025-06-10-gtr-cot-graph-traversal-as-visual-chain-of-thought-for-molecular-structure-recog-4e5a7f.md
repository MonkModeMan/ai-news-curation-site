---
title: 'GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure
  Recognition'
description: "arXiv:2506.07553v1 Announce Type: new \nAbstract: Optical Chemical Structure\
  \ Recognition (OCSR) is crucial for digitizing chemical knowledge by converting\
  \ molecular images into machine-readable formats. While recent vision-language models\
  \ (VLMs) have shown potential in this task, their image-captioning approach often\
  \ struggles with complex molecular structures and inconsistent annotations. To overcome\
  \ these challenges, we introduce GTR-Mol-VLM, a novel framework featuring two key\
  \ innovations: (1) the \\textit{Graph Traversal as Visual Chain of Thought} mechanism\
  \ that emulates human reasoning by incrementally parsing molecular graphs through\
  \ sequential atom-bond predictions, and (2) the data-centric principle of \\textit{Faithfully\
  \ Recognize What You've Seen}, which addresses the mismatch between abbreviated\
  \ structures in images and their expanded annotations. To support model development,\
  \ we constructed GTR-CoT-1.3M, a large-scale instruction-tuning dataset with meticulously\
  \ corrected annotations, and introduced MolRec-Bench, the first benchmark designed\
  \ for a fine-grained evaluation of graph-parsing accuracy in OCSR. Comprehensive\
  \ experiments demonstrate that GTR-Mol-VLM achieves superior results compared to\
  \ specialist models, chemistry-domain VLMs, and commercial general-purpose VLMs.\
  \ Notably, in scenarios involving molecular images with functional group abbreviations,\
  \ GTR-Mol-VLM outperforms the second-best baseline by approximately 14 percentage\
  \ points, both in SMILES-based and graph-based metrics. We hope that this work will\
  \ drive OCSR technology to more effectively meet real-world needs, thereby advancing\
  \ the fields of cheminformatics and AI for Science. We will release GTR-CoT at https://github.com/opendatalab/GTR-CoT."
pubDate: Tue, 10 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.07553
---

Computer Science > Artificial Intelligence
[Submitted on 9 Jun 2025]
Title:GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition
View PDF HTML (experimental)Abstract:Optical Chemical Structure Recognition (OCSR) is crucial for digitizing chemical knowledge by converting molecular images into machine-readable formats. While recent vision-language models (VLMs) have shown potential in this task, their image-captioning approach often struggles with complex molecular structures and inconsistent annotations. To overcome these challenges, we introduce GTR-Mol-VLM, a novel framework featuring two key innovations: (1) the \textit{Graph Traversal as Visual Chain of Thought} mechanism that emulates human reasoning by incrementally parsing molecular graphs through sequential atom-bond predictions, and (2) the data-centric principle of \textit{Faithfully Recognize What You've Seen}, which addresses the mismatch between abbreviated structures in images and their expanded annotations. To support model development, we constructed GTR-CoT-1.3M, a large-scale instruction-tuning dataset with meticulously corrected annotations, and introduced MolRec-Bench, the first benchmark designed for a fine-grained evaluation of graph-parsing accuracy in OCSR. Comprehensive experiments demonstrate that GTR-Mol-VLM achieves superior results compared to specialist models, chemistry-domain VLMs, and commercial general-purpose VLMs. Notably, in scenarios involving molecular images with functional group abbreviations, GTR-Mol-VLM outperforms the second-best baseline by approximately 14 percentage points, both in SMILES-based and graph-based metrics. We hope that this work will drive OCSR technology to more effectively meet real-world needs, thereby advancing the fields of cheminformatics and AI for Science. We will release GTR-CoT at this https URL.
Current browse context:
cs.AI
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.