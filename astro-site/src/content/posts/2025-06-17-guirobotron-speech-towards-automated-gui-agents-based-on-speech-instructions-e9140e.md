---
title: 'GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions'
description: "arXiv:2506.11127v1 Announce Type: cross \nAbstract: Autonomous agents\
  \ for Graphical User Interfaces (GUIs) are revolutionizing human-computer interaction,\
  \ yet their reliance on text-based instructions imposes limitations on accessibility\
  \ and convenience, particularly in hands-free scenarios. To address this gap, we\
  \ propose GUIRoboTron-Speech, the first end-to-end autonomous GUI agent that directly\
  \ accepts speech instructions and on-device screenshots to predict actions. Confronted\
  \ with the scarcity of speech-based GUI agent datasets, we initially generated high-quality\
  \ speech instructions for training by leveraging a random timbre text-to-speech\
  \ (TTS) model to convert existing text instructions. We then develop GUIRoboTron-Speech's\
  \ capabilities through progressive grounding and planning training stages. A key\
  \ contribution is a heuristic mixed-instruction training strategy designed to mitigate\
  \ the modality imbalance inherent in pre-trained foundation models. Comprehensive\
  \ experiments on several benchmark datasets validate the robust and superior performance\
  \ of GUIRoboTron-Speech, demonstrating the significant potential and widespread\
  \ applicability of speech as an effective instruction modality for driving GUI agents.\
  \ Our code and datasets are available at https://github.com/GUIRoboTron/GUIRoboTron-Speech."
pubDate: Mon, 16 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.11127
---

Computer Science > Computation and Language
[Submitted on 10 Jun 2025]
Title:GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions
View PDF HTML (experimental)Abstract:Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing human-computer interaction, yet their reliance on text-based instructions imposes limitations on accessibility and convenience, particularly in hands-free scenarios. To address this gap, we propose GUIRoboTron-Speech, the first end-to-end autonomous GUI agent that directly accepts speech instructions and on-device screenshots to predict actions. Confronted with the scarcity of speech-based GUI agent datasets, we initially generated high-quality speech instructions for training by leveraging a random timbre text-to-speech (TTS) model to convert existing text instructions. We then develop GUIRoboTron-Speech's capabilities through progressive grounding and planning training stages. A key contribution is a heuristic mixed-instruction training strategy designed to mitigate the modality imbalance inherent in pre-trained foundation models. Comprehensive experiments on several benchmark datasets validate the robust and superior performance of GUIRoboTron-Speech, demonstrating the significant potential and widespread applicability of speech as an effective instruction modality for driving GUI agents. Our code and datasets are available at this https URL.
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.