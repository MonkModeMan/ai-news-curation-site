---
title: Solving Inequality Proofs with Large Language Models
description: "arXiv:2506.07927v1 Announce Type: new \nAbstract: Inequality proving,\
  \ crucial across diverse scientific and mathematical fields, tests advanced reasoning\
  \ skills such as discovering tight bounds and strategic theorem application. This\
  \ makes it a distinct, demanding frontier for large language models (LLMs), offering\
  \ insights beyond general mathematical problem-solving. Progress in this area is\
  \ hampered by existing datasets that are often scarce, synthetic, or rigidly formal.\
  \ We address this by proposing an informal yet verifiable task formulation, recasting\
  \ inequality proving into two automatically checkable subtasks: bound estimation\
  \ and relation prediction. Building on this, we release IneqMath, an expert-curated\
  \ dataset of Olympiad-level inequalities, including a test set and training corpus\
  \ enriched with step-wise solutions and theorem annotations. We also develop a novel\
  \ LLM-as-judge evaluation framework, combining a final-answer judge with four step-wise\
  \ judges designed to detect common reasoning flaws. A systematic evaluation of 29\
  \ leading LLMs on IneqMath reveals a surprising reality: even top models like o1\
  \ achieve less than 10% overall accuracy under step-wise scrutiny; this is a drop\
  \ of up to 65.5% from their accuracy considering only final answer equivalence.\
  \ This discrepancy exposes fragile deductive chains and a critical gap for current\
  \ LLMs between merely finding an answer and constructing a rigorous proof. Scaling\
  \ model size and increasing test-time computation yield limited gains in overall\
  \ proof correctness. Instead, our findings highlight promising research directions\
  \ such as theorem-guided reasoning and self-refinement. Code and data are available\
  \ at https://ineqmath.github.io/."
pubDate: Tue, 10 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.07927
---

Computer Science > Artificial Intelligence
[Submitted on 9 Jun 2025]
Title:Solving Inequality Proofs with Large Language Models
View PDF HTML (experimental)Abstract:Inequality proving, crucial across diverse scientific and mathematical fields, tests advanced reasoning skills such as discovering tight bounds and strategic theorem application. This makes it a distinct, demanding frontier for large language models (LLMs), offering insights beyond general mathematical problem-solving. Progress in this area is hampered by existing datasets that are often scarce, synthetic, or rigidly formal. We address this by proposing an informal yet verifiable task formulation, recasting inequality proving into two automatically checkable subtasks: bound estimation and relation prediction. Building on this, we release IneqMath, an expert-curated dataset of Olympiad-level inequalities, including a test set and training corpus enriched with step-wise solutions and theorem annotations. We also develop a novel LLM-as-judge evaluation framework, combining a final-answer judge with four step-wise judges designed to detect common reasoning flaws. A systematic evaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even top models like o1 achieve less than 10% overall accuracy under step-wise scrutiny; this is a drop of up to 65.5% from their accuracy considering only final answer equivalence. This discrepancy exposes fragile deductive chains and a critical gap for current LLMs between merely finding an answer and constructing a rigorous proof. Scaling model size and increasing test-time computation yield limited gains in overall proof correctness. Instead, our findings highlight promising research directions such as theorem-guided reasoning and self-refinement. Code and data are available at this https URL.
Current browse context:
cs.AI
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.