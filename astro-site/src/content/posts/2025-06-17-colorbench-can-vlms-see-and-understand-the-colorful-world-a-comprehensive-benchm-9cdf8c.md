---
title: 'ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive
  Benchmark for Color Perception, Reasoning, and Robustness'
description: "arXiv:2504.10514v2 Announce Type: replace-cross \nAbstract: Color plays\
  \ an important role in human perception and usually provides critical clues in visual\
  \ reasoning. However, it is unclear whether and how vision-language models (VLMs)\
  \ can perceive, understand, and leverage color as humans. This paper introduces\
  \ ColorBench, an innovative benchmark meticulously crafted to assess the capabilities\
  \ of VLMs in color understanding, including color perception, reasoning, and robustness.\
  \ By curating a suite of diverse test scenarios, with grounding in real applications,\
  \ ColorBench evaluates how these models perceive colors, infer meanings from color-based\
  \ cues, and maintain consistent performance under varying color transformations.\
  \ Through an extensive evaluation of 32 VLMs with varying language models and vision\
  \ encoders, our paper reveals some undiscovered findings: (i) The scaling law (larger\
  \ models are better) still holds on ColorBench, while the language model plays a\
  \ more important role than the vision encoder. (ii) However, the performance gaps\
  \ across models are relatively small, indicating that color understanding has been\
  \ largely neglected by existing VLMs. (iii) CoT reasoning improves color understanding\
  \ accuracies and robustness, though they are vision-centric tasks. (iv) Color clues\
  \ are indeed leveraged by VLMs on ColorBench but they can also mislead models in\
  \ some tasks. These findings highlight the critical limitations of current VLMs\
  \ and underscore the need to enhance color comprehension. Our ColorBenchcan serve\
  \ as a foundational tool for advancing the study of human-level color understanding\
  \ of multimodal AI."
pubDate: Mon, 16 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2504.10514
---

Computer Science > Computer Vision and Pattern Recognition
[Submitted on 10 Apr 2025 (v1), last revised 12 Jun 2025 (this version, v2)]
Title:ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness
View PDF HTML (experimental)Abstract:Color plays an important role in human perception and usually provides critical clues in visual reasoning. However, it is unclear whether and how vision-language models (VLMs) can perceive, understand, and leverage color as humans. This paper introduces ColorBench, an innovative benchmark meticulously crafted to assess the capabilities of VLMs in color understanding, including color perception, reasoning, and robustness. By curating a suite of diverse test scenarios, with grounding in real applications, ColorBench evaluates how these models perceive colors, infer meanings from color-based cues, and maintain consistent performance under varying color transformations. Through an extensive evaluation of 32 VLMs with varying language models and vision encoders, our paper reveals some undiscovered findings: (i) The scaling law (larger models are better) still holds on ColorBench, while the language model plays a more important role than the vision encoder. (ii) However, the performance gaps across models are relatively small, indicating that color understanding has been largely neglected by existing VLMs. (iii) CoT reasoning improves color understanding accuracies and robustness, though they are vision-centric tasks. (iv) Color clues are indeed leveraged by VLMs on ColorBench but they can also mislead models in some tasks. These findings highlight the critical limitations of current VLMs and underscore the need to enhance color comprehension. Our ColorBenchcan serve as a foundational tool for advancing the study of human-level color understanding of multimodal AI.
Submission history
From: Yijun Liang [view email][v1] Thu, 10 Apr 2025 16:36:26 UTC (39,371 KB)
[v2] Thu, 12 Jun 2025 20:35:42 UTC (18,137 KB)
Current browse context:
cs.CV
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.