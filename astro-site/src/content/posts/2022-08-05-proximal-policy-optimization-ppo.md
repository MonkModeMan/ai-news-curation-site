---
title: "Proximal Policy Optimization (PPO)"
description: ""
summary: ""
pubDate: "Fri, 05 Aug 2022 00:00:00 GMT"
source: "Hugging Face Blog"
url: "https://huggingface.co/blog/deep-rl-ppo"
thumbnail: "https://huggingface.co/blog/assets/93_deep_rl_ppo/thumbnail.png"
---

