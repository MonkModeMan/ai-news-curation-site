---
title: LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making
  in Dynamically Changing Environments
description: "arXiv:2506.07223v1 Announce Type: new \nAbstract: In the realm of embodied\
  \ intelligence, the evolution of large language models (LLMs) has markedly enhanced\
  \ agent decision making. Consequently, researchers have begun exploring agent performance\
  \ in dynamically changing high-risk scenarios, i.e., fire, flood, and wind scenarios\
  \ in the HAZARD benchmark. Under these extreme conditions, the delay in decision\
  \ making emerges as a crucial yet insufficiently studied issue. We propose a Time\
  \ Conversion Mechanism (TCM) that translates inference delays in decision-making\
  \ into equivalent simulation frames, thus aligning cognitive and physical costs\
  \ under a single FPS-based metric. By extending HAZARD with Respond Latency (RL)\
  \ and Latency-to-Action Ratio (LAR), we deliver a fully latency-aware evaluation\
  \ protocol. Moreover, we present the Rapid-Reflex Async-Reflect Agent (RRARA), which\
  \ couples a lightweight LLM-guided feedback module with a rule-based agent to enable\
  \ immediate reactive behaviors and asynchronous reflective refinements in situ.\
  \ Experiments on HAZARD show that RRARA substantially outperforms existing baselines\
  \ in latency-sensitive scenarios."
pubDate: Tue, 10 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.07223
---

Computer Science > Artificial Intelligence
[Submitted on 8 Jun 2025]
Title:LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments
View PDF HTML (experimental)Abstract:In the realm of embodied intelligence, the evolution of large language models (LLMs) has markedly enhanced agent decision making. Consequently, researchers have begun exploring agent performance in dynamically changing high-risk scenarios, i.e., fire, flood, and wind scenarios in the HAZARD benchmark. Under these extreme conditions, the delay in decision making emerges as a crucial yet insufficiently studied issue. We propose a Time Conversion Mechanism (TCM) that translates inference delays in decision-making into equivalent simulation frames, thus aligning cognitive and physical costs under a single FPS-based metric. By extending HAZARD with Respond Latency (RL) and Latency-to-Action Ratio (LAR), we deliver a fully latency-aware evaluation protocol. Moreover, we present the Rapid-Reflex Async-Reflect Agent (RRARA), which couples a lightweight LLM-guided feedback module with a rule-based agent to enable immediate reactive behaviors and asynchronous reflective refinements in situ. Experiments on HAZARD show that RRARA substantially outperforms existing baselines in latency-sensitive scenarios.
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.