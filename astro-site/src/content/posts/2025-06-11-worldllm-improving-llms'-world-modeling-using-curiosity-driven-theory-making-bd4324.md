---
title: 'WorldLLM: Improving LLMs'' world modeling using curiosity-driven theory-making'
description: "arXiv:2506.06725v1 Announce Type: new \nAbstract: Large Language Models\
  \ (LLMs) possess general world knowledge but often struggle to generate precise\
  \ predictions in structured, domain-specific contexts such as simulations. These\
  \ limitations arise from their inability to ground their broad, unstructured understanding\
  \ in specific environments. To address this, we present WorldLLM, a framework that\
  \ enhances LLM-based world modeling by combining Bayesian inference and autonomous\
  \ active exploration with reinforcement learning. WorldLLM leverages the in-context\
  \ learning abilities of LLMs to guide an LLM-based world model's predictions using\
  \ natural language hypotheses given in its prompt. These hypotheses are iteratively\
  \ refined through a Bayesian inference framework that leverages a second LLM as\
  \ the proposal distribution given collected evidence. This evidence is collected\
  \ using a curiosity-driven reinforcement learning policy that explores the environment\
  \ to find transitions with a low log-likelihood under our LLM-based predictive model\
  \ using the current hypotheses. By alternating between refining hypotheses and collecting\
  \ new evidence, our framework autonomously drives continual improvement of the predictions.\
  \ Our experiments demonstrate the effectiveness of WorldLLM in a textual game environment\
  \ that requires agents to manipulate and combine objects. The framework not only\
  \ enhances predictive accuracy, but also generates human-interpretable theories\
  \ of environment dynamics."
pubDate: Tue, 10 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.06725
---

Computer Science > Artificial Intelligence
[Submitted on 7 Jun 2025]
Title:WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making
View PDF HTML (experimental)Abstract:Large Language Models (LLMs) possess general world knowledge but often struggle to generate precise predictions in structured, domain-specific contexts such as simulations. These limitations arise from their inability to ground their broad, unstructured understanding in specific environments. To address this, we present WorldLLM, a framework that enhances LLM-based world modeling by combining Bayesian inference and autonomous active exploration with reinforcement learning. WorldLLM leverages the in-context learning abilities of LLMs to guide an LLM-based world model's predictions using natural language hypotheses given in its prompt. These hypotheses are iteratively refined through a Bayesian inference framework that leverages a second LLM as the proposal distribution given collected evidence. This evidence is collected using a curiosity-driven reinforcement learning policy that explores the environment to find transitions with a low log-likelihood under our LLM-based predictive model using the current hypotheses. By alternating between refining hypotheses and collecting new evidence, our framework autonomously drives continual improvement of the predictions. Our experiments demonstrate the effectiveness of WorldLLM in a textual game environment that requires agents to manipulate and combine objects. The framework not only enhances predictive accuracy, but also generates human-interpretable theories of environment dynamics.
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.