---
title: NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture
  Experimental Variability in Biological Neuron Models
description: "arXiv:2506.04536v2 Announce Type: replace-cross \nAbstract: Characterizing\
  \ the diverse computational properties of human neurons via multimodal electrophysiological,\
  \ transcriptomic, and morphological data provides the foundation for constructing\
  \ and validating bio-realistic neuron models that can advance our understanding\
  \ of fundamental mechanisms underlying brain function. However, current modeling\
  \ approaches remain constrained by the limited availability and intrinsic variability\
  \ of experimental neuronal data. To capture variability, ensembles of deterministic\
  \ models are often used, but are difficult to scale as model generation requires\
  \ repeating computationally expensive optimization for each neuron. While deep learning\
  \ is becoming increasingly relevant in this space, it fails to capture the full\
  \ biophysical complexity of neurons, their nonlinear voltage dynamics, and variability.\
  \ To address these shortcomings, we introduce NOBLE, a neural operator framework\
  \ that learns a mapping from a continuous frequency-modulated embedding of interpretable\
  \ neuron features to the somatic voltage response induced by current injection.\
  \ Trained on data generated from biophysically realistic neuron models, NOBLE predicts\
  \ distributions of neural dynamics accounting for the intrinsic experimental variability.\
  \ Unlike conventional bio-realistic neuron models, interpolating within the embedding\
  \ space offers models whose dynamics are consistent with experimentally observed\
  \ responses. NOBLE is the first scaled-up deep learning framework validated on real\
  \ experimental data, enabling efficient generation of synthetic neurons that exhibit\
  \ trial-to-trial variability and achieve a $4200\\times$ speedup over numerical\
  \ solvers. To this end, NOBLE captures fundamental neural properties, opening the\
  \ door to a better understanding of cellular composition and computations, neuromorphic\
  \ architectures, large-scale brain circuits, and general neuroAI applications."
pubDate: Mon, 16 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.04536
---

Computer Science > Machine Learning
[Submitted on 5 Jun 2025 (v1), last revised 12 Jun 2025 (this version, v2)]
Title:NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models
View PDF HTML (experimental)Abstract:Characterizing the diverse computational properties of human neurons via multimodal electrophysiological, transcriptomic, and morphological data provides the foundation for constructing and validating bio-realistic neuron models that can advance our understanding of fundamental mechanisms underlying brain function. However, current modeling approaches remain constrained by the limited availability and intrinsic variability of experimental neuronal data. To capture variability, ensembles of deterministic models are often used, but are difficult to scale as model generation requires repeating computationally expensive optimization for each neuron. While deep learning is becoming increasingly relevant in this space, it fails to capture the full biophysical complexity of neurons, their nonlinear voltage dynamics, and variability. To address these shortcomings, we introduce NOBLE, a neural operator framework that learns a mapping from a continuous frequency-modulated embedding of interpretable neuron features to the somatic voltage response induced by current injection. Trained on data generated from biophysically realistic neuron models, NOBLE predicts distributions of neural dynamics accounting for the intrinsic experimental variability. Unlike conventional bio-realistic neuron models, interpolating within the embedding space offers models whose dynamics are consistent with experimentally observed responses. NOBLE is the first scaled-up deep learning framework validated on real experimental data, enabling efficient generation of synthetic neurons that exhibit trial-to-trial variability and achieve a $4200\times$ speedup over numerical solvers. To this end, NOBLE captures fundamental neural properties, opening the door to a better understanding of cellular composition and computations, neuromorphic architectures, large-scale brain circuits, and general neuroAI applications.
Submission history
From: Luca Ghafourpour [view email][v1] Thu, 5 Jun 2025 01:01:18 UTC (5,299 KB)
[v2] Thu, 12 Jun 2025 22:50:25 UTC (5,298 KB)
Current browse context:
cs.LG
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
IArxiv Recommender
(What is IArxiv?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.