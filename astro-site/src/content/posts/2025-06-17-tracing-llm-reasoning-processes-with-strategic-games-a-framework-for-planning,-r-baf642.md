---
title: 'Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning,
  Revision, and Resource-Constrained Decision Making'
description: "arXiv:2506.12012v1 Announce Type: new \nAbstract: Large language models\
  \ (LLMs) are increasingly used for tasks that require complex reasoning. Most benchmarks\
  \ focus on final outcomes but overlook the intermediate reasoning steps - such as\
  \ planning, revision, and decision making under resource constraints. We argue that\
  \ measuring these internal processes is essential for understanding model behavior\
  \ and improving reliability. We propose using strategic games as a natural evaluation\
  \ environment: closed, rule-based systems with clear states, limited resources,\
  \ and automatic feedback. We introduce a framework that evaluates LLMs along three\
  \ core dimensions: planning, revision, and resource-constrained decision making.\
  \ To operationalize this, we define metrics beyond win rate, including overcorrection\
  \ risk rate, correction success rate, improvement slope, and over-budget ratio.\
  \ In 4320 adversarial rounds across 12 leading models, ChatGPT-o3-mini achieves\
  \ the top composite score, with a win rate of 74.7 percent, a correction success\
  \ rate of 78.6 percent, and an improvement slope of 0.041. By contrast, Qwen-Plus,\
  \ despite an overcorrection risk rate of 81.6 percent, wins only 25.6 percent of\
  \ its matches - primarily due to excessive resource use. We also observe a negative\
  \ correlation between overcorrection risk rate and correction success rate (Pearson\
  \ r = -0.51, p = 0.093), suggesting that more frequent edits do not always improve\
  \ outcomes. Our findings highlight the value of assessing not only what LLMs decide\
  \ but how they arrive at those decisions"
pubDate: Mon, 16 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.12012
---

Computer Science > Artificial Intelligence
[Submitted on 13 Jun 2025]
Title:Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making
View PDF HTML (experimental)Abstract:Large language models (LLMs) are increasingly used for tasks that require complex reasoning. Most benchmarks focus on final outcomes but overlook the intermediate reasoning steps - such as planning, revision, and decision making under resource constraints. We argue that measuring these internal processes is essential for understanding model behavior and improving reliability. We propose using strategic games as a natural evaluation environment: closed, rule-based systems with clear states, limited resources, and automatic feedback. We introduce a framework that evaluates LLMs along three core dimensions: planning, revision, and resource-constrained decision making. To operationalize this, we define metrics beyond win rate, including overcorrection risk rate, correction success rate, improvement slope, and over-budget ratio. In 4320 adversarial rounds across 12 leading models, ChatGPT-o3-mini achieves the top composite score, with a win rate of 74.7 percent, a correction success rate of 78.6 percent, and an improvement slope of 0.041. By contrast, Qwen-Plus, despite an overcorrection risk rate of 81.6 percent, wins only 25.6 percent of its matches - primarily due to excessive resource use. We also observe a negative correlation between overcorrection risk rate and correction success rate (Pearson r = -0.51, p = 0.093), suggesting that more frequent edits do not always improve outcomes. Our findings highlight the value of assessing not only what LLMs decide but how they arrive at those decisions
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.