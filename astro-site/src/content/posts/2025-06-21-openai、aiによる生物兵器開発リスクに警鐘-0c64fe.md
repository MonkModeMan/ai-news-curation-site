---
title: OpenAI、AIによる生物兵器開発リスクに警鐘
description: OpenAIは、AIが悪用され生物兵器開発につながる深刻なリスクがあると警告した。同社の将来のAIモデルは専門知識のない人物による生物学的脅威の作成を可能にする恐れがあるという。有害リクエストの拒否や専門家との連携、疑わしい行為の監視などの多角的な対策を講じ、社会全体の防御力向上も提唱している。
summary: OpenAIは、AIが悪用され生物兵器開発につながる深刻なリスクがあると警告した。同社の将来のAIモデルは専門知識のない人物による生物学的脅威の作成を可能にする恐れがあるという。有害リクエストの拒否や専門家との連携、疑わしい行為の監視などの
pubDate: Fri, 20 Jun 2025 07:04:00 +0900
source: ITmedia AI
tags:
- japan
- itmedia
- ai
url: https://www.itmedia.co.jp/aiplus/articles/2506/20/news054.html
---

米OpenAIは6月19日（現地時間）、AIモデルの進化が生物学分野に多大な恩恵をもたらす一方で、デュアルユース（軍民両用）の深刻なリスク、特に生物兵器への悪用の可能性があると警告した。
同社の将来のAIモデルは、専門知識の少ない人でも生物学的脅威を作成できるレベルの実質的な支援を提供できてしまうと予測している。
この脅威に対し、OpenAIは多角的な対策を講じているという。
まず、政府機関や専門家と連携し、脅威モデルを形成する。生物学の専門家による評価データの作成・検証や、専門家による徹底的なレッドチーミング（攻撃シミュレーション）を実施している。
また、生物兵器化を可能にするものなどの有害なリクエストは拒否し、デュアルユースのリクエストに対しては、実行可能な指示や詳細な情報提供を避けているという。初心者による誤用を防ぐため、高レベルの洞察は提供しつつ、詳細情報は制限している。また、疑わしい行為を検出システムで監視・ブロックし、ポリシー違反があった場合はアカウント停止や法執行機関への通報も行う。
さらに、7月にバイオディフェンスサミットを開催するほか、認定機関へのモデルアクセスプロトコルを策定し、政府や民間セクターと協力して社会全体の生物学的防御力を向上させるよう提唱している。
OpenAIは、ユーザーに対し、AIモデルを危害を加える目的で利用しないよう強く求め、違反した場合は厳しく対処すると明記している。安全とセキュリティをAIモデルの不可欠な要素とし、世界中の関係者との協力を通じて、バイオセキュリティエコシステムの準備とブレイクスルーの実現を目指すとしている。
Copyright © ITmedia, Inc. All Rights Reserved.