---
title: 'Subjective Experience in AI Systems: What Do AI Researchers and the Public
  Believe?'
description: "arXiv:2506.11945v1 Announce Type: cross \nAbstract: We surveyed 582\
  \ AI researchers who have published in leading AI venues and 838 nationally representative\
  \ US participants about their views on the potential development of AI systems with\
  \ subjective experience and how such systems should be treated and governed. When\
  \ asked to estimate the chances that such systems will exist on specific dates,\
  \ the median responses were 1% (AI researchers) and 5% (public) by 2024, 25% and\
  \ 30% by 2034, and 70% and 60% by 2100, respectively. The median member of the public\
  \ thought there was a higher chance that AI systems with subjective experience would\
  \ never exist (25%) than the median AI researcher did (10%). Both groups perceived\
  \ a need for multidisciplinary expertise to assess AI subjective experience. Although\
  \ support for welfare protections for such AI systems exceeded opposition, it remained\
  \ far lower than support for protections for animals or the environment. Attitudes\
  \ toward moral and governance issues were divided in both groups, especially regarding\
  \ whether such systems should be created and what rights or protections they should\
  \ receive. Yet a majority of respondents in both groups agreed that safeguards against\
  \ the potential risks from AI systems with subjective experience should be implemented\
  \ by AI developers now, and if created, AI systems with subjective experience should\
  \ treat others well, behave ethically, and be held accountable. Overall, these results\
  \ suggest that both AI researchers and the public regard the emergence of AI systems\
  \ with subjective experience as a possibility this century, though substantial uncertainty\
  \ and disagreement remain about the timeline and appropriate response."
pubDate: Mon, 16 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.11945
---

Computer Science > Computers and Society
[Submitted on 13 Jun 2025]
Title:Subjective Experience in AI Systems: What Do AI Researchers and the Public Believe?
View PDFAbstract:We surveyed 582 AI researchers who have published in leading AI venues and 838 nationally representative US participants about their views on the potential development of AI systems with subjective experience and how such systems should be treated and governed. When asked to estimate the chances that such systems will exist on specific dates, the median responses were 1% (AI researchers) and 5% (public) by 2024, 25% and 30% by 2034, and 70% and 60% by 2100, respectively. The median member of the public thought there was a higher chance that AI systems with subjective experience would never exist (25%) than the median AI researcher did (10%). Both groups perceived a need for multidisciplinary expertise to assess AI subjective experience. Although support for welfare protections for such AI systems exceeded opposition, it remained far lower than support for protections for animals or the environment. Attitudes toward moral and governance issues were divided in both groups, especially regarding whether such systems should be created and what rights or protections they should receive. Yet a majority of respondents in both groups agreed that safeguards against the potential risks from AI systems with subjective experience should be implemented by AI developers now, and if created, AI systems with subjective experience should treat others well, behave ethically, and be held accountable. Overall, these results suggest that both AI researchers and the public regard the emergence of AI systems with subjective experience as a possibility this century, though substantial uncertainty and disagreement remain about the timeline and appropriate response.
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.