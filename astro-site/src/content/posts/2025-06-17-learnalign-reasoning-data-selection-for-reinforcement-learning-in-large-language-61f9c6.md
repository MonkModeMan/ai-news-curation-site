---
title: 'LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language
  Models Based on Improved Gradient Alignment'
description: "arXiv:2506.11480v1 Announce Type: cross \nAbstract: Reinforcement learning\
  \ (RL) has become a key technique for enhancing LLMs' reasoning abilities, yet its\
  \ data inefficiency remains a major bottleneck. To address this critical yet challenging\
  \ issue, we present a novel gradient-alignment-based method, named LearnAlign, which\
  \ intelligently selects the learnable and representative training reasoning data\
  \ for RL post-training. To overcome the well-known issue of response-length bias\
  \ in gradient norms, we introduce the data learnability based on the success rate,\
  \ which can indicate the learning potential of each data point. Experiments across\
  \ three mathematical reasoning benchmarks demonstrate that our method significantly\
  \ reduces training data requirements while achieving minor performance degradation\
  \ or even improving performance compared to full-data training. For example, it\
  \ reduces data requirements by up to 1,000 data points with better performance (77.53%)\
  \ than that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show\
  \ its effectiveness in the staged RL setting. This work provides valuable insights\
  \ into data-efficient RL post-training and establishes a foundation for future research\
  \ in optimizing reasoning data selection.To facilitate future work, we will release\
  \ code."
pubDate: Mon, 16 Jun 2025 00:00:00 -0400
source: arXiv AI
tags:
- arxiv
- ai
- research
url: https://arxiv.org/abs/2506.11480
---

Computer Science > Machine Learning
[Submitted on 13 Jun 2025]
Title:LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment
View PDFAbstract:Reinforcement learning (RL) has become a key technique for enhancing LLMs' reasoning abilities, yet its data inefficiency remains a major bottleneck. To address this critical yet challenging issue, we present a novel gradient-alignment-based method, named LearnAlign, which intelligently selects the learnable and representative training reasoning data for RL post-training. To overcome the well-known issue of response-length bias in gradient norms, we introduce the data learnability based on the success rate, which can indicate the learning potential of each data point. Experiments across three mathematical reasoning benchmarks demonstrate that our method significantly reduces training data requirements while achieving minor performance degradation or even improving performance compared to full-data training. For example, it reduces data requirements by up to 1,000 data points with better performance (77.53%) than that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show its effectiveness in the staged RL setting. This work provides valuable insights into data-efficient RL post-training and establishes a foundation for future research in optimizing reasoning data this http URL facilitate future work, we will release code.
References & Citations
Bibliographic and Citation Tools
Bibliographic Explorer (What is the Explorer?)
Connected Papers (What is Connected Papers?)
Litmaps (What is Litmaps?)
scite Smart Citations (What are Smart Citations?)
Code, Data and Media Associated with this Article
alphaXiv (What is alphaXiv?)
CatalyzeX Code Finder for Papers (What is CatalyzeX?)
DagsHub (What is DagsHub?)
Gotit.pub (What is GotitPub?)
Hugging Face (What is Huggingface?)
Papers with Code (What is Papers with Code?)
ScienceCast (What is ScienceCast?)
Demos
Recommenders and Search Tools
Influence Flower (What are Influence Flowers?)
CORE Recommender (What is CORE?)
IArxiv Recommender
(What is IArxiv?)
arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.