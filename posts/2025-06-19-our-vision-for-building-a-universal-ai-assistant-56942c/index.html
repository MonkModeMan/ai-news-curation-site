<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>Our vision for building a universal AI assistant</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/_page_.BNX7D8gk.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- ‚úÖ „Çø„Ç§„Éà„É´ --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">üì∞ Our vision for building a universal AI assistant</h1> <p class="text-sm text-gray-500"> 2025/5/20 ‚Äì DeepMind Blog  <a href="https://deepmind.google/discover/blog/our-vision-for-building-a-universal-ai-assistant/" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
ÂÖÉË®ò‰∫ã
</a>  </p> </header> <!-- ‚úÖ Êú¨Êñá --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> Our vision for building a universal AI assistant
Over the last decade, we‚Äôve laid a lot of the foundations for the modern AI era, from pioneering the Transformer architecture on which all large language models are based, to developing agent systems that can learn and plan like AlphaGo and AlphaZero.
We‚Äôve applied these techniques to make breakthroughs in quantum computing, mathematics, life sciences and algorithmic discovery. And we continue to double down on the breadth and depth of our fundamental research, working to invent the next big breakthroughs necessary for artificial general intelligence (AGI).
This is why we‚Äôre working to extend our best multimodal foundation model, Gemini 2.5 Pro, to become a ‚Äúworld model‚Äù that can make plans and imagine new experiences by understanding and simulating aspects of the world, just as the brain does.
We‚Äôve been taking strides in this direction for a while, from our pioneering work training agents to master complex games like Go and StarCraft, to building Genie 2, which is capable of generating 3D simulated environments that you can interact with, from a single image prompt.
Already, we can see evidence of these capabilities emerging in Gemini‚Äôs ability to use world knowledge and reasoning to represent and simulate natural environments, Veo‚Äôs deep understanding of intuitive physics, and the way Gemini Robotics teaches robots to grasp, follow instructions and adjust on the fly.
Making Gemini a world model is a critical step in developing a new, more general and more useful kind of AI ‚Äî a universal AI assistant. This is an AI that‚Äôs intelligent, understands the context you are in, and that can plan and take action on your behalf, across any device.
Bringing Project Astra‚Äôs live capabilities into our products
Our ultimate vision is to transform the Gemini app into a universal AI assistant that will perform everyday tasks for us, take care of our mundane admin and surface delightful new recommendations ‚Äî making us more productive and enriching our lives.
This starts with the capabilities we first explored last year in our research prototype Project Astra, such as video understanding, screen sharing and memory.
Over the past year, we‚Äôve been integrating capabilities like these into Gemini Live for more people to experience today. We continue to relentlessly improve and explore new innovations at the frontier. For example, we upgraded voice output to be more natural with native audio, we‚Äôve improved memory and added computer control.
We‚Äôre now gathering feedback about these capabilities from trusted testers and are working to bring them to Gemini Live, to new experiences in Search, the Live API for developers and new form factors, like glasses.
Through every step of this process, safety and responsibility are central to our work. We recently conducted a large research project, exploring the ethical issues surrounding advanced AI assistants, and this work continues to inform our research, development and deployment.
Building AI that can multitask for you
We‚Äôve also been exploring how agentic capabilities can help people multitask, with Project Mariner. This is a research prototype that explores the future of human-agent interaction, starting with browsers.
Since launching Project Mariner last December, we‚Äôve been working closely with a group of trusted testers to gather feedback and improve its experimental capabilities.
Project Mariner now includes a system of agents that can complete up to ten different tasks at a time. These agents can help you look up information, make bookings, buy things, do research and more ‚Äî all at the same time.
The updated Project Mariner is available to Google AI Ultra subscribers in the U.S. We&#39;re bringing its computer use capabilities into the Gemini API, and we‚Äôre planning to bring more of its capabilities to Google products throughout the year. Read more about our agentic capabilities in Search and the Gemini app.
With this, and all our groundbreaking work, we‚Äôre building AI that‚Äôs more personal, proactive and powerful, enriching our lives, advancing the pace of scientific progress and ushering in a new golden age of discovery and wonder. </article> <!-- ‚úÖ Êàª„Çã„Éú„Çø„É≥ --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
‚Üê ‰∏ÄË¶ß„Å∏Êàª„Çã
</a> </div> </div> <!-- ‚úÖ base „ÇíÊ≠£„Åó„ÅèÂüã„ÇÅËæº„ÇÄ --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- ‚úÖ Êàª„Çã„É™„É≥„ÇØ„ÇíÊ≠£„Åó„ÅèÊßãÁØâ --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("‚úÖ base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("‚úÖ backLink.href:", backLink.href);
      } else {
        console.warn("‚ö†Ô∏è backLink not found");
      }
    </script> </body> </html>