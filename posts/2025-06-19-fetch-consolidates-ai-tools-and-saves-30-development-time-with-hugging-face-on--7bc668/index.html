<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/_page_.Ba3Vwl3b.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- âœ… ã‚¿ã‚¤ãƒˆãƒ« --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">ğŸ“° Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS</h1> <p class="text-sm text-gray-500"> 2023/2/23 â€“ Hugging Face Blog  <a href="https://huggingface.co/blog/fetch-eap-case-study" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
å…ƒè¨˜äº‹
</a>  </p> </header> <!-- âœ… æœ¬æ–‡ --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS
If you need support in using Hugging Face and AWS, please get in touch with us here - our team will contact you to discuss your requirements!
Executive Summary
Fetch, a consumer rewards company, developed about 15 different AI tools to help it receive, route, read, process, analyze, and store receipts uploaded by users. The company has more than 18 million active monthly users for its shopping rewards app. Fetch wanted to rebuild its AI-powered platform and, using Amazon Web Services (AWS) and with the support of AWS Partner Hugging Face, moved from using third-party applications to developing its own tools to gain better insights about customers. Consumers scan receipts â€”or forward electronic receiptsâ€” to receive rewards points for their purchases. Businesses can offer special rewards to users, such as extra points for purchasing a particular product. The company can now process more than 11 million receipts per day faster and gets better data.
Fetch Needed a Scalable Way to Train AI Faster
Fetchâ€”formerly Fetch Rewardsâ€”has grown since its founding to serve 18 million active users every month who scan 11 million receipts every day to earn reward points. Users simply take a picture of their receipt and upload it using the companyâ€™s app. Users can also upload electronic receipts. Receipts earn points; if the receipt is from a brand partner of Fetch, it may qualify for promotions that award additional points. Those points can be redeemed for gift cards from a number of partners. But scanning is just the beginning. Once Fetch receives the receipts, it must process them, extracting data and analytics and filing the data and the receipts. It has been using artificial intelligence (AI) tools running on AWS to do that.
The company was using an AI solution from a third party to process receipts, but found it wasnâ€™t getting the data insights it needed. Fetchâ€™s business partners wanted information about how customers were engaging with their promotions, and Fetch didnâ€™t have the granularity it needed to extract and process data from millions of receipts daily. â€œFetch was using a third-party provider for its brain, which is scanning receipts, but scanning is not enough,â€ says Boris Kogan, computer vision scientist at Fetch. â€œThat solution was a black box and we had no control or insight into what it did. We just got results we had to accept. We couldnâ€™t give our business partners the information they wanted.â€
Kogan joined Fetch tasked with the job of building thorough machine learning (ML) and AI expertise into the company and giving it full access to all aspects of the data it was receiving. To do this, he hired a team of engineers to bring his vision to life. â€œAll of our infrastructure runs on AWS, we also rely on the AWS products to train our models,â€ says Kogan. â€œWhen the team started working on creating a brain of our own, of course, we first had to train our models and we did that on AWS. We allocated 12 months for the project and completed it in 8 month because we always had the resources we needed.â€
Hugging Face Opens Up the Black Box
The Fetch team engaged with AWS Partner Hugging Face through the Hugging Face Expert Acceleration Program on the AWS Marketplace to help Fetch unlock new tools to power processes after the scans had been uploaded. Hugging Face is a leader in open-source AI and provides guidance to enterprises on using AI. Many enterprises, including Fetch, use transformers from Hugging Face, which allow users to train and deploy open-source ML models in minutes. â€œEasy access to Transformers models is something that started with Hugging Face, and they&#39;re great at that,â€ says Kogan. The Fetch and Hugging Face teams worked to identify and train state-of-the-art document AI models, improving entity resolution and semantic search.
In this relationship, Hugging Face acted in an advisory capacity, transferring knowledge to help the Fetch engineers use its resources more effectively. â€œFetch had a great team in place,â€ says Yifeng Yin, machine learning engineer at Hugging Face. â€œThey didn&#39;t need us to come in and run the project or build it. They wanted to learn how to use Hugging Face to train the models they were building. We showed them how to use the resources, and they ran with it.â€ With Yifengâ€™s guidance, Fetch was able to cut its development time by 30 percent.
Because it was building its own AI and ML models to take over from the third-party â€˜brainâ€™, it needed to ensure a robust system that produced good results before switching over. Fetch required doing this without interrupting the flow of millions of receipts every day. â€œBefore we rolled anything out, we built a shadow pipeline,â€ says Sam Corzine, lead machine learning engineer at Fetch. â€œWe took all the things and reprocessed them in our new ML pipeline. We could do audits of everything. It was running full volume, reprocessing all of those 11 million receipts and doing analytics on them for quite a while before anything made it into the main data fields. The black box was still running the show and we were checking our results against it.â€ The solution uses Amazon SageMakerâ€”which lets businesses build, train, and deploy ML models for any use case with fully managed infrastructure, tools, and workflows. It also uses AWS Inferentia accelerators to deliver high performance at the lowest cost for deep learning (DL) inference applications.
Fetch Grows AI Expertise, Cuts Latency by 50%, and Saves Costs
Fetchâ€™s commitment to developing in-house ML and AI capabilities has resulted in several benefits, including some cost savings, but more important is the development of a service that better serves the needs of the customers. â€œWith any app you have to give the customer a reason to keep coming back,â€ says Corzine. â€œWeâ€™ve improved responsiveness for customers with faster processing of uploads, cutting processing latency by 50 percent. If you keep customers waiting too long, theyâ€™ll disengage. And the more customers use Fetch, the better understanding we and our partners get about whatâ€™s important to them. By building our own models, we get details we never had before.â€
The company can now train a model in hours instead of the days or weeks it used to take. Development time has also been reduced by about 30 percent. And while it may not be possible to put a number to it, another major benefit has been creating a more stable foundation for Fetch. â€œRelying on a third-party black box presented considerable business risk to us,â€ says Corzine. â€œBecause Hugging Face existed and its community existed, we were able to use that tooling and work with that community. At the end of the day, we now control our destiny.â€
Fetch is continuing to improve the service to customers and gain a better understanding of customer behavior now that it is an AI-first company, rather than a company that uses a third-party AI â€˜brainâ€™. â€œHugging Face and AWS gave us the infrastructure and the resources to do what we need,â€ says Kogan. â€œHugging Face has democratized transformer models, models that were nearly impossible to train, and made them available to anyone. We couldnâ€™t have done this without them.â€
This article is a cross-post from an originally published post on February 2024 on AWS&#39;s website. </article> <!-- âœ… æˆ»ã‚‹ãƒœã‚¿ãƒ³ --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
â† ä¸€è¦§ã¸æˆ»ã‚‹
</a> </div> </div> <!-- âœ… base ã‚’æ­£ã—ãåŸ‹ã‚è¾¼ã‚€ --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- âœ… æˆ»ã‚‹ãƒªãƒ³ã‚¯ã‚’æ­£ã—ãæ§‹ç¯‰ --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("âœ… base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("âœ… backLink.href:", backLink.href);
      } else {
        console.warn("âš ï¸ backLink not found");
      }
    </script> </body> </html>