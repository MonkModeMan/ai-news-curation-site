<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>Helping machines understand visual content with AI</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/_page_.Ba3Vwl3b.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- âœ… ã‚¿ã‚¤ãƒˆãƒ« --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">ğŸ“° Helping machines understand visual content with AI</h1> <p class="text-sm text-gray-500"> 2025/6/9 â€“ MIT  <a href="https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
å…ƒè¨˜äº‹
</a>  </p> </header> <!-- âœ… æœ¬æ–‡ --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> Data should drive every decision a modern business makes. But most businesses have a massive blind spot: They donâ€™t know whatâ€™s happening in their visual data.
Coactive is working to change that. The company, founded by Cody Coleman â€™13, MEng â€™15 and William Gaviria Rojas â€™13, has created an artificial intelligence-powered platform that can make sense of data like images, audio, and video to unlock new insights.
Coactiveâ€™s platform can instantly search, organize, and analyze unstructured visual content to help businesses make faster, better decisions.
â€œIn the first big data revolution, businesses got better at getting value out of their structured data,â€ Coleman says, referring to data from tables and spreadsheets. â€œBut now, approximately 80 to 90 percent of the data in the world is unstructured. In the next chapter of big data, companies will have to process data like images, video, and audio at scale, and AI is a key piece of unlocking that capability.â€
Coactive is already working with several large media and retail companies to help them understand their visual content without relying on manual sorting and tagging. Thatâ€™s helping them get the right content to users faster, remove explicit content from their platforms, and uncover how specific content influences user behavior.
More broadly, the founders believe Coactive serves as an example of how AI can empower humans to work more efficiently and solve new problems.
â€œThe word coactive means to work together concurrently, and thatâ€™s our grand vision: helping humans and machines work together,â€ Coleman says. â€œWe believe that vision is more important now than ever because AI can either pull us apart or bring us together. We want Coactive to be an agent that pulls us together and gives human beings a new set of superpowers.â€
Giving computers vision
Coleman met Gaviria Rojas in the summer before their first yearthrough the MIT Interphase Edge program. Both would go on to major in electrical engineering and computer science and work on bringing MIT OpenCourseWare content to Mexican universities, among other projects.
â€œThat was a great example of entrepreneurship,â€ Coleman recalls of the OpenCourseWare project. â€œIt was really empowering to be responsible for the business and the software development. It led me to start my own small web-development businesses afterward, and to take [the MIT course] Founderâ€™s Journey.â€
Coleman first explored the power of AI at MIT while working as a graduate researcher with the Office of Digital Learning (now MIT Open Learning), where he used machine learning to study how humans learn on MITx, which hosts massive, open online courses created by MIT faculty and instructors.
â€œIt was really amazing to me that you could democratize this transformational journey that I went through at MIT with digital learning â€” and that you could apply AI and machine learning to create adaptive systems that not only help us understand how humans learn, but also deliver more personalized learning experiences to people around the world,â€ Coleman says of MITx. â€œThat was also the first time I got to explore video content and apply AI to it.â€
After MIT, Coleman went to Stanford University for his PhD, where he worked on lowering barriers to using AI. The research led him to work with companies like Pinterest and Meta on AI and machine-learning applications.
â€œThatâ€™s where I was able to see around the corner into the future of what people wanted to do with AI and their content,â€ Coleman recalls. â€œI was seeing how leading companies were using AI to drive business value, and thatâ€™s where the initial spark for Coactive came from. I thought, â€˜What if we create an enterprise-grade operating system for content and multimodal AI to make that easy?â€™â€
Meanwhile, Gaviria Rojas moved to the Bay Area in 2020 and started working as a data scientist at eBay. As part of the move, he needed help transporting his couch, and Coleman was the lucky friend he called.
â€œOn the car ride, we realized we both saw an explosion happening around data and AI,â€ Gaviria Rojas says. â€œAt MIT, we got a front row seat to the big data revolution, and we saw people inventing technologies to unlock value from that data at scale. Cody and I realized we had another powder keg about to explode with enterprises collecting tremendous amount of data, but this time it was multimodal data like images, video, audio, and text. There was a missing technology to unlock it at scale. That was AI.â€
The platform the founders went on to build â€” what Coleman describes as an â€œAI operating systemâ€ â€” is model agnostic, meaning the company can swap out the AI systems under the hood as models continue to improve. Coactiveâ€™s platform includes prebuilt applications that business customers can use to do things like search through their content, generate metadata, and conduct analytics to extract insights.
â€œBefore AI, computers would see the world through bytes, whereas humans would see the world through vision,â€ Coleman says. â€œNow with AI, machines can finally see the world like we do, and thatâ€™s going to cause the digital and physical worlds to blur.â€
Improving the human-computer interface
Reutersâ€™ database of images supplies the worldâ€™s journalists with millions of photos. Before Coactive, the company relied on reporters manually entering tags with each photo so that the right images would show up when journalists searched for certain subjects.
â€œIt was incredible slow and expensive to go through all of these raw assets, so people just didnâ€™t add tags,â€ Coleman says. â€œThat meant when you searched for things, there were limited results even if relevant photos were in the database.â€
Now, when journalists on Reutersâ€™ website select â€˜Enable AI Search,â€™ Coactive can pull up relevant content based on its AI systemâ€™s understanding of the details in each image and video.
â€œItâ€™s vastly improving the quality of results for reporters, which enables them to tell better, more accurate stories than ever before,â€ Coleman says.
Reuters is not alone in struggling to manage all of its content. Digital asset management is a huge component of many media and retail companies, who today often rely on manually entered metadata for sorting and searching through that content.
Another Coactive customer is Fandom, which is one of the worldâ€™s largest platforms for information around TV shows, videogames, and movies with more than 300 million monthly active users. Fandom is using Coactive to understand visual data in their online communities and help remove excessive gore and sexualized content.
â€œIt used to take 24 to 48 hours for Fandom to review each new piece of content,â€ Coleman says. â€œNow with Coactive, theyâ€™ve codified their community guidelines and can generate finer-grain information in an average of about 500 milliseconds.â€
With every use case, the founders see Coactive as enabling a new paradigm in the ways humans work with machines.
â€œThroughout the history of human-computer interaction, weâ€™ve had to bend over a keyboard and mouse to input information in a way that machines could understand,â€ Coleman says. â€œNow, for the first time, we can just speak naturally, we can share images and video with AI, and it can understand that content. Thatâ€™s a fundamental change in the way we think about human-computer interactions. The core vision of Coactive is because of that change, we need a new operating system and a new way of working with content and AI.â€ </article> <!-- âœ… æˆ»ã‚‹ãƒœã‚¿ãƒ³ --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
â† ä¸€è¦§ã¸æˆ»ã‚‹
</a> </div> </div> <!-- âœ… base ã‚’æ­£ã—ãåŸ‹ã‚è¾¼ã‚€ --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- âœ… æˆ»ã‚‹ãƒªãƒ³ã‚¯ã‚’æ­£ã—ãæ§‹ç¯‰ --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("âœ… base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("âœ… backLink.href:", backLink.href);
      } else {
        console.warn("âš ï¸ backLink not found");
      }
    </script> </body> </html>