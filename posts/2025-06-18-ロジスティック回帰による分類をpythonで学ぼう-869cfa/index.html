<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>「ロジスティック回帰」による分類をPythonで学ぼう</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/_page_.CO8YC2Z5.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- ✅ タイトル --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">📰 「ロジスティック回帰」による分類をPythonで学ぼう</h1> <p class="text-sm text-gray-500"> 2025/6/17 – ITmedia AI  <a href="https://atmarkit.itmedia.co.jp/ait/articles/2506/18/news014.html" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
元記事
</a>  </p> </header> <!-- ✅ 本文 --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> �u�m���[������w�ׂ�v�����b�g�[�ɂ����@�B�w�K����A�ڂ̑�5��B���悢�捡��A�uYes�^No�v��u�X�p�����ǂ����v�Ƃ������g���ށh�\���������܂��B��������������\�I�Ȏ�@���u���W�X�e�B�b�N��A�v�ł��B�}���g���Ďd�g�݂�l�������₳�����w�сAPython��scikit-learn�ł̎������̌����܂��B���߂Ă̐l�ł����S���Ď��g�߂���e�ł��B
�@�u���̏��i�͔���邩�^�ǂ����H�v�u���̌ڋq�̓T�[�r�X����������^�ǂ����H�v�\�\ ��������Yes�^No�̔��f�i�����ށj���f�[�^����\����������ʂ́A�r�W�l�X�����ł�������܂���ˁH�@����́A���̂悤�ȍۂɖ𗧂A�@�B�w�K�̑�\�I�Ȏ�@�ł������W�X�e�B�b�N��A�ɂ��g���ށh�ɂ��Ċw��ł����܂��傤�B
�@��̓I�ɂ́A���W�X�e�B�b�N��A�̊T�v����A���̎d�g�݁A������Python�v���O���~���O�ɂ�郂�f���̎����ƕ]���܂Ŏ��g�݁A�g���ށh�̊�b�X�L����Z���ԂŏK�����邱�Ƃ�ڎw���܂��i�}1�j�B�g���ށh���}�X�^�[����ƁA����܂Łu�o���⊨�ɗ����Ă������f�v���u�f�[�^�̗��t�������锻�f�v�ɕς��邱�Ƃ��ł��A�r�W�l�X�̈ӎv����ɂ��傢�ɖ𗧂��܂��B
�@����܂ł̘A�ڂł́A��3���Ő��`��A�ɂ��āA��4���Ń��b�\��A�ƃ��b�W��A�ɂ��āA�܂�g���l�h��\������u��A�v�̎�@���w��ł��܂����B����͐V���ȃe�[�}�ɓ���A�g�J�e�S���[�h��\������u���ށv�̎�@���w��ł����܂��B����ȍ~�ł́A����A�����_���t�H���X�g�A�T�|�[�g�x�N�^�[�}�V���Ak-�ߖT�@�Ƒ����̂ł��y���݂ɁI
�@�Ȃ�������A�厖�ȃG�b�Z���X�Ƀt�H�[�J�X���A�ߋ��L���Ƃ̋��ʕ����͂ł��邾���ȗ����Ă��܂��B�������A���W�X�e�B�b�N��A�͐��`��A�����������G�Ȃ��߁A�d�g�݂̐����͖�1.5�{�قǂɂȂ�܂��B����A�v���O���~���O�͂���܂ł̒m���̉��p�Ȃ̂ŁA�Z���Ԃœǂ߂�͂��ł��B����āA�L���S�̂̃{�����[�����͐��`��A�Ɠ������炢���Ƒz�肵�Ă��܂��B
�@���W�X�e�B�b�N��A�́A�uYes���^No���v�Ƃ�������l�i��2�N���X�j�́g���ށh�����������߂́A��{�I�Ŏ��p���̍�����@�ł��B�Ⴆ�u���̃��[���̓X�p�����^�ǂ����H�v�Ƃ������₢�ɑ��A�f�[�^�Ɋ�Â��g�\���h�ɂ���Ĕ��f�ł��܂��B�@�B�w�K�ɂ����镪�ގ�@�̒��ł��A�܂��K�����Ă��������g�K�C�X�L���h�ƌ����܂��B
�@�}1�Ɏ������ʂ�A����̃��W�X�e�B�b�N��A���f�����APython���C�u�����uscikit-learn�v���g���Ύ�y�Ɏ����ł��܂��B�{�e�ł͂܂��A���W�X�e�B�b�N��A�̊�{�I�ȊT�O��l������}���g���ĕ�����₷��������܂��B���̌�A���H�Ŗ𗧂�\�I�Ȏg�p��ɍi���āAPython�ɂ�������̌����Ă����܂��B
�@�܂��A�y���W�z�Ƃ����\�t�g�}�b�N�X��A�ƌĂ���@���ȒP�ɏЉ�܂��B���W�X�e�B�b�N��A����l�����ɗp������̂ɑ��A�\�t�g�}�b�N�X��A��3�ȏ�̃N���X���������N���X�����̂��߂̉��p�I�Ȏ�@�ł��B�������W�X�e�B�b�N��A�i�̈��j�Ƃ��Ă��A���̎�@���K������A��蕝�L�����ޖ��ɑΉ��ł���悤�ɂȂ�܂��B
�@�܂Ƃ߂�ƁA����͐}2�Ɏ������e���w�Ԃ��Ƃ��ł��܂��B
�@����ł́A�܂��̓��W�X�e�B�b�N��A�̊T�v�Љ��n�߂Ă����܂��B
�@�u�@�B�w�K�͓�����v�Ǝv���Ă��܂��H�@�S�z�͗v��܂���B���̘A�ڂł́A�u�m���[������w�ׂ�v�����b�g�[�ɁA�@�B�w�K�̊�b�Ɗe��@��}���ƊȌ��Ȑ����ŕ�����₷��������܂��BPython���g�������H���K������܂��̂ŁA�����̎�������ƂŎ��p�I�ȃX�L����g�ɕt�����܂��B
�@�{�A�ڂł́A��̓I�ȋ@�B�w�K�̎�@�i��F���`��A�A����Ak-means�Ȃǁj��������Ă��܂��B����ȍ~�̐V���L�����������Ȃ��悤�ɁA���Јȉ��̃��[���ʒm�̓o�^�����肢���܂��B
�@���W�X�e�B�b�N��A�iLogistic Regression�j�́A���̓f�[�^�Əo�͌��ʂ̊W���uS���^�̋Ȑ��v�i�����W�X�e�B�b�N���A�ڍׂ͌�q�j�Ń��f���������@�ł��B����A���`��A���f���ł��A�u�Ȑ��v�ł͂Ȃ��u�����v�ŊW��\�����Ă��܂����B���̈Ⴂ�����ɏd�v�ȃ|�C���g�ł��B
�@�Ⴆ�ΐ}3�́A���̓f�[�^�i�����ϐ��A�����ʁj�Ƃ��āu�T�[�r�X�̗��p�v���A�o�͌��ʁi�ړI�ϐ��A�^�[�Q�b�g�A���x���^�N���X���x���j�Ƃ��āu�މ���i1�j�^���Ă��Ȃ��i0�j�v�����ˋ�̃f�[�^����U�z�}���쐬���A���̏�Ƀ��W�X�e�B�b�N��A���f���̗\���Ȑ��iS���J�[�u�j���������}�ł��B
�@�U�z�}�̑S�Ă̓_���g�ł����Ă͂܂�̂悢�Ȑ��h�������Ă��܂��B���ꂪ���W�X�e�B�b�N��A�̖{���ł��B���̋Ȑ�����A�Ⴆ�T�[�r�X���p��15���̎��͑މ�m����3.18���Ƃ������Ɓi���\���l�j���ǂݎ��܂��ˁi�}3�ŐF�Ŏ����������j�B
�@�������A�m���l�̂܂܂ł́uYes���^No���v�Ƃ����g���ށh�ɂ͎g���Â炢�ł���ˁB�����ŁA0.5�����Ȃ�u�p���v�A0.5�ȏ��Ȃ�u�މ�v�A�Ƃ�����i��臒l�s���������A�������t�Fthreshold�j��݂��āA�m���l��0�i��No�j��1�i��Yes�j�������U���idiscretization�A�܂�A���l��2�̃J�e�S���[�ɕ����j���܂��B������O���t�������̂��}4�ł��B
�@���U���̊�ƂȂ���i�}4�ł͗ΐF�̓_���j�́A���苫�E�iDecision Boundary�j�ƌĂ�܂��B�}4�̂悤�ɂ��̋��E���ɂ���ăO���t������ƁA�U�z�}�̂ǂ̓_���u�p����0�v���^�u�މ1�v�������o�I�ɔc�����₷���Ȃ�܂��B�ȏオ�A�}�ŗ�������u���W�X�e�B�b�N��A�ɂ��g���ށh���@�v�ł��B
�@���̂悤�ɂ��ĕ��ނł���A�Ⴆ�Έȉ��̂悤�ȏ�ʂŖ𗧂��܂��B���ۂɃ��W�X�e�B�b�N��A�́A���܂��܂ȕ���ŕ��L���g���Ă��܂��i�`���̐}1�ɂ��L�ڂ��Ă��܂��j�B
�@��������A�Ȑ��ŕ\�����ꂽ���ރ��f���ɂ���āu�ǂ��炩���J�e�S���[�i��F�X�p���^��X�p���A�މ�^�p���A�w���^��w���j�ɑ������m�����\�����A��������苫�E����������v���ƂŎ�������܂��B�@�B�w�K�ɂ����郍�W�X�e�B�b�N��A�́A���̂悤�ɂ��āg��l���ށh�̖��������ł��܂��B
�@�������A�}3�i��}4�j�ɕ`���ꂽS���^�̋Ȑ��́A�����ɂ���Č`������Ă��܂��B���͂��̋Ȑ����A���`��A�Ɠ����悤�Ɂux�ɐ��������āA��������y���v�Z���鐔���v�Œ�`����Ă��܂��i���̓��e�͌�ŏڂ������܂��j�B
�@�܂��́A�}5�ɂ���z��7.20915�|0.70838x�̂悤�Ȑ����ŁAx�i�����ł́u�T�[�r�X���p�v�j���g���ēr���̌v�Z�lz�����߂܂��B���̌v�Z�́A���w�Ŋw�Ԉꎟ���i�������̐����j�Ȃ̂ŊȒP�ł��ˁB���̌v�Z�̎d���͐��`��A�ƑS�������ł��B�ڂ����͌�q���܂��B
�@���ɁA����z���uS���^���J�[�u��`�����W�X�e�B�b�N���v�ɒʂ����ƂŁA�ŏI�I��y�̒l�i�����ł́u�މ�m���v�j���Z�o���܂��B����������ƁA�u�܂��͒����œr���̒lz���v�Z���A����z���Ȑ��ɕϊ����Ċm���l�����߂�v�Ƃ����A2�X�e�b�v�̍\���ɂȂ��Ă���̂ł��B
�@���̂悤�Ƀ��W�X�e�B�b�N��A�́A���`��A�Ƃ́g�Z��̂悤�ȊW�h�ł��B����ă��W�X�e�B�b�N��A�ł��A���������u�X���v�A�܂�ϐ��Ɂu�W�i�����j�鐔�i�������Z���鐔�j�v����A�W���iregression coefficient�j�ƌĂ�܂��B�ؕ��iintercept�j�Ƃ����p������̂܂g���܂��B
�@�o�͂͊m���Ɂg����`�h�ł����A�O���̌v�Z�i�����`�����j���g���`�h�ł��邽�߁A���W�X�e�B�b�N��A�͈�ʂɁu���`��A�̈��v�Ƒ������܂��B�c�c����Ȃ킯�ŁA�g���ށh�̂��߂̎�@�Ȃ̂Ɂu���W�X�e�B�b�N�g��A�h�v�Ƃ����A������ƕ���킵�����O�ɂȂ��Ă��܂��i��j�B
�@���`��A���f���́A�����ʂ�1�Ȃ�u�����v�A2�Ȃ�u���ʁv�A3�ȏ�Ȃ�u�����ʁv�ŕ\������܂����B����A���W�X�e�B�b�N��A���f���͏����قȂ�A�����ʂ�1�Ȃ�uS���^���Ȑ��iCurve�j�v�A2�Ȃ�u�Ȗ��iSurface�j�v�A3�ȏ�ł́u���Ȗ��iHypersurface�j�v�ŕ\������܂��i���Ȃ��A���ۂ́g���ށh�́A���ɐ��������ʂ�A���̏o�͂�臒l��݂����u���苫�E�v�ɂ���čs���܂��j�B
�@�������A�Ȗʂ⒴�Ȗʂ͐}�ɂ��Ă������I�ȗ�����������߁A�{�e�ł͓����ʂ�2�ȏ�̃��f���̐}�����ȗ����܂��B�C���[�W�Ƃ��ẮA���`��A�́u��A���ʁv���u�Ȗʁv�ɒu����������悤�Ȃ��̂ƍl����Ƃ悢�ł��傤�B
�@���Ȃ݂ɁA���`��A�ł́A�����ʂ�1�̃��f�����u�P��A�v�A2�ȏ�̃��f�����u�d��A�v�ƌĂѕ����Ă��܂����B����A���W�X�e�B�b�N��A�ł́A��ʂɂ��������p��̋�ʂ͍s���܂���B
�@�ȏ�ŁA�u���W�X�e�B�b�N��A�����`��A�����p������@�ł��邱�Ɓv���������Ă����Ǝv���܂��B�������A���f���̃p�����[�^�[�i�Ⴆ�ΐ�قǂ̐����ɏo�Ă����ؕ�7.20915��W���|0.70838�j�����肷��d�g�݂́A���`��A�̌v�Z���@�u�ŏ����@�v�Ƃ͈قȂ�܂��B���ɁA���̎d�g�݂����Ă����܂��傤�B
�@�f�[�^�ɍł��t�B�b�g���郍�W�X�e�B�b�N��A���f���iS���^�̗\���Ȑ��^�Ȗʁ^���Ȗʁj�̊e�p�����[�^�[�������邽�߂ɂ́A��ʓI�Ɂu�Ŗށi�����䂤�j����v�i���Ŗޖ@�j�ƌĂ��v�Z���@���p�����܂��B�ȉ��ŁA���̎d�g�݂��ł��邾�������ł͂Ȃ��}���𒆐S�ɐ������Ă����܂��B
�@�܂��͌P���p�̃f�[�^�Z�b�g���K�v�ł��B�ȉ��̐����ł́A��قǂ̗�i�}3�`5�j�Ɠ����f�[�^���g�����Ƃɂ��܂��i�}6�j�B���̃f�[�^�ɂ́A�����ʁix�j�Ƃ��āu�T�[�r�X���p�v���A�^�[�Q�b�g�iy�j�Ƃ��āu�p���i0�j�^�މ�i1�j�v�̃��x�����܂܂�Ă��܂��B
�@����́A�}6�ɕ`���ꂽ�S�Ă̓_�Ɂg�ł����Ă͂܂肪�悢�Ȑ��h�����������ł��ˁB�����ŁA�܂��͓K���ɉ��̗\���Ȑ��������Ă݂܂��B
�@�O�f�̐}5�ł����������悤�ɁA���W�X�e�B�b�N��A�̗\���Ȑ���`���ɂ́A
�Ƃ����A2�X�e�b�v�̌v�Z���K�v�ł��B
�i1�j���`����
�@�܂��i1�j�̌v�Z�ɂ́A���`�����ilinear combination�j���d�ݕt�����`�a�iweighted linear sum�j�ƌĂ����@��p���܂��B��̓I�ɂ́A�ؕЂ��p�����[�^�[��0�A�T�[�r�X���p�ix�j�ɑ���W���i�����̌X���j���p�����[�^�[��1�ƒu���ƁA�����͈ȉ��̂悤�ɂȂ�܂��i�����`��A�Ɠ������j�B
�@�Ƃ���ŁA���Ɏ��������̒��ɁA���w�L���̃l�C�s�A��e�i���I�C���[���A���R�ΐ��̒�j���o�Ă��܂����A������e���g���Ɓu���������₷���i���X�����v�Z���₷���j�v�A�܂�u�p�����[�^�[�œK���̌v�Z�����₷���v�Ƃ��������b�g�����邽�߂ɍ̗p����Ă���A�ƒm���Ă����A�d�g�݂𗝉�����ɂ͏\���ł��B
�i2�j���W�X�e�B�b�N��
�@���Ɂi2�j�̌v�Z�ɂ́A���W�X�e�B�b�N���iLogistic function�A�����ɂ��W�����W�X�e�B�b�N���j�ƌĂ����@��p���܂��B��̓I�ɂ͈ȉ��̐����ɂ��A��قǌv�Z�������`�����̌��ʁiz�j�ɑ���\���m���iy�j�����߂�v�Z�ɂȂ�܂��B
�@���̊��ɂ��A���`�����ɂ��u�����v�́A�uS���^�̋Ȑ��v�ɕϊ�����܂��i�}7�j�BS���^�i���V�O���C�h�j�ɂȂ邱�Ƃ���A���W�X�e�B�b�N�����V�O���C�h���iSigmoid function�j�Ƃ��Ă�܂��i�����Ȃ݂ɁA�j���[�����l�b�g���[�N�ł͂��̌Ăѕ����嗬�ł��j�B
�@����ł͂Ȃ��A�u�����v���uS���^�̋Ȑ��v�ɕς���̂ł��傤���H�@�}7�̃O���t�����Ȃ���A�����l���Ă݂Ă��������B
�@���R�́A�u�����v���Əc���̒l�͈̔͂������i�\���`���j�ɂȂ��Ă��܂�����ł��B����A�uS���^�̋Ȑ��v�Ȃ�c���̒l�͈̔͂�0.0�`1.0�Ɏ��܂�܂��B�܂�0�`100�����m���iprobability�j�Ƃ��Ĉ�����̂ł��B�m���Ȃ�u�p�����^�މ�v�̂悤�Ȕ��ʂɃs�b�^���ł��ˁB
�@�v����ɁA�u�����l���m���l�ɕϊ����邱�Ɓv�����W�X�e�B�b�N���̖����ł��B
���̗\���Ȑ�
�@���āA�ȏ��2�̐�����g�ݍ��킹��ƁA���̂悤�Ȑ����ɂ܂Ƃ߂��܂��B�ȉ��ł͂��̌`�Ŏg���Ă������Ƃɂ��܂��B
�@����͐}���Ő������邽�߂ɁA�e�p�����[�^�[�ɑ��鉼�̏����l��ݒ肵�܂��B���̏����l�͂����܂Łu���v�Ȃ̂ŁA�D���Ɍ��߂č\���܂���B�����ł���0�̏����l���|5.0�A��1�̏����l��0.5�Ƃ��܂��傤�B
�@����ɂ��A
�Ƃ��������̗\���Ȑ��ɂȂ�܂��B�}8�ɁA���̋Ȑ���`���Ă݂܂����B
�@�}8�ł́u���̗\���Ȑ����A���ۂ̃f�[�^����ǂꂭ�炢�Y���Ă��邩�v�ɒ��ڂ��Ă��������B���̏ꍇ���Y���Ƃ́A�u�e�f�[�^�|�C���g�v�Ɓu���̗\���Ȑ��i�����W�X�e�B�b�N��A���f���j�v�̊Ԃ̋����̂悤�Ȃ��̂ł��B�����ɂ͋����ł͂Ȃ��̂ł����i�ڍ�q�j�A�}8�ɂ͎Q�l�C���[�W�Ƃ��āu�Y���̖��v��`���Ă݂܂����i���̗\���Ȑ����ƁA���p�����Ȃ��قǁA�މ�Ȃ����ƂɂȂ��Ă��܂��Ă��܂��j�B
�@�f�^�����ȏ����l�������̂ŁA�f�[�^�ƋȐ����S���t�B�b�g���Ă��܂���ˁB���W�X�e�B�b�N��A�ł́A������œK�ȋȐ��Ɏ����I�ɒ������悤�Ƃ����킯�ł��B
�@���`��A�ł́A����l�i���e�f�[�^�̃^�[�Q�b�g�j�Ɨ\���l�i�����f���̏o�͒l�j�Ƃ��������l���m�̈����Z�����ŁA�ȒP�Ɂu�����v���v�Z�ł��܂����B
�@����A���W�X�e�B�b�N��A�ł́A����l�i�������ł́u�p���i0�j���^�މ�i1�j���v�̐������x���j�ƁA�\���l�i�������ł͑މ��m���j�́u�Y���v���v�Z���܂����A�����̒l�͊m���l�i�����P�ʂɉ��H���ꂽ�l�j�ł��邽�߁A�P���Ɉ����Z���Ă��������u�����v�ɂ͂Ȃ�܂���B
�����z�b�g�\��
�@�u�����A�p���i0�j���^�މ�i1�j���A�����P�ʂ́g�m���h�Ȃ́H�v�Ǝv������������܂���B�����������J�e�S���[�l�́A�u�p���v���������A�u�މ�v���������H�A�Ƃ���2���ڂɕ�����ƁA���ꂼ����g�m���h�Ƃ��Ĉ����܂��B
�@���Ȃ݂ɁA�Ⴆ�u�x��v���������A��������Ȃǂ���3���ڈȏ�ɑ��₷���Ƃ��\�ł��i�����N���X���ނ̏ꍇ�j�B
�@�Ⴆ�ΐ���l��1�Ȃ�A�p����0���A�މ���100���ɂȂ�܂��B����l��0�Ȃ�A�p����100���A�މ���0���ł��ˁB�p�[�Z���g�𐔒l�ŕ\�������0����0.0�A100����1.0�ł��̂ŁA�^�[�Q�b�g�ƂȂ镡���̍��ڂ̂����A������1���ڂ�����1�ŁA�c��S�Ă̍��ڂ�0�ɂȂ�܂��B
�@����l��1�ɂ܂Ƃ߂Đ��w�I�Ƀx�N�g���ŏ����ƁA�p����[0, 1]��A�މ���[1, 0]�Ə����܂��B���̂悤�ȏ������́A�����z�b�g�ione-hot�j�\���ƌĂ�܂��B�܂��A���̂悤�ɕϊ����邱�Ƃ������z�b�g�G���R�[�f�B���O�ƌĂт܂��B
�m�����z�̃Y��
�@�����āA[1, 0]��[0, 1]���m�����z�ƌ��Ȃ��܂��B�}9�́A����f�[�^�|�C���g�̐���l���u�p���v�Ɓu�މ�v��2�̖_�O���t�ŕ\�����邱�ƂŁA�m�����z�̃O���t�ƂȂ��Ă��܂��B���l�ɁA���̃f�[�^����͂����ۂ̃��f���ɂ��\���l���m�����z�Ƃ��ĕ\���ł��܂��B
�@�}9�̉��ɂ���p�i�m���Fprobability�́gp�h�j�́A�u�މ�m���v��\���܂��B�t�Ɂu�p���m���v�́A100���i��1.00�j����މ�m���ip�j�������悢�̂ŁA1�|p�ɂȂ�܂��ˁi�������2�̕ϐ��́A��q�̐����Ŋ��p����܂��j�B
�@���̂悤�ɍl���邱�ƂŁA�e�f�[�^�ɑ��āu�������x���̊m�����z�v�Ɓu���f���o�͂̊m�����z�v�̃Y���i���s��v�j���v�Z����悭�Ȃ�܂��B���̌v�Z���@���A�����G���g���s�[�iCross-entropy�A�N���X�G���g���s�[�j�Ƃ������ł��B�u�����G���g���s�[�����iLoss�j�v��u�����G���g���s�[�덷�iError�j�v�Ƃ��Ă�܂��B
�@���`��A�ł́A�u�c���v�ƌĂ��Y���̍��v�l���v�Z���邽�߂�RSS�i�c���̓��a�j�Ƃ��������g���܂������A�����G���g���s�[�͂��̃��W�X�e�B�b�N��A�ł��ƍl����ƕ�����₷���ł��傤�B
�@�����G���g���s�[�́A�m�����z�̃Y�������R�ΐ���p���Đ��l�����܂��B���̐����́A�^�X�N���u��l���ށiBinary Classification�j�v���u���N���X���ށiMulti-class Classification�j�v���ŏ����قȂ�܂��B�����ł͓�l���ރ^�X�N�������Ă��邽�߁A��l���ޗp�̐������Љ�܂��B���N���X���ޗp�͂��ƂŏЉ�܂��B
��l���ޗp�̌����G���g���s�[
�@�ȉ��̐����ł́An�̓f�[�^���ii�͂��̉��Ԗڂ��j�Alog�͎��R�ΐ��i��ln�A�܂�l�C�s�A��e���Ƃ���ΐ��j�A���͑��a��\���܂��B���̐������u�������Ă��邩�v�̈Ӗ��͂��ƂŐ�������̂ŁA�����͂����ƌ��邾���ō\���܂���B
�@���̐������{�̉ӏ��ō��E�ɕ�����܂��B�{�̍����ł�p�i�����ł͑މ�m���j�̃Y�����A�E���ł�1�|p�i�����ł͌p���m���j�̃Y�����v�Z���Ă��܂��B���E�ǂ�����u�������މ�i1�j���^�p���i0�j���v�ɉ����āA�����Ɨ\���̃Y�����v�Z������e�ɂȂ��Ă��܂��̂ŁA���������������܂��B
�@����������li�Ԗ� �~ ���R�ΐ�(�\���li�Ԗ�)�Ƃ����v�Z�ɒ��ڂ��Ă��������B����li�Ԗ���0�̏ꍇ�A0�ɉ����|���Z���Ă����ʂ�0�ɂȂ�܂���ˁB
�@����li�Ԗ���1�̏ꍇ�A�\���li�Ԗ���1.0�Ȃ�A���R�ΐ��̌v�Z�Ɋ�Â��A���̌��ʂ�0�ł��B���l�̌v�Z�ŁA0.5�Ȃ��|0.7�A0.1�Ȃ��|2.3�ƂȂ�܂��B�܂�A�\�����Ԉ���Ă���قǁi���Y�����傫���Ȃ�قǁj�A���ʂ̐��l���}�C�i�X�����ɑ傫���Ȃ�܂��B���Ȃ݂ɁA�����̐擪���|�i�}�C�i�X�j���t���Ă���̂́A�}�C�i�X�~�}�C�i�X�����Łu�v���X�̒l�v�ɂ��邽�߂ł��B
�@�Ȃ��A�\���li�Ԗ���0.0��������1.0�̏ꍇ�A���w�I�Ɍv�Z���s�\�ȁulog(0)�̌v�Z�v���������邽�ߔ����Ȃ���Ȃ�܂���B���̂��߁Ascikit-learn�Ȃǂ̃��C�u�����ł́A�\���li�Ԗ���0.0��1.0�ɂȂ�Ȃ��悤�ɁA���ɏ����Ȓl�iepsilon�j��p���āA���l��[epsilon, 1�|epsilon]�͈̔͂ɐ����iclip�j���Ă��܂��B����ɂ��Alog()���̓��͂���ɗL���Ȕ͈͂Ɏ��܂邽�߁A���S�Ɍv�Z�ł���悤�ɂȂ��Ă��܂��B
�@���̂悤�Ɍv�Z���������ip�j�ƉE���i1�|p�j�A2�N���X���̃Y���𑫂��Z������ŁA�S�f�[�^�������v���ăf�[�^���Ŋ��邱�Ƃ��������Ă���A�Ƃ����̂��u��l���ޗp�̌����G���g���s�[�̐����v�̈Ӗ��ł��B
�@����ɂ��u�Y���̕��ϒl�v�����܂�܂��i�P�Ɂu�����v��u�덷�v�Ƃ��Ă�܂��j�B���̑����l���������قǁu�f�[�^�ɓ��Ă͂܂�̂悢�i���t�B�b�g����j�Ȑ��v�ł��邱�Ƃ�\���܂��B�܂胍�W�X�e�B�b�N��A���f���̗\�����x�������Ƃ������Ƃł��B
�@�Ȃ��A�\���li�Ԗ��̕����ɂ́A�O�q�������W�X�e�B�b�N���i�������ȉ��ɍČf�j���������܂��B�������A���ۂɑ�����������͏������G�ɂȂ����C���ɂȂ�̂Łi��j�A�����ďȗ����܂��B
�@���̃��W�X�e�B�b�N���̏o�͂��g�����u�����G���g���s�[�v�̐������g���āA�p�����[�^�[��0�i�ؕЁj����1�i�T�[�r�X���p�ɑ���W���j�����߂���@�����Ă����܂��傤�B���W�X�e�B�b�N��A�̖ڕW�́A�Y���i�������G���g���s�[�j���ł��邾���������Ȃ�悤�ȁA�œK�ȃp�����[�^�[�������邱�Ƃł��B
�@�œK�ȃp�����[�^�[�̋��ߕ��́A��{�I�ɂ͐��`��A��RSS�i�c���̓��a�j�̍ŏ����Ɠ����l�����ł��B��̓I�ɂ́A�}10�Ɏ����Ȑ��̒J���������C���[�W�ł��B
�@��ԒJ��̕������A�����G���g���s�[�̌v�Z�l���ł��������Ȃ�u�œK�ȃp�����[�^�[�v�ł��i�������G���g���s�[�̍ŏ����j�B
�@�}10���������Ɍ���ƁA�u�Y���̒��x�v�i�������G���g���s�[�j���ǂꂾ���傫������������܂��B�u�Y���i���s��v�j�v�̐^�t�̊T�O�́u��v�v�Ȃ̂ŁA�t�̎��_�ŏォ�牺�Ɍ���ƁA�u��v�̒��x�v���ǂꂾ���傫������������܂���ˁB
�@���́u��v�̒��x�v�́A�u�ށi�����Ɓj���炵���v�Ƃ����Ӗ����ޓx�i�䂤�ǁALikelihood�j��ϊ��������l�ł��B�u�����G���g���s�[�̍ŏ����v���u�ޓx�̍ő剻�v�ƂȂ�̂ŁA���W�X�e�B�b�N��A�ɂ�����p�����[�^�[����̎�@�́u�Ŗސ���v�ƌĂ��̂ł��B�Ŗސ���ɂ��ẮA���炽�߂Č�q�̃R�����ŐG��܂��B
�@���W�X�e�B�b�N��A�̏ꍇ�A���`��A�̂悤�ɍœK�ȃp�����[�^�[���u���w�̌������g���Ĉꔭ�ŋ��߂�v�i����͓I�ɉ����j�Ƃ������@���g���܂���B���W�X�e�B�b�N���Ƃ�������`�̕ϊ�������������߁A�Ȑ���Ȗʂ͎R��J���������悤�Ȍ`�Ŕg�ł��Ă���A�J����ꔭ�Ōv�Z����ƋǏ��I�ȒJ��i���Ǐ����j�ɛƁi�́j�܂��ĊԈ�����l�ɂȂ�\�������邩��ł��B
���z�~���@
�@���W�X�e�B�b�N��A�ł́A�f�[�^���ƂɁu�Ȑ��ɑ���ڐ��̌X���v�i�����z�FGradient�ƌĂ��j���v�Z���Ē~�ς��A���̌��z�̍��v����J��̏ꏊ�i���œK���j��T���Ă����܂��B���z�Ƃ́u�⓹�v�̂��ƂŁA�܂�{�[���𓊂��č⓹��]�����C���[�W�ł��i�}11�j�B���̍œK����@�́A���z�~���@�iGradient Descent�j�ƌĂ�܂��B
�@���z�~���@�ɂ́A�f�[�^�S�̂��g���o�b�`���z�~���@��A������x�̂܂Ƃ܂育�Ƃ̃f�[�^���g���~�j�o�b�`���z�~���@�Ȃǂ�����܂��B�j���[�����l�b�g���[�N�Ɠ����Ȃ̂Łi�Q�l�L���j�A�����ł͏ڍׂ��������܂��B
�@���z�~���@�́A�œK���A���S���Y���̈�ɉ߂��܂���Bscikit-learn�Ȃǂ̃��C�u�����ł́A���W�X�e�B�b�N��A�ŔC�ӂ̍œK���A���S���Y����I���ł��܂��B��������g���ꍇ���A�œK�ȃp�����[�^�[��0�i�ؕЁj����1�i�T�[�r�X���p�ɑ���W���j�����܂�܂��B
�@�œK���A���S���Y���ł́A�u�P���i�w�K�j������J��Ԃ����v���Ӗ������C�e���[�V�������iiteration�j�����߂āA���̉����J���T���čœK���̓x���������߂邱�Ƃ��ł��܂��B�܂��A�u1��̃C�e���[�V�����Ŋw�ԃX�s�[�h�v���Ӗ������w�K���ilearning-rate�j�����߂�ꍇ������܂����Ascikit-learn�Ń��W�X�e�B�b�N��A����ꍇ�͓����I�Ɏ�����������邽�߁A�ʏ�͎w��ł��܂���B
�@�}11�́A���z�~���@�ɂ��ŏ������i�ޗl�q�̃C���[�W�����������̂ł��B��{�I�ɁA�ŏ��̓{�[�����J��Ɍ����č�̋}���z��傫���]���藎���A�J��ɋ߂Â����X�ɍ�̌��z���ɂ₩�ɂȂ�ɂ�Ă������Ɠ]����悤�ɂȂ��Ă����A�ŏI�I�ɒJ�̒�i�ŏ��l�j�ɂ��ǂ蒅���Ƃ�������ł��B
�@���̂悤�ɂ��Ċe�p�����[�^�[�̍œK�l�����߂�ƁA�茳�ł̌v�Z��ł���0��7.48�A��1���|0.74�Ƌ��܂�܂����B�O�f�̐}5�Ə����p�����[�^�[�l���قȂ�܂����A����͎g�p�����œK���A���S���Y�����قȂ邩��ł��i���}5�ł�scikit-learn�̃f�t�H���g���g���܂������A�����ł͌��z�~���@�Ŏ蓮�v�Z���܂����B�Q�l�F�T���v���m�[�g�u�b�N�j�B�p�����[�^�[�l�́A�œK���A���S���Y���ɉ����g�����ŕς���Ă���̂Œ��ӂ��Ă��������B
�@�ȏ�ŁA�����G���g���s�[���ŏ��ƂȂ�œK�ȃp�����[�^�[��0����1���v�Z�ł����̂ŁA������p���čŏI�I�ȃ��W�X�e�B�b�N��A���f���i�����ł͗\���Ȑ��j�����肵�܂��B�܂����`�����̐����͈ȉ��̂悤�ɂȂ�܂��B
�@����z�����W�X�e�B�b�N���ɑ������ƁA�ȉ��̐����ɂȂ�܂��B
�@���̐����̗\���Ȑ����U�z�}��ɕ`�悷��Ɛ}12�̂悤�ɂȂ�܂��B
�@�ȏ�̂悤�ɍŖސ���́A�P���Z�b�g�ɍł��K�������W�X�e�B�b�N��A���f���i�\���Ȑ��^���ʁ^�����ʁj�������邽�߂̌v�Z���@�Ƃ����킯�ł��B
�@��قǂ����������悤�ɁA�u�Y���̒��x���ŏ������邱�Ɓv�́u��v�̒��x�i���ޓx�j���ő剻���邱�Ɓv�Ɠ����Ӗ��ɂȂ�܂��B���W�X�e�B�b�N��A�̍œK����@�́A���́u�ޓx�̍ő剻�v�̎��_����u�Ŗސ����iMaximum Likelihood Estimation�FMLE�j�v�ƌĂ�܂��B
�@�l�����̓V���v���ŁA�u���݂̃��f���i�\���Ȑ��j���A�P���Z�b�g���ǂꂾ�������Ƃ��炵�������ł��邩�i���ޓx�j���ő�ɂ��悤�v�Ƃ������̂ł��B�R�^�̃O���t���v�������ׂĂ��������i�}13�j�B���̎R�̒��オ�u�����Ƃ��炵���i�ޓx�j���ő�v�ƂȂ�p�����[�^�[�l�i�̑g�ݍ��킹�j�ł��B
�@����A�����G���g���s�[�́u�Y�����ŏ��ɂ��悤�v�Ƃ������ł����A���̒��g�i�����j�́u���̑ΐ��ޓx�v���̂��̂ł��B�擪�Ƀ}�C�i�X���t���Ă��邽�߁A�O���t�̌`���t���i�R�^���J�^�j�ɂȂ��Č����邾���Ȃ̂ł��i�܂�}10�́A�u���̐}13���t���ɂ��ď����ό`���������́v�Ƃ������܂��j�B
�@�u�����G���g���s�[���ŏ������邱�Ɓv�Ɓu�ޓx���ő剻���邱�Ɓv�́A���w�I�ɂ͑S�������Ӗ��ł��B���_���Ⴄ�����Ȃ̂ŁA�u�Ŗސ���H�@������v�ƍ\����K�v�͂���܂���B
�@�ȏ�Ń��W�X�e�B�b�N��A���f���̊e�p�����[�^�[�����肷��d�g�݂𗝉����܂����B�����Ď��H�Ƃ��āAscikit-learn�ɂ��v���O���~���O��̌����Ă݂܂��傤�B
�@scikit-learn�ɂ́A���W�X�e�B�b�N��A���f�����\�z�ł���LogisticRegression�N���X�isklearn.linear_model���W���[���j������܂��B
�@���X�g1�����̎g�����ł��B���`��A�Ƃقړ����Ȃ̂ŁAfit()���\�b�h�܂ł̐����͊������܂��B�c��2�s�̃��\�b�h�Ăяo���ł́A�P�����ꂽ���W�X�e�B�b�N��A���f�����g���āA�\���́u�m���l�v�Ɓu�ŏI�I�ȗ\�����ʁi0��1�̏o�͒l�j�v���擾���Ă��܂��B
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(���������FX��, ���^�[�Q�b�g�Fy��)
model.predict_proba(���V�����f�[�^��) # �\���l�i���m���l�j���o��
model.predict(���V�����f�[�^��) # �\�����ʁi��0��1���j���o��
�@predict_proba()���\�b�h�ł́A�\���l�Ƃ��āu�m���l�v�i��F�މ�m���j���擾�ł��܂��B���A���̊m���l��0.5�ȉ��Ȃ�0�i��F�p���j�A0.5�����Ȃ�1�i��F�މ�j�̂悤�ɁA�ŏI�I�ȃN���X���x���i0��1���j�����肵�����ł���ˁB�����������U�����ꂽ�\�����ʂ��擾�������ꍇ�ɂ́Apredict()���\�b�h���g���܂��B
�@�������LogisticRegression�N���X�ɂ́A�����ȊO�ɂ����܂��܂ȋ@�\��������Ă��܂��B�ڂ����͌����y�[�W�����Q�Ƃ��������B
�@����ł́A���̃N���X���g���Ď��ۂɃ��W�X�e�B�b�N��A���f�����쐬���A��l���ނ��s���Ă݂܂��傤�B
�@�{�A�ڂ́A��1���Ő��������悤�ɁA�����̃N���E�h���uGoogle Colab�v�̗��p��O��Ƃ��Ă��܂��B��{�I�ɂ́AColab�ŐV�K�m�[�g�u�b�N��������A�ȍ~�Ő�������R�[�h����͂��Ȃ�����s���ʂ������̖ڂŊm���߂Ă��������B���ɓ��͍ς݂̃m�[�g�u�b�N���g�������ꍇ�́A������̃T���v���m�[�g�u�b�N�������p���������B
�@�܂��̓f�[�^�Z�b�g���������܂��B����́Ascikit-learn����ǂݍ��߂�uWine�i���C���j�f�[�^�Z�b�g�v���g���܂��B���̓f�[�^�ƂȂ�����ʂɂ́A���L��13���ڂ�����܂��B����������l�ϐ��i�����l�j�ł���A�J�e�S���J���ϐ��i�J�e�S���[�l�j�͊܂܂�Ă��܂���B
�@�o�͌��ʂƂȂ�^�[�Q�b�g�͈ȉ��̒ʂ�ł��B�����́A3��ނ̈قȂ�i�킩����ꂽ�u���C���̎�ށv��\���N���X���x���i����l�j�̂����A3�ڂ��J�b�g����2��ނɂ��邱�ƂŁA�X�I�ɓ�l���ޗp�̃f�[�^�Z�b�g�Ƃ��ĉ��p�������̂ł��B
�@Wine�f�[�^�Z�b�g�ɂ��Ă��ڂ����m�肽���ꍇ�́A������̋L�����Q�Ƃ��Ă��������B
�@���̃f�[�^�Z�b�g��ǂݍ��ނɂ́Asklearn.datasets.load_wine()�����Ăяo�������ł��B�P���Z�b�g�ƃe�X�g�Z�b�g�ɕ�������܂ł̃R�[�h���ȉ��̃��X�g2�Ɏ����܂��B
from sklearn.datasets import load_wine
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
# �f�[�^�Z�b�g�̓ǂݍ���
wine = load_wine()
# �����ʂƃ^�[�Q�b�g�̎擾
X = wine.data
y = wine.target
# �N���X1�i0�j�ƃN���X2�i1�j�̃f�[�^�����ɍi�荞��
mask = (y == 0) | (y == 1)
X = X[mask]
y = y[mask]
# �f�[�^�̕W����
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# �P���Z�b�g�ƃe�X�g�Z�b�g�ɕ���
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=0)
print(f&#39;�P���Z�b�g�̃T�C�Y: {X_train.shape}&#39;) # ��: �P���Z�b�g�̃T�C�Y: (117, 13)
print(f&#39;�e�X�g�Z�b�g�̃T�C�Y: {X_test.shape}&#39;) # ��: �e�X�g�Z�b�g�̃T�C�Y: (13, 13)
�@�Ȃ��A�����ʊԂ̃X�P�[�����قȂ邽�߁A�O�����Ƃ��Ċe�����ʂ��W�����i�����ς��u0�v�ɁA�W�������u1�v�̃X�P�[���ɕϊ��j���Ă��܂��B
�@���ɁA���悢��LogisticRegression�N���X�isklearn.linear_model���W���[���j���g���ă��W�X�e�B�b�N��A���f�����쐬���A�P�����܂��B���X�g3�͂��̃R�[�h��ł��B
from sklearn.linear_model import LogisticRegression
# ���W�X�e�B�b�N��A���f���̌P��
model = LogisticRegression(solver=&#39;lbfgs&#39;)
model.fit(X_train, y_train)
print(&#39;�W���F&#39;, model.coef_)
print(&#39;�ؕЁF&#39;, model.intercept_)
# �W���F [[-1.50497653 -0.53548103 -0.90018867 1.00264039 -0.31198706 -0.09362577
# -0.28866105 0.2635515 0.25998733 -0.74083219 -0.00681288 -0.62169609
# -1.85070478]]
# �ؕЁF [0.2751988]
�@LogisticRegression�N���X��solver�p�����[�^�[�ɂ́A�œK���A���S���Y���isolver�F�\���o�[�j���w��ł��܂��B���X�g3�ł́A�f�t�H���g�l�Ɠ���&#39;lbfgs&#39;���w�肵�܂����i�ȗ����\�ł����A�����̂��ߖ������Ă��܂��j�B
�@��ȑI�����͈ȉ��̒ʂ�ł��B�e�A���S���Y���̏ڍׂȎd�g�݂ɂ͗�������܂���̂ŁA�����ł͖��̂Ǝg�������̖ڈ����������Ă����܂��傤�B
�@��&#39;sag&#39;��&#39;saga&#39;�̖��O�ɂ���ug�v�iGradient�j�́A��L�́u�ǂ�Ȏd�g�݁H�v�̐����ň������u���z�~���@�iGD�FGradient Descent�j�v�̈��ł��邱�Ƃ������Ă��܂��B
�@�œK���A���S���Y���̐�����ڂ����d�g�݂�m��Ȃ��Ă��A��L�̎w�j���Q�l�Ƀ\���o�[��I�ׂΎ��p��͏\���ł��B���f���̗\�����x�����߂�ۂ́A�قȂ�\���o�[��1�������Ĕ�r���Ă݂Ă��悢�ł��傤�B�������Ƃ��́A�܂�&#39;lbfgs&#39;���g���A�����̏ꍇ���܂������܂��B
�@�����āA���X�g3�̍Ō�ŏo�͂���model.coef_�i�W���j��model.intercept_�i�ؕЁj����A���f���̓�����Ԃ𐔒l�Ŋm�F�ł��܂��ˁB�Ȃ��A���̗�ł́A�W���̐���13�Ƒ������߁A�������̃O���t�ƂȂ�}���ł��܂��A�W����1�ł���A�O�f�́u�}3�@���W�X�e�B�b�N��A���f���̗\���Ȑ��̗�v�̂悤�ɐ}���ł��܂��B
�@���ɁA���X�g4�͂��̃��f�����g���ăe�X�g�Z�b�g����u���C���̃N���X�i0��1���j�v��\������R�[�h��ł��B
# �e�X�g�Z�b�g��p���ĕ��ޗ\���i�\�����ʂƊm���l�̎擾�j
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)
# �擪5���̗\�����ʂƁA���̗\���m���l��\��
print(f&#39;���ۂ̃N���X�i�擪5���j:{y_test[:5]}&#39;)
print(f&#39;�\�����ʁi�擪5���j:{y_pred[:5]}&#39;)
print(&#39;---&#39;)
print(f&#39;�\���m���l�i�擪5���j:\n{y_proba[:5]}&#39;)
# ���ۂ̃N���X�i�擪5���j:[0 1 1 1 1]
# �\�����ʁi�擪5���j:[0 1 1 1 1]
# ---
# �\���m���l�i�擪5���j:
# [[0.99578134 0.00421866]
# [0.00122679 0.99877321]
# [0.0013692 0.9986308 ]
# [0.02719697 0.97280303]
# [0.00682272 0.99317728]]
�@�\�����ʁi��predict()���\�b�h�œ�����N���X���x���j�ƁA���ۂ̃N���X�i���e�X�g�Z�b�g�̐������x���j���r�ł���悤�ɏo�͂��Ă��܂��B�擪��5���͑S�Đ������Ă���A���𗦂�100���ł����B����ł́A�e�X�g�Z�b�g�S�̂ł̐��𗦂͂ǂ̒��x�Ȃ̂ł��傤���H�@�]�����Ă݂܂��傤�B
�@���X�g5�́A�P���ς݂̃��W�X�e�B�b�N��A���f�����g���āA�e�X�g�Z�b�g�S�̂ɑ��镪�ރ��f���̐��\��]������R�[�h��ł��B���ރ^�X�N�ł́u���𗦁v���悭�g���܂����A���̃R�[�h�ł́u�K�����v�u�Č����v�uF1�X�R�A�v�ȂǁA���𗦂Ƃ͈قȂ�ϓ_�̕]���w�W�������ă`�F�b�N���Ă��܂��i�����̕]���w�W�͌�قǊȒP�ɐ������܂��j�B
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# �\�����ʁiy_pred�j�Ɛ������x���iy_test�j���r���āA�e�]���w�W���Z�o
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
# ���ʂ��o��
print(f&#39;���𗦁iAccuracy�j: {acc:.2f}&#39;)
print(f&#39;�K�����iPrecision�j: {prec:.2f}&#39;)
print(f&#39;�Č����iRecall�j: {rec:.2f}&#39;)
print(f&#39;F1�X�R�A�iF1 Score�j: {f1:.2f}&#39;)
# ���𗦁iAccuracy�j: 1.00
# �K�����iPrecision�j: 1.00
# �Č����iRecall�j: 1.00
# F1�X�R�A�iF1 Score�j: 1.00
�@���X�g5�ł́A�e�X�g�Z�b�g�S�̂ł��u�S�Ă̕]���w�W��1.00�i��100���j�̐��\�ł��邱�Ɓv���m�F�ł��܂����B���ɗD�G�ȕ��ރ��f���ł��ˁB�������́A����̃f�[�^�Z�b�g�ł̕��ރ^�X�N�́A�ȒP�߂����̂�������܂���B
�@���ރ��f���̕]���ł́A�u���𗦂��������Ĉ��S���Ȃ��v���Ƃ���ł��B
�@�Ⴆ�A�������x����1�i���z���FPositive�j�ł���f�[�^��100�����킸��2�������Ȃ��ꍇ�A�S�Ă�0�i���A���FNegative�j�Ɨ\�����邾���ŁA���𗦂�98���ɂȂ�܂��B��������͍����\�Ɍ����Ă��A�d�v�ȃN���X�i���̏ꍇ���z���j����x�����o�ł��Ȃ��A���ɕ������f���ɂȂ��Ă���\��������̂ł��B
�@�����z�����u�a�C����v��\���Ȃ�A�S�Ă��u�a�C�Ȃ��v�Ɣ��肷��̂́A�댯�ȃ��f���ł���ˁB���̂悤�ȕ���������Ȃ����߂ɁA���𗦂����łȂ��A�Č����A�K�����AF1�X�R�A�ȂǕ����̕]���w�W���Ċm�F����̂������߂ł��B
�@����ł́A���X�g5�Ŏg�����]���w�W�ɂ��ĊȒP�ɂ܂Ƃ߂܂��B���w�҂��������Ă��������d�v�Ȏw�W�ł����A������v�Z���@�͏ȗ�����̂ŁA�K�v�ɉ����Ċe���ڂ̃����N����Q�Ƃ��Ă��������B���ꂼ�ꏭ��������Ă��Ċo���ɂ�����������܂��A�g�����тɈȉ��̓��e�����x�����Ԃ��Ă݂�Ƃ悢�ł��傤�B
�@�ȏ�ŁA���W�X�e�B�b�N��A�ɂ���l���ނ̊�b����������@�܂ł��w�т܂����B���́y���W�z�Ƃ��āA����N���X���ނɊg�������u�\�t�g�}�b�N�X��A�i�������W�X�e�B�b�N��A�j�v���Љ�܂��B�������Ă�����������܂��A�����܂ł̒m�������p����X���[�Y�ɗ����ł��܂��B�����ŗ����~�܂�̂͂��������Ȃ��̂ŁA���Ђ��̗���̂܂܍Ō�܂Ŋw�ѐ��Ă��܂��܂��傤�I
�@�����܂ŏЉ�Ă������W�X�e�B�b�N��A�́A2�N���X�̕��ނɎg���邽�߁A�u���ibinary�j���W�X�e�B�b�N��A�v�Ƃ��Ă�܂��B����ɑ��āA3�N���X�ȏ�̑��N���X�ނ����@�́A�u�����imultinomial�j���W�X�e�B�b�N��A�v�ƌĂ�邱�Ƃ�����܂��B
�@���̑�\�I�Ȏ�@���A�\�t�g�}�b�N�X��A�iSoftmax Regression�j�ł��B���W�X�e�B�b�N��A�Ɗ�{�I�Ȏd�g�݂͓����ł����A�ȉ���2�̓_�������u�������܂��B
�@�܂�A����2�_���������邾���ŁA�\�t�g�}�b�N�X��A�������ł����Ⴄ�Ƃ������ƁB�����ł��������撣������f�R�����ł���ˁI
�@�����Ȃ݂ɁA���݂�scikit-learn��LogisticRegression�N���X�ł́A���N���X���ނ��s���Ǝ����I�Ɂu�����imultinomial�j���\�t�g�}�b�N�X��A�v�������K�p����܂��B�������A�O�q�̍œK���A���S���Y���ł��G�ꂽ�悤�ɁA&#39;liblinear&#39;�\���o�[���g���ꍇ�̂݁A�u1���̑��iovr�Fone-vs-rest�j�v�����ɂȂ�܂��B���̕����ł́A�e�N���X�ɂ��Čʂɓ��W�X�e�B�b�N��A�����s���邽�߁A�\�t�g�}�b�N�X��A����������ɂȂ�₷���_�ɒ��ӂ��Ă��������B
�@����ł́A�u�u������������v�Ɓu�ς��Ȃ��l�����v�ɒ��ڂ��Ȃ���A���W�X�e�B�b�N��A�Ɠ�������ɉ����āA�\�t�g�}�b�N�X��A�̎d�g�݂�������Ă����܂��B�Ȃ��A�d�����镔���͏ȗ����A�v�_�ɍi���ďЉ�܂��B
�@�\�t�g�}�b�N�X��A�̎d�g�݂ł��A�܂��͉��̃��f�����쐬���܂��B���̃��f���́A���`�����ƃ��W�X�e�B�b�N����g�ݍ��킹�����ł����B���́u���W�X�e�B�b�N���v���u�\�t�g�}�b�N�X���v�ɒu�������܂��B
�\�t�g�}�b�N�X��
�@���W�X�e�B�b�N���ł́A�u�N���X1�i��0�j�v�̋t���u�N���X2�i��1�j�v�Ȃ̂ŁA1�̊���2�N���X���̊m����\���ł��܂����B�ł�3�N���X�ȏ�ł́A�����͂����܂���B
�@�\�t�g�}�b�N�X���iSoftmax function�j�ł́A�N���X���ƂɊm�����v�Z����K�v������܂��B�Ⴆ��3�N���X�Ȃ�A�u�N���X1�iy1�j�v�u�N���X2�iy2�j�v�u�N���X3�iy3�j�v�Ƃ���3�̗\���m���iyj�j�����߂܂��B��j�̓N���X�ԍ��i1�`3�Ȃǁj�ł��B
�@���̌v�Z���A�܂�e�N���X�ɑ�����`�����̌��ʁizj�j����\���m���iyj�j�����߂鐔���͈ȉ��̂悤�ɂȂ�܂��B��m�̓N���X���ł��Bk�̓N���X�ԍ��i1�`3�Ȃǁj�ł����A����̑��a�i���j�ł͑S�N���X��ΏۂƂ��邽�߁A�Ak��j�Ƃ͕ʂ̃N���X�ԍ��Ƃ��Ďg���Ă��܂��B
�@�ĂсA�l�C�s�A��e���o�ꂵ�܂����ˁB����́A���z�i�������j�̌v�Z�����₷�����邽�߂ł����B
�@������������Ȃ��Ă��C�ɂ��Ȃ��đ��v�ł��B���W�X�e�B�b�N���Ɠ����悤�ɁA�u�N���X���Ƃ̊m�����o���Ă���v�\�\���̈Ӗ��������߂Ă����OK�ł��B
�@���ɁA�������x���i���u�N���X1���^2���^3���v�j�ƁA�\���l�i���e�N���X�̗\���m���j�́g�Y���h���v�Z���܂��B�������x���́A�����z�b�g�\���ɂ��邱�ƂŊm�����z�ƌ��Ȃ��܂��B�\���l���A�N���X���Ƃ̗\���m���iyj�j���x�N�g���ɑS�Ă܂Ƃ߂�A�m�����z�ɂȂ�܂��B����ŁA2�̊m�����z�́g�Y���h�������悤�ɂȂ�܂��ˁB
�m�����z�̃Y��
�@�O�̂��߁A�N���X��3����ꍇ�̊m�����z�O���t�������܂��i�}14�j�B���W�X�e�B�b�N��A�̏ꍇ�Ƃقړ����ŁA�_��1�{�����������ł��B
�@�m�����z�̃Y���́A�����G���g���s�[�Ő��l���ł��܂����B�������A���̐����́A�^�X�N���u��l���ށv���u���N���X���ށv���ŏ����قȂ�̂ŁA�����ő��N���X���ޗp�̐������Љ�܂��B
�@�Ƃ����Ă��A��l���ޗp�Ƒ��N���X���ޗp�ŁA����Ă��邱�Ƃ͓����ł��B�����̌����ڂ͈���Ă��A�u�ǂ�����Y���𑪂鎮�Ȃv�Ǝv���Ă�����OK�ł��B
���N���X���ޗp�̃N���X�G���g���s�[
�@�ȉ��̐����ł́An�̓f�[�^���ii�͂��̉��Ԗڂ��j�Am�̓N���X���ik�͂��̃N���X�ԍ��j�Alog�͎��R�ΐ��i��ln�A��̓l�C�s�A��e�j�A���͑��a��\���܂��B
�@��l���ޗp�ł́A�u�{�̉ӏ��ō��E�ɕ������v�Ɛ������܂����B���N���X���ނł́A���ꂪ�u���a���ɂ���āA�N���X�̐������{�����v�Ƃ��������ɂȂ�܂��B�܂�A�����{�̌J��Ԃ��ƌ��Ȃ��A����Ă��邱�Ƃ͓�l���ނƓ����Ƃ����킯�ł��B
�@�Y�����v�Z�ł�����A���Ƃ͌��z�~���@�Ȃǂ̍œK���A���S���Y�����g���āA�œK�ȃp�����[�^�[�����߂邾���ł��B����ŁA���f���͊����ł��B
�@�ȏオ�\�t�g�}�b�N�X��A�̎d�g�݂ł��B���W�X�e�B�b�N��A����������w���炱���A�\�t�g�}�b�N�X��A�̗����͂��ȒP�������̂ł͂Ȃ��ł��傤���B
�@�Ō�ɁA�v���O���~���O��̈Ⴂ�ɂ��Ă��G��Ă����܂��傤�B�Ƃ����Ă��A�قƂ�ǈႢ�͂���܂���B�|�C���g�͎���2�����ł��B
�@�S�̓I�ȃR�[�h���e�́A���W�X�e�B�b�N��A�Ƃقړ����ɂȂ邽�߁A�S�̂̌f�ڂ͏ȗ����A�قȂ镔�����������グ�܂��B�R�[�h�����s���Ă݂������́A�T���v���m�[�g�u�b�N�������p���������B
�i1�j3�ȏ�̃N���X�ւ̑Ή�
�@�����ł́A�f�[�^�Z�b�g�Ɋ܂܂��S�ẴN���X���g�p���܂��B��قǂ́u�N���X3�v�����O���Ă����̂ŁA���炽�߂ă^�[�Q�b�g�ƂȂ鐳�����x�����ȉ��Ɏ����Ă����܂��B
�@�O�f�́u���X�g2�@Wine�f�[�^�Z�b�g��ǂݍ��݃R�[�h��v�ł́Amask�ɂ���Ă킴�킴�u�N���X3�v�����O���Ă��܂������A���̏������s�v�ł��B�����ł͑S�ẴN���X���g�p���邽�߁A�ȉ��̂悤�ɊY���̃R�[�h���R�����g�A�E�g���Ă��������B
# �i�荞�ނ��������đS�ẴN���X���g�p
# mask = (y == 0) | (y == 1)
# X = X[mask]
# y = y[mask]
�@���̕ύX�����ŁA���f���̌P����\���̃R�[�h�͂��̂܂g���܂��B
�i2�j�����N���X�̕]���X�R�A�ɑΉ�
�@�Ō�̕]���p�̃R�[�h���قڂ��̂܂g���܂����A�ق�̏�����������������K�v������܂��B
�@�Ƃ����̂��A���N���X���ނ̕]���w�W�ł���K�����^�Č����^F1�X�R�A�́A�N���X���Ƃɕ]���l�i�X�R�A�j���v�Z���邽�߁A�����ρiaverage�j���čŏI�I�ȕ]���l�����߂�K�v�����邩��ł��B
�@���̍�Ƃ͊ȒP�ŁA�e�]������average=&#39;macro&#39;�Ƃ���������ǉ����邾���ł��B���X�g7�̑����������m�F���Ă��������B
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# �\�����ʁiy_pred�j�Ɛ������x���iy_test�j���r���āA�e�]���w�W���Z�o
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, average=&#39;macro&#39;)
rec = recall_score(y_test, y_pred, average=&#39;macro&#39;)
f1 = f1_score(y_test, y_pred, average=&#39;macro&#39;)
# ���ʂ��o��
print(f&#39;���𗦁iAccuracy�j: {acc:.2f}&#39;)
print(f&#39;�K�����iPrecision�j: {prec:.2f}&#39;)
print(f&#39;�Č����iRecall�j: {rec:.2f}&#39;)
print(f&#39;F1�X�R�A�iF1 Score�j: {f1:.2f}&#39;)
# ���𗦁iAccuracy�j: 1.00
# �K�����iPrecision�j: 1.00
# �Č����iRecall�j: 1.00
# F1�X�R�A�iF1 Score�j: 1.00
�@���Ȃ݂ɐ��𗦁iAccuracy�j�́A���Ƃ��ƑS�N���X���܂Ƃ߂ĕ]������w�W�Ȃ̂ŁAaverage=&#39;macro&#39;�̎w��͕s�v�ł��i���������w��ł��܂���j�B
�@�K�����^�Č����^F1�X�R�A���v�Z������̈���average�ɂ́A����̎w��l������܂��B���ꂼ��̈Ӗ���g�������w�j�A�����b�g�ƃf�����b�g���ȉ��ɊȌ��ɂ܂Ƃ߂܂��B
�@�ʏ�́A���X�g7�̂悤��average=&#39;macro&#39;���w�肷��̂�����ł��B�������A�f�[�^�Z�b�g�ɃN���X�s�ύt������ꍇ�́A���𗦂�}�C�N�����ς����ł͕s�\���Ȃ��Ƃ�����܂��B�}�N�����ς���d���ς������Ċm�F���邱�ƂŁA�������Ŏ��Ԃɑ������]�����\�ɂȂ�܂��B
�@����́APython�ɂ�郍�W�X�e�B�b�N��A�i�ƃ\�t�g�}�b�N�X��A�j�̊T�v�Ǝd�g�݁A��{�I�ȃv���O���~���O��������܂����B�m����蒅�����邽�߂ɁA�]�T������A�����̎��͎���������Ă݂Ă��������B
�@����́A���ރ^�X�N�̎�@�Ƃ��Č����������܂��B���y���݂ɁB
�@�I�����W�F�̕������N���b�N�܂��̓^�b�v����Ɠ������\������܂��B�q���g���~�����ꍇ�́A�ΐF�̕������N���b�N���Ă��������B�����ߖ��Ɏg����I�������\������܂��B
�@���W�X�e�B�b�N��A�́A���̓f�[�^�Əo�͌��ʂ̊W���u���`�����ƃ��W�X�e�B�b�N���v�ɂ���ă��f�������A0��1����l���ނ��s����@�ł��Bscikit-learn�ł́ALogisticRegression�N���X���g���Ď����ł��܂��B
�@���W�X�e�B�b�N���́A������S���^�̋Ȑ��ɕϊ����邱�ƂŁA0.0�`1.0���m���l���o�͂��܂��B���̒l�ɑ���0.5�Ȃǂ�臒l�i���������j��ݒ肵�A�ǂ���̃N���X�ɕ��ނ��邩�f���܂��B�O���t��ł��̋��E���������́A���苫�E�ƌĂ�܂��B
�@���f���̃p�����[�^�[�́A�����G���g���s�[�Ƃ������������ŏ�������悤�Ŗސ���ɂ���ċ��߂��A���z�~���@�Ȃǂ̍œK���A���S���Y�����g���܂��B���ރ��f���̐��\��]������ۂɂ́A���𗦁A�K�����A�Č����AF1�X�R�A�Ƃ����������̎w�W���p�����܂��B
�@�\�t�g�}�b�N�X��A�́A���N���X���ނɑΉ������������W�X�e�B�b�N��A�̈��ł���A���W�X�e�B�b�N���̑�����\�t�g�}�b�N�X�����g�p���܂��B��{�I�Ȏd�g�݂́A���W�X�e�B�b�N��A�Ƌ��ʂł��B
�q���g�F �@���苫�E�@�@�����@�@���N���X�@�@LogisticRegression�@�@�K�����@�@��l�@�@���z�~���@�@���`�@�@�덷�t�`�d�@�@�����G���g���s�[�@�@�ޓx�@�@LogisticClassification�@�@���ސ��@�@N���@�@�z�����@�@�����@�@�\�t�g�}�b�N�X���@�@�m���@�@�V�O���C�h���@�@S���@
�u�@�B�w�K�����v
���S�Ҍ����A�f�[�^���́EAI�E�@�B�w�K�EPython�̕����@�@��IT��Deep Insider�Ŋw�ڂ�
Copyright© Digital Advantage Corp. All Rights Reserved. </article> <!-- ✅ 戻るボタン --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
← 一覧へ戻る
</a> </div> </div> <!-- ✅ base を正しく埋め込む --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- ✅ 戻るリンクを正しく構築 --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("✅ base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("✅ backLink.href:", backLink.href);
      } else {
        console.warn("⚠️ backLink not found");
      }
    </script> </body> </html>