<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>「ロジスティック回帰」による分類をPythonで学ぼう</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/_page_.CO8YC2Z5.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- ✅ タイトル --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">📰 「ロジスティック回帰」による分類をPythonで学ぼう</h1> <p class="text-sm text-gray-500"> 2025/6/17 – ITmedia AI  <a href="https://atmarkit.itmedia.co.jp/ait/articles/2506/18/news014.html" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
元記事
</a>  </p> </header> <!-- ✅ 本文 --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> um¯[©çw×évðbg[Éµ½@BwKüåAÚÌæ5ñB¢æ¢æ¡ñ©çAuYes^NovâuXp©Ç¤©vÆ¢Á½gªÞh\ªðµ¢Ü·B±êðÀ»·éã\IÈè@ªuWXeBbNñAvÅ·B}ðgÁÄdgÝâl¦ûðâ³µwÑAPythonÆscikit-learnÅÌÀàÌ±µÜ·BßÄÌlÅàÀSµÄæègßéàeÅ·B
@u±Ì¤iÍêé©^Ç¤©Hvu±ÌÚqÍT[rXððñµ»¤©^Ç¤©Hv\\ ±¤µ½Yes^NoÌ»fiªÞjðf[^©ç\ªµ½¢êÊÍArWlXâúíÅ½³ñ èÜ·æËH@¡ñÍA±Ìæ¤ÈÛÉð§ÂA@BwKÌã\IÈè@Å éWXeBbNñAÉæégªÞhÉÂ¢ÄwñÅ¢«Üµå¤B
@ïÌIÉÍAWXeBbNñAÌTv©çA»ÌdgÝA»µÄPythonvO~OÉæéfÌÀÆ]¿ÜÅæègÝAgªÞhÌîbXLðZÔÅK¾·é±ÆðÚwµÜ·i}1jBgªÞhð}X^[·éÆA±êÜÅuo±â¨ÉÁÄ¢½»fvðuf[^Ì t¯ª é»fvÉÏ¦é±ÆªÅ«ArWlXÌÓvèÉàå¢Éð§¿Ü·B
@±êÜÅÌAÚÅÍAæ3ñÅü`ñAÉÂ¢ÄAæ4ñÅb\ñAÆbWñAÉÂ¢ÄAÂÜèglhð\ª·éuñAvÌè@ðwñÅ«Üµ½B¡ñ©çÍV½Èe[}ÉüèAgJeS[hð\ª·éuªÞvÌè@ðwñÅ¢«Ü·BñÈ~ÅÍAèØA_tHXgAT|[gxN^[}VAk-ßT@Æ±ÌÅ¨yµÝÉI
@È¨¡ñàAåÈGbZXÉtH[JXµAßLÆÌ¤ÊªÍÅ«é¾¯ÈªµÄ¢Ü·B½¾µAWXeBbNñAÍü`ñAæèàµ¡GÈ½ßAdgÝÌà¾Íñ1.5{ÙÇÉÈèÜ·BêûAvO~OÍ±êÜÅÌm¯ÌpÈÌÅAZÔÅÇßéÍ¸Å·BæÁÄALSÌÌ{ [´Íü`ñAÆ¯¶ç¢¾ÆzèµÄ¢Ü·B
@WXeBbNñAÍAuYes©^No©vÆ¢Á½ñli2NXjÌgªÞhâèðð½ßÌAî{IÅÀp«Ì¢è@Å·Bá¦Îu±Ì[ÍXp©^Ç¤©HvÆ¢Á½â¢ÉÎµAf[^ÉîÃg\ªhÉæÁÄ»fÅ«Ü·B@BwKÉ¨¯éªÞè@ÌÅàAÜ¸K¾µÄ¨«½¢gKCXLhÆ¾¦Ü·B
@}1É¦µ½ÊèA¡ñÌWXeBbNñAfàAPythonCuuscikit-learnvðg¦ÎèyÉÀÅ«Ü·B{eÅÍÜ¸AWXeBbNñAÌî{IÈTOâl¦ûð}ðgÁÄª©èâ·ðàµÜ·B»ÌãAÀHÅð§Âã\IÈgpáÉiÁÄAPythonÉæéÀðÌ±µÄ¢«Ü·B
@Ü½AyWzÆµÄ\tg}bNXñAÆÄÎêéè@àÈPÉÐîµÜ·BWXeBbNñAªñlªÞÉp¢çêéÌÉÎµA\tg}bNXñAÍ3ÂÈãÌNXðµ¤½NXªÞÌ½ßÌpIÈè@Å·B½WXeBbNñAiÌêíjÆàÄÎêéA±Ìè@ðK¾·êÎAæèL¢ªÞâèÉÎÅ«éæ¤ÉÈèÜ·B
@ÜÆßéÆA¡ñÍ}2É¦·àeðwÔ±ÆªÅ«Ü·B
@»êÅÍAÜ¸ÍWXeBbNñAÌTvÐî©çnßÄ¢«Ü·B
wPythonÅwÔu@BwKvüåx
@u@BwKÍïµ»¤vÆvÁÄ¢Ü¹ñ©H@SzÍvèÜ¹ñB±ÌAÚÅÍAum¯[©çw×évðbg[ÉA@BwKÌîbÆeè@ð}ðÆÈÈà¾Åª©èâ·ðàµÜ·BPythonðgÁ½ÀHKà èÜ·ÌÅA©ªÌèð®©·±ÆÅÀpIÈXLðgÉt¯çêÜ·B
@{AÚÅÍAïÌIÈ@BwKÌè@iáFü`ñAAèØAk-meansÈÇjððàµÄ¢Ü·BñÈ~ÌV Lð©¦³È¢æ¤ÉAºÐÈºÌ[ÊmÌo^ð¨è¢µÜ·B
@WXeBbNñAiLogistic RegressionjÍAüÍf[^ÆoÍÊÌÖWðuS^ÌÈüviWXeBbNÖAÚ×ÍãqjÅf»·éè@Å·BêûAü`ñAfÅÍAuÈüvÅÍÈu¼üvÅÖWð\»µÄ¢Üµ½B±Ìá¢ªÁÉdvÈ|CgÅ·B
@á¦Î}3ÍAüÍf[^ià¾ÏAÁ¥ÊjÆµÄuT[rXÌpñvðAoÍÊiÚIÏA^[QbgAx^NXxjÆµÄuÞïµ½i1j^µÄ¢È¢i0jvðÂËóÌf[^©çUz}ðì¬µA»ÌãÉWXeBbNñAfÌ\ªÈüiSJ[ujðø¢½}Å·B
@Uz}ÌSÄÌ_ÉgÅàÄÍÜèÌæ¢Èühðø¢Ä¢Ü·B±êªWXeBbNñAÌ{¿Å·B±ÌÈü©çAá¦ÎT[rXpñª15ñÌÍÞïm¦ª3.18Æ¢¤±Æi\ªljªÇÝæêÜ·Ëi}3ÅÂFÅ¦µ½ªjB
@½¾µAm¦lÌÜÜÅÍuYes©^No©vÆ¢¤gªÞhÉÍg¢Ãç¢Å·æËB»±ÅA0.5¢Èçup±vA0.5ÈãÈçuÞïvAÆ¢¤îièlsµ«¢¿A¢«¿tFthresholdjðÝ¯ÄAm¦lð0iNoj©1iYesj©É£U»idiscretizationAÂÜèA±lð2ÂÌJeS[ÉªjµÜ·B»êðOt»µ½Ìª}4Å·B
@£U»ÌîÆÈéüi}4ÅÍÎFÌ_üjÍAè«EiDecision BoundaryjÆÄÎêÜ·B}4Ìæ¤É±Ì«EüÉæÁÄOtðª·éÆAUz}ÌÇÌ_ªup±0v©^uÞï1v©ðoIÉc¬µâ·ÈèÜ·BÈãªA}Åð·éuWXeBbNñAÉæégªÞhû@vÅ·B
@±Ìæ¤ÉµÄªÞÅ«êÎAá¦ÎÈºÌæ¤ÈêÊÅð§¿Ü·BÀÛÉWXeBbNñAÍA³Ü´ÜÈªìÅLgíêÄ¢Ü·i`ªÌ}1ÉàLÚµÄ¢Ü·jB
@¢¸êàAÈüÅ\»³ê½ªÞfÉæÁÄuÇ¿ç©ÌJeS[iáFXp^ñXpAÞï^p±Awü^ñwüjÉ®·ém¦ð\ªµA³çÉè«EÅªÞ·év±ÆÅÀ»³êÜ·B@BwKÉ¨¯éWXeBbNñAÍA±Ìæ¤ÉµÄgñlªÞhÌâèððÅ«Ü·B
@à¿ëñA}3iâ}4jÉ`©ê½S^ÌÈüÍA®ÉæÁÄ`ªìçêÄ¢Ü·BÀÍ±ÌÈüàAü`ñAÆ¯¶æ¤ÉuxÉðüêÄA»±©çyðvZ·é®vÅè`³êÄ¢Ü·i»ÌàeÍãÅÚµ©Ü·jB
@Ü¸ÍA}5É éz7.20915|0.70838xÌæ¤È®ÅAxi±±ÅÍuT[rXpñvjðgÁÄrÌvZlzðßÜ·B±ÌvZÍAwÅwÔê®i¼üÌ®jÈÌÅÈPÅ·ËB±ÌvZÌdûÍü`ñAÆS¯¶Å·BÚµÍãqµÜ·B
@ÉA±ÌzðuS^ÌJ[uð`WXeBbNÖvÉÊ·±ÆÅAÅIIÈyÌli±±ÅÍuÞïm¦vjðZoµÜ·B¾¢·¦éÆAuÜ¸Í¼üÅrÌlzðvZµA»ÌzðÈüÉÏ·µÄm¦lðßévÆ¢¤A2XebvÌ\¢ÉÈÁÄ¢éÌÅ·B
@±Ìæ¤ÉWXeBbNñAÍAü`ñAÆÍgZíÌæ¤ÈÖWhÅ·BæÁÄWXeBbNñAÅàA¼üªÂuX«vAÂÜèÏÉuWi©©jéi©¯Z·éjvÍñAWiregression coefficientjÆÄÎêÜ·BØÐiinterceptjÆ¢¤pêà»ÌÜÜgíêÜ·B
@oÍÍm©Égñü`hÅ·ªAO¼ÌvZiü`jªgü`hÅ é½ßAWXeBbNñAÍêÊÉuü`ñAÌêívÆ¨¦çêÜ·Bcc»ñÈí¯ÅAgªÞhÌ½ßÌè@ÈÌÉuWXeBbNgñAhvÆ¢¤A¿åÁÆ´çíµ¢¼OÉÈÁÄ¢Ü·iêÎjB
@ü`ñAfÍAÁ¥Êª1ÂÈçu¼üvA2ÂÈçu½ÊvA3ÂÈãÈçu´½ÊvÅ\»³êÜµ½BêûAWXeBbNñAfÍµÙÈèAÁ¥Êª1ÂÈçuS^ÌÈüiCurvejvA2ÂÈçuÈÊiSurfacejvA3ÂÈãÅÍu´ÈÊiHypersurfacejvÅ\»³êÜ·i¦È¨AÀÛÌgªÞhÍAùÉà¾µ½ÊèA»ÌoÍÉèlðÝ¯½uè«EvÉæÁÄsíêÜ·jB
@½¾µAÈÊâ´ÈÊÍ}ÉµÄà¼´IÈðªïµ¢½ßA{eÅÍÁ¥Êª2ÂÈãÌfÌ}¦ðÈªµÜ·BC[WÆµÄÍAü`ñAÌuñA½ÊvªuÈÊvÉu«·íÁ½æ¤ÈàÌÆl¦éÆæ¢Åµå¤B
@¿ÈÝÉAü`ñAÅÍAÁ¥Êª1ÂÌfðuPñAvA2ÂÈãÌfðudñAvÆÄÑª¯Ä¢Üµ½BêûAWXeBbNñAÅÍAêÊÉ»¤µ½pêÌæÊÍsíêÜ¹ñB
@ÈãÅAuWXeBbNñAªü`ñAðpµ½è@Å é±Ævªª©ÁÄ«½Æv¢Ü·B½¾µAfÌp[^[iá¦ÎæÙÇÌ®ÉoÄ«½ØÐ7.20915âW|0.70838jðè·édgÝÍAü`ñAÌvZû@uÅ¬ñæ@vÆÍÙÈèÜ·BÉA»ÌdgÝð©Ä¢«Üµå¤B
@f[^ÉÅàtBbg·éWXeBbNñAfiS^Ì\ªÈü^ÈÊ^´ÈÊjÌep[^[ð©Â¯é½ßÉÍAêÊIÉuÅÞi³¢ä¤jèviÅÞ@jÆÄÎêévZû@ªp¢çêÜ·BÈºÅA»ÌdgÝðÅ«é¾¯®ÅÍÈ}ððSÉà¾µÄ¢«Ü·B
@Ü¸ÍPûpÌf[^ZbgªKvÅ·BÈºÌà¾ÅÍAæÙÇÌái}3`5jÆ¯¶f[^ðg¤±ÆÉµÜ·i}6jB±Ìf[^ÉÍAÁ¥ÊixjÆµÄuT[rXpñvªA^[QbgiyjÆµÄup±i0j^Þïi1jvÌxªÜÜêÄ¢Ü·B
@¡ñÍA}6É`©ê½SÄÌ_ÉgÅàÄÍÜèªæ¢Èühðø«½¢Å·ËB»±ÅAÜ¸ÍKÉ¼Ì\ªÈüðø¢ÄÝÜ·B
@OfÌ}5Åàà¾µ½æ¤ÉAWXeBbNñAÌ\ªÈüð`ÉÍA
Æ¢¤A2XebvÌvZªKvÅ·B
i1jü`
@Ü¸i1jÌvZÉÍAü`ilinear combinationjâdÝt«ü`aiweighted linear sumjÆÄÎêéû@ðp¢Ü·BïÌIÉÍAØÐðp[^[À0AT[rXpñixjÉÎ·éWi¼üÌX«jðp[^[À1ÆuÆA®ÍÈºÌæ¤ÉÈèÜ·i¦ü`ñAÆ¯¶®jB
@Æ±ëÅAÉ¦·®ÌÉAwLÌlCsAeiIC[A©RÎÌêjªoÄ«Ü·ªA®Éeðg¤Æu÷ªðµâ·¢iX«ðvZµâ·¢jvAÂÜèup[^[ÅK»ÌvZªµâ·¢vÆ¢¤bgª é½ßÉÌp³êÄ¢éAÆmÁÄ¨¯ÎAdgÝðð·éÉÍ\ªÅ·B
i2jWXeBbNÖ
@Éi2jÌvZÉÍAWXeBbNÖiLogistic functionAµ§ÉÍWWXeBbNÖjÆÄÎêéû@ðp¢Ü·BïÌIÉÍÈºÌ®ÉæèAæÙÇvZµ½ü`ÌÊizjÉÎ·é\ªm¦iyjðßévZÉÈèÜ·B
@±ÌÖÉæèAü`Éæéu¼üvÍAuS^ÌÈüvÉÏ·³êÜ·i}7jBS^iVOChjÉÈé±Æ©çAWXeBbNÖÍVOChÖiSigmoid functionjÆàÄÎêÜ·i¦¿ÈÝÉAj [lbg[NÅÍ»ÌÄÑûªå¬Å·jB
@»êÅÍÈºAu¼üvðuS^ÌÈüvÉÏ¦éÌÅµå¤©H@}7ÌOtð©ÈªçAµl¦ÄÝÄ¾³¢B
@RÍAu¼üv¾Æc²ÌlÌÍÍª³Ài\`jÉÈÁÄµÜ¤©çÅ·BêûAuS^ÌÈüvÈçc²ÌlÌÍÍÍ0.0`1.0ÉûÜèÜ·BÂÜè0`100Ìm¦iprobabilityjÆµÄµ¦éÌÅ·Bm¦Èçup±©^Þï©vÌæ¤È»ÊÉsb^Å·ËB
@v·éÉAuÀlðm¦lÉÏ··é±ÆvªWXeBbNÖÌðÅ·B
¼Ì\ªÈü
@³ÄAÈãÌ2ÂÌ®ðgÝí¹éÆAÌæ¤È®ÉÜÆßçêÜ·BÈºÅÍ±Ì`ÅgÁÄ¢±ÆÉµÜ·B
@¡ñÍ}ðÅà¾·é½ßÉAep[^[ÉÎ·é¼ÌúlðÝèµÜ·B±ÌúlÍ ÜÅu¼vÈÌÅAD«ÉßÄ\¢Ü¹ñB±±ÅÍÀ0ÌúlÍ|5.0AÀ1Ìúlð0.5ÆµÜµå¤B
@±êÉæèA
Æ¢¤®Ì\ªÈüÉÈèÜ·B}8ÉA±ÌÈüð`¢ÄÝÜµ½B
@}8ÅÍu¼Ì\ªÈüªAÀÛÌf[^©çÇêç¢YÄ¢é©vÉÚµÄ¾³¢B±ÌêÌYÆÍAuef[^|CgvÆu¼Ì\ªÈüiWXeBbNñAfjvÌÔÌ£Ìæ¤ÈàÌÅ·Bµ§ÉÍ£ÅÍÈ¢ÌÅ·ªiÚ×ãqjA}8ÉÍQlC[WÆµÄuYÌîóvð`¢ÄÝÜµ½i±Ì\ªÈü¾ÆApñªÈ¢ÙÇAÞïµÈ¢±ÆÉÈÁÄµÜÁÄ¢Ü·jB
@f^Èúl¾Á½ÌÅAf[^ÆÈüªStBbgµÄ¢Ü¹ñËBWXeBbNñAÅÍA±êðÅKÈÈüÉ©®IÉ²®µæ¤Æ¢¤í¯Å·B
@ü`ñAÅÍA³ðlief[^Ì^[QbgjÆ\ªlifÌoÍljÆ¢¤Àl¯mÌø«Z¾¯ÅAÈPÉu£vªvZÅ«Üµ½B
@êûAWXeBbNñAÅÍA³ðli±±ÅÍup±i0j©^Þïi1j©vÌ³ðxjÆA\ªli±±ÅÍÞïm¦jÌuYvðvZµÜ·ªA±êçÌlÍm¦liPÊÉÁH³ê½ljÅ é½ßAPÉø«ZµÄà³µ¢u£vÉÍÈèÜ¹ñB
zbg\»
@u¦ÁAp±i0j©^Þïi1j©AàPÊÌgm¦hÈÌHvÆvÁ½©àµêÜ¹ñB±¤¢Á½JeS[lÍAup±vª½©AuÞïvª½©HAÆ¢¤2ÚÉª¯éÆA»ê¼êðgm¦hÆµÄµ¦Ü·B
@¿ÈÝÉAá¦Îuxïvª½©AðÁ¦éÈÇµÄ3ÚÈãÉâ·±ÆàÂ\Å·i½NXªÞÌêjB
@á¦Î³ðlª1ÈçAp±0AÞï100ÉÈèÜ·B³ðlª0ÈçAp±100AÞï0Å·ËBp[ZgðlÅ\»·éÆ00.0A1001.0Å·ÌÅA^[QbgÆÈé¡ÌÚÌ¤¿A³ðÌ1Ú¾¯ª1ÅAcèSÄÌÚÍ0ÉÈèÜ·B
@³ðlð1ÂÉÜÆßÄwIÉxNgÅÆAp±[0, 1]âAÞï[1, 0]Æ¯Ü·B±Ìæ¤È«ûÍAzbgione-hotj\»ÆÄÎêÜ·BÜ½A±Ìæ¤ÉÏ··é±ÆðzbgGR[fBOÆÄÑÜ·B
m¦ªzÌY
@»µÄA[1, 0]â[0, 1]Ím¦ªzÆ©È¹Ü·B}9ÍA éf[^|CgÌ³ðlðup±vÆuÞïvÌ2ÂÌ_OtÅ\»·é±ÆÅAm¦ªzÌOtÆÈÁÄ¢Ü·B¯lÉA»Ìf[^ðüÍµ½ÛÌfÉæé\ªlàm¦ªzÆµÄ\»Å«Ü·B
@}9ÌºÉ épim¦FprobabilityÌgphjÍAuÞïm¦vð\µÜ·BtÉup±m¦vÍA100i1.00j©çÞïm¦ipjðø¯Îæ¢ÌÅA1|pÉÈèÜ·Ëi¦±êç2ÂÌÏÍAãqÌ®Åp³êÜ·jB
@±Ìæ¤Él¦é±ÆÅAef[^ÉÎµÄu³ðxÌm¦ªzvÆufoÍÌm¦ªzvÌYisêvjðvZ·êÎæÈèÜ·B»ÌvZû@ªAð·Ggs[iCross-entropyANXGgs[jÆ¢¤ÖÅ·Buð·Ggs[¹¸iLossjvâuð·Ggs[ë·iErrorjvÆàÄÎêÜ·B
@ü`ñAÅÍAuc·vÆÄÎêéYÌvlðvZ·é½ßÉRSSic·ÌñæajÆ¢¤Öðg¢Üµ½ªAð·Ggs[Í»ÌWXeBbNñAÅ¾Æl¦éÆª©èâ·¢Åµå¤B
@ð·Ggs[ÍAm¦ªzÌYð©RÎðp¢Äl»µÜ·B»Ì®ÍA^XNªuñlªÞiBinary Classificationjv©u½NXªÞiMulti-class Classificationjv©ÅµÙÈèÜ·B±±ÅÍñlªÞ^XNðð¢Ä¢é½ßAñlªÞpÌ®ðÐîµÜ·B½NXªÞpÍ ÆÅÐîµÜ·B
ñlªÞpÌð·Ggs[
@ÈºÌ®ÅÍAnÍf[^iiÍ»Ì½ÔÚ©jAlogÍ©RÎilnAÂÜèlCsAeðêÆ·éÎjA°Íað\µÜ·B±Ì®ªu½ðµÄ¢é©vÌÓ¡Í ÆÅà¾·éÌÅA®Í´ÁÆ©é¾¯Å\¢Ü¹ñB
@±Ì®Í{ÌÓÅ¶EÉª©êÜ·B{Ì¶¤ÅÍpi±±ÅÍÞïm¦jÌYðAE¤ÅÍ1|pi±±ÅÍp±m¦jÌYðvZµÄ¢Ü·B¶EÇ¿çàu³ðªÞïi1j©^p±i0j©vÉ¶ÄA³ðÆ\ªÌYðvZ·éàeÉÈÁÄ¢Ü·ÌÅA¶¤¾¯à¾µÜ·B
@¶¤Ì³ðliÔÚ ~ ©RÎ(\ªliÔÚ)Æ¢¤vZÉÚµÄ¾³¢B³ðliÔÚª0ÌêA0É½ð|¯ZµÄàÊÍ0ÉÈèÜ·æËB
@³ðliÔÚª1ÌêA\ªliÔÚª1.0ÈçA©RÎÌvZÉîÃ«A»ÌÊÍ0Å·B¯lÌvZÅA0.5Èç|0.7A0.1Èç|2.3ÆÈèÜ·BÂÜèA\ªªÔáÁÄ¢éÙÇiYªå«ÈéÙÇjAÊÌlª}CiXûüÉå«ÈèÜ·B¿ÈÝÉA®ÌæªÉ|i}CiXjªt¢Ä¢éÌÍA}CiX~}CiXûüÅuvXÌlvÉ·é½ßÅ·B
@È¨A\ªliÔÚª0.0àµÍ1.0ÌêAwIÉvZªsÂ\Èulog(0)ÌvZvª¶·é½ßð¯È¯êÎÈèÜ¹ñB»Ì½ßAscikit-learnÈÇÌCuÅÍA\ªliÔÚª0.0â1.0ÉÈçÈ¢æ¤ÉAñíÉ¬³Èliepsilonjðp¢ÄAlð[epsilon, 1|epsilon]ÌÍÍÉ§ÀiclipjµÄ¢Ü·B±êÉæèAlog()ÖÌüÍªíÉLøÈÍÍÉûÜé½ßAÀSÉvZÅ«éæ¤ÉÈÁÄ¢Ü·B
@±Ìæ¤ÉvZµ½¶¤ipjÆE¤i1|pjA2NXªÌYð«µZµ½ãÅASf[^ªðvµÄf[^Åé±ÆÅ½ÏµÄ¢éAÆ¢¤ÌªuñlªÞpÌð·Ggs[Ì®vÌÓ¡Å·B
@±êÉæèuYÌ½ÏlvªÜèÜ·iPÉu¹¸vâuë·vÆàÄÎêÜ·jB»Ì¹¸lª¬³¢ÙÇuf[^ÉÄÍÜèÌæ¢itBbg·éjÈüvÅ é±Æð\µÜ·BÂÜèWXeBbNñAfÌ\ª¸xª¢Æ¢¤±ÆÅ·B
@È¨A\ªliÔÚÌªÉÍAOqµ½WXeBbNÖi®ðÈºÉÄfjªãü³êÜ·B½¾µAÀÛÉãüµ½®Íµ¡GÉÈèïµ¢CªÉÈéÌÅiêÎjA ¦ÄÈªµÜ·B
@±ÌWXeBbNÖÌoÍðgÁ½uð·Ggs[vÌ®ðgÁÄAp[^[À0iØÐjâÀ1iT[rXpñÉÎ·éWjðßéû@ð©Ä¢«Üµå¤BWXeBbNñAÌÚWÍAYið·Ggs[jªÅ«é¾¯¬³Èéæ¤ÈAÅKÈp[^[ð©Â¯é±ÆÅ·B
@ÅKÈp[^[ÌßûÍAî{IÉÍü`ñAÌRSSic·ÌñæajÌÅ¬»Æ¯¶l¦ûÅ·BïÌIÉÍA}10É¦·ÈüÌJêð©Â¯éC[WÅ·B
@êÔJêÌªªAð·Ggs[ÌvZlªÅà¬³ÈéuÅKÈp[^[vÅ·ið·Ggs[ÌÅ¬»jB
@}10ðº©çãÉ©éÆAuYÌöxvið·Ggs[jªÇê¾¯å«¢©ªª©èÜ·BuYisêvjvÌ^tÌTOÍuêvvÈÌÅAtÌ_Åã©çºÉ©éÆAuêvÌöxvªÇê¾¯å«¢©ªª©èÜ·æËB
@±ÌuêvÌöxvÍAuÞiàÁÆjàçµ³vÆ¢¤Ó¡ÌÞxiä¤ÇALikelihoodjðÏ·µ½lÅ·Buð·Ggs[ÌÅ¬»vuÞxÌÅå»vÆÈéÌÅAWXeBbNñAÉ¨¯ép[^[èÌè@ÍuÅÞèvÆÄÎêéÌÅ·BÅÞèÉÂ¢ÄÍA ç½ßÄãqÌRÅGêÜ·B
@WXeBbNñAÌêAü`ñAÌæ¤ÉÅKÈp[^[ðuwÌö®ðgÁÄêÅßéviðÍIÉðjÆ¢¤û@ªg¦Ü¹ñBWXeBbNÖÆ¢¤ñü`ÌÏ·ªÁíÁ½½ßAÈüâÈÊÍRâJªôÂà éæ¤È`ÅgÅÁÄ¨èAJêðêÅvZ·éÆÇIÈJêiÇðjÉÆiÍjÜÁÄÔáÁ½lÉÈéÂ\«ª é©çÅ·B
ùz~º@
@WXeBbNñAÅÍAf[^²ÆÉuÈüÉÎ·éÚüÌX«viùzFGradientÆÄÎêéjðvZµÄ~ÏµA»ÌùzÌv©çJêÌêiÅKðjðTÁÄ¢«Ü·BùzÆÍuâ¹vÌ±ÆÅAÂÜè{[ð°Äâ¹ð]ª·C[WÅ·i}11jB±ÌÅK»è@ÍAùz~º@iGradient DescentjÆÄÎêÜ·B
@ùz~º@ÉÍAf[^SÌðg¤ob`ùz~º@âA éöxÌÜÆÜè²ÆÌf[^ðg¤~job`ùz~º@ÈÇª èÜ·Bj [lbg[NÆ¯¶ÈÌÅiQlLjA±±ÅÍÚ×ð¤µÜ·B
@ùz~º@ÍAÅK»ASYÌêÂÉß¬Ü¹ñBscikit-learnÈÇÌCuÅÍAWXeBbNñAÅCÓÌÅK»ASYðIðÅ«Ü·B¢¸êðg¤êàAÅKÈp[^[À0iØÐjâÀ1iT[rXpñÉÎ·éWjªÜèÜ·B
@ÅK»ASYÅÍAuPûiwKjð½ñJèÔ·©vðÓ¡·éCe[ViiterationjðßÄA»Ìñ¾¯JêðTµÄÅK»Ìx¢ðßé±ÆªÅ«Ü·BÜ½Au1ñÌCe[VÅwÔXs[hvðÓ¡·éwK¦ilearning-ratejðßéêà èÜ·ªAscikit-learnÅWXeBbNñA·éêÍàIÉ©®²®³êé½ßAÊíÍwèÅ«Ü¹ñB
@}11ÍAùz~º@ÉæèÅ¬»ªiÞlqÌC[Wð¦µ½àÌÅ·Bî{IÉAÅÍ{[ªJêÉü¯ÄâÌ}ùzðå«]ªè¿AJêÉßÃ«XÉâÌùzªÉâ©ÉÈéÉÂêÄäÁèÆ]ªéæ¤ÉÈÁÄ¢«AÅIIÉJÌêiÅ¬ljÉ½Çè Æ¢¤¬êÅ·B
@±Ìæ¤ÉµÄep[^[ÌÅKlðßéÆAè³ÅÌvZáÅÍÀ0Í7.48AÀ1Í|0.74ÆÜèÜµ½BOfÌ}5Æµp[^[lªÙÈèÜ·ªA±êÍgpµ½ÅK»ASYªÙÈé©çÅ·i¦}5ÅÍscikit-learnÌftHgðg¢Üµ½ªA±±ÅÍùz~º@Åè®vZµÜµ½BQlFTvm[gubNjBp[^[lÍAÅK»ASYÉ½ðg¤©ÅÏíÁÄéÌÅÓµÄ¾³¢B
@ÈãÅAð·Ggs[ªÅ¬ÆÈéÅKÈp[^[À0ÆÀ1ªvZÅ«½ÌÅA±êçðp¢ÄÅIIÈWXeBbNñAfi±±ÅÍ\ªÈüjðèµÜ·BÜ¸ü`Ì®ÍÈºÌæ¤ÉÈèÜ·B
@±ÌzðWXeBbNÖÉãü·éÆAÈºÌ®ÉÈèÜ·B
@±Ì®Ì\ªÈüðUz}ãÉ`æ·éÆ}12Ìæ¤ÉÈèÜ·B
@ÈãÌæ¤ÉÅÞèÍAPûZbgÉÅàKµ½WXeBbNñAfi\ªÈü^½Ê^´½Êjð©Â¯é½ßÌvZû@Æ¢¤í¯Å·B
@æÙÇàà¾µ½æ¤ÉAuYÌöxðÅ¬»·é±ÆvÍuêvÌöxiÞxjðÅå»·é±ÆvÆ¯¶Ó¡ÉÈèÜ·BWXeBbNñAÌÅK»è@ÍA±ÌuÞxÌÅå»vÌ_©çuÅÞèiMaximum Likelihood EstimationFMLEjvÆÄÎêÜ·B
@l¦ûÍVvÅAu»ÝÌfi\ªÈüjªAPûZbgðÇê¾¯àÁÆàçµà¾Å«é©iÞxjðÅåÉµæ¤vÆ¢¤àÌÅ·BR^ÌOtðv¢©×Ä¾³¢i}13jB±ÌRÌ¸ãªuàÁÆàçµ³iÞxjªÅåvÆÈép[^[liÌgÝí¹jÅ·B
@êûAð·Ggs[ÍuYðÅ¬Éµæ¤vÆ¢¤ÖÅ·ªA»Ìgi®jÍuÌÎÞxv»ÌàÌÅ·BæªÉ}CiXªt¢Ä¢é½ßAOtÌ`ªt³iR^¨J^jÉÈÁÄ©¦é¾¯ÈÌÅ·iÂÜè}10ÍAu±Ì}13ðt³ÉµÄµÏ`³¹½àÌvÆà¾¦Ü·jB
@uð·Ggs[ðÅ¬»·é±ÆvÆuÞxðÅå»·é±ÆvÍAwIÉÍS¯¶Ó¡Å·B_ªá¤¾¯ÈÌÅAuÅÞèH@ïµ»¤vÆ\¦éKvÍ èÜ¹ñB
@ÈãÅWXeBbNñAfÌep[^[ðè·édgÝððµÜµ½B±¢ÄÀHÆµÄAscikit-learnÉæévO~OðÌ±µÄÝÜµå¤B
@scikit-learnÉÍAWXeBbNñAfð\zÅ«éLogisticRegressionNXisklearn.linear_modelW [jª èÜ·B
@Xg1ª»Ìg¢ûÅ·Bü`ñAÆÙÚ¯¶ÈÌÅAfit()\bhÜÅÌà¾Í¤µÜ·Bcè2sÌ\bhÄÑoµÅÍAPû³ê½WXeBbNñAfðgÁÄA\ªÌum¦lvÆuÅIIÈ\ªÊi0©1ÌoÍljvðæ¾µÄ¢Ü·B
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(Á¥ÊFX, ^[QbgFy)
model.predict_proba(Vµ¢f[^) # \ªlim¦ljðoÍ
model.predict(Vµ¢f[^) # \ªÊi0©1©jðoÍ
@predict_proba()\bhÅÍA\ªlÆµÄum¦lviáFÞïm¦jªæ¾Å«Ü·BªA±Ìm¦lª0.5ÈºÈç0iáFp±jA0.5ð´¦éÈç1iáFÞïjÌæ¤ÉAÅIIÈNXxi0©1©jðèµ½¢Å·æËB±¤µ½£U»³ê½\ªÊðæ¾µ½¢êÉÍApredict()\bhðg¢Ü·B
@à¿ëñLogisticRegressionNXÉÍA±êçÈOÉà³Ü´ÜÈ@\ªõíÁÄ¢Ü·BÚµÍö®y[Wð²QÆ¾³¢B
@»êÅÍA±ÌNXðgÁÄÀÛÉWXeBbNñAfðì¬µAñlªÞðsÁÄÝÜµå¤B
@{AÚÍAæ1ñÅà¾µ½æ¤ÉA³¿ÌNEhÂ«uGoogle ColabvÌpðOñÆµÄ¢Ü·Bî{IÉÍAColabÅVKm[gubNðìÁÄAÈ~Åà¾·éR[hðüÍµÈªçÀsÊð©ªÌÚÅm©ßÄ¾³¢BùÉüÍÏÝÌm[gubNðg¢½¢êÍA±¿çÌTvm[gubNð²p¾³¢B
@Ü¸Íf[^ZbgðõµÜ·B¡ñÍAscikit-learn©çÇÝßéuWineiCjf[^Zbgvðg¢Ü·BüÍf[^ÆÈéÁ¥ÊÉÍAºLÌ13Úª èÜ·B¢¸êàlÏiÀljÅ èAJeSJÏiJeS[ljÍÜÜêÄ¢Ü¹ñB
@oÍÊÆÈé^[QbgÍÈºÌÊèÅ·B±êçÍA3íÞÌÙÈéií©çìçê½uCÌíÞvð\·NXxi³ðljÌ¤¿A3ÂÚðJbgµÄ2íÞÉ·é±ÆÅAÖXIÉñlªÞpÌf[^ZbgÆµÄpµ½àÌÅ·B
@Winef[^ZbgÉÂ¢ÄæèÚµmè½¢êÍA±¿çÌLðQÆµÄ¾³¢B
@±Ìf[^ZbgðÇÝÞÉÍAsklearn.datasets.load_wine()ÖðÄÑo·¾¯Å·BPûZbgÆeXgZbgÉª·éÜÅÌR[hðÈºÌXg2É¦µÜ·B
from sklearn.datasets import load_wine
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
# f[^ZbgÌÇÝÝ
wine = load_wine()
# Á¥ÊÆ^[QbgÌæ¾
X = wine.data
y = wine.target
# NX1i0jÆNX2i1jÌf[^¾¯ÉièÞ
mask = (y == 0) | (y == 1)
X = X[mask]
y = y[mask]
# f[^ÌW»
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# PûZbgÆeXgZbgÉª
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=0)
print(f&#39;PûZbgÌTCY: {X_train.shape}&#39;) # á: PûZbgÌTCY: (117, 13)
print(f&#39;eXgZbgÌTCY: {X_test.shape}&#39;) # á: eXgZbgÌTCY: (13, 13)
@È¨AÁ¥ÊÔÌXP[ªÙÈé½ßAOÆµÄeÁ¥ÊðW»i½Ïðu0vÉAWÎ·ðu1vÌXP[ÉÏ·jµÄ¢Ü·B
@ÉA¢æ¢æLogisticRegressionNXisklearn.linear_modelW [jðgÁÄWXeBbNñAfðì¬µAPûµÜ·BXg3Í»ÌR[háÅ·B
from sklearn.linear_model import LogisticRegression
# WXeBbNñAfÌPû
model = LogisticRegression(solver=&#39;lbfgs&#39;)
model.fit(X_train, y_train)
print(&#39;WF&#39;, model.coef_)
print(&#39;ØÐF&#39;, model.intercept_)
# WF [[-1.50497653 -0.53548103 -0.90018867 1.00264039 -0.31198706 -0.09362577
# -0.28866105 0.2635515 0.25998733 -0.74083219 -0.00681288 -0.62169609
# -1.85070478]]
# ØÐF [0.2751988]
@LogisticRegressionNXÌsolverp[^[ÉÍAÅK»ASYisolverF\o[jðwèÅ«Ü·BXg3ÅÍAftHglÆ¯¶&#39;lbfgs&#39;ðwèµÜµ½iÈªàÂ\Å·ªAà¾Ì½ß¾¦µÄ¢Ü·jB
@åÈIðÍÈºÌÊèÅ·BeASYÌÚ×ÈdgÝÉÍ§¿üèÜ¹ñÌÅA±±ÅÍ¼ÌÆg¢ª¯ÌÚÀð³¦Ä¨«Üµå¤B
@¦&#39;sag&#39;â&#39;saga&#39;Ì¼OÉ éugviGradientjÍAãLÌuÇñÈdgÝHvÌà¾ÅµÁ½uùz~º@iGDFGradient DescentjvÌêíÅ é±Æð¦µÄ¢Ü·B
@ÅK»ASYÌ®âÚµ¢dgÝðmçÈÄàAãLÌwjðQlÉ\o[ðI×ÎÀpãÍ\ªÅ·BfÌ\ª¸xðßéÛÍAÙÈé\o[ð1Â¸ÂµÄärµÄÝÄàæ¢Åµå¤BÀÁ½Æ«ÍAÜ¸&#39;lbfgs&#39;ðg¦ÎA½Ìê¤Ü¢«Ü·B
@Á¦ÄAXg3ÌÅãÅoÍµ½model.coef_iWjÆmodel.intercept_iØÐj©çAfÌàóÔðlÅmFÅ«Ü·ËBÈ¨A±ÌáÅÍAWÌª13ÂÆ½¢½ßA³ÌOtÆÈè}¦Å«Ü¹ñªAWª1ÂÅ êÎAOfÌu}3@WXeBbNñAfÌ\ªÈüÌávÌæ¤É}¦Å«Ü·B
@ÉAXg4Í»ÌfðgÁÄeXgZbg©çuCÌNXi0©1©jvð\ª·éR[háÅ·B
# eXgZbgðp¢ÄªÞ\ªi\ªÊÆm¦lÌæ¾j
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)
# æª5Ì\ªÊÆA»Ì\ªm¦lð\¦
print(f&#39;ÀÛÌNXiæª5j:{y_test[:5]}&#39;)
print(f&#39;\ªÊiæª5j:{y_pred[:5]}&#39;)
print(&#39;---&#39;)
print(f&#39;\ªm¦liæª5j:\n{y_proba[:5]}&#39;)
# ÀÛÌNXiæª5j:[0 1 1 1 1]
# \ªÊiæª5j:[0 1 1 1 1]
# ---
# \ªm¦liæª5j:
# [[0.99578134 0.00421866]
# [0.00122679 0.99877321]
# [0.0013692 0.9986308 ]
# [0.02719697 0.97280303]
# [0.00682272 0.99317728]]
@\ªÊipredict()\bhÅ¾çêéNXxjÆAÀÛÌNXieXgZbgÌ³ðxjðärÅ«éæ¤ÉoÍµÄ¢Ü·BæªÌ5ÍSÄ³ðµÄ¨èA³ð¦Í100Åµ½B»êÅÍAeXgZbgSÌÅÌ³ð¦ÍÇÌöxÈÌÅµå¤©H@]¿µÄÝÜµå¤B
@Xg5ÍAPûÏÝÌWXeBbNñAfðgÁÄAeXgZbgSÌÉÎ·éªÞfÌ«\ð]¿·éR[háÅ·BªÞ^XNÅÍu³ð¦vªægíêÜ·ªA±ÌR[hÅÍuK¦vuÄ»¦vuF1XRAvÈÇA³ð¦ÆÍÙÈéÏ_Ì]¿wWà¹¹Ä`FbNµÄ¢Ü·i±êçÌ]¿wWÍãÙÇÈPÉà¾µÜ·jB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# \ªÊiy_predjÆ³ðxiy_testjðärµÄAe]¿wWðZo
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
# ÊðoÍ
print(f&#39;³ð¦iAccuracyj: {acc:.2f}&#39;)
print(f&#39;K¦iPrecisionj: {prec:.2f}&#39;)
print(f&#39;Ä»¦iRecallj: {rec:.2f}&#39;)
print(f&#39;F1XRAiF1 Scorej: {f1:.2f}&#39;)
# ³ð¦iAccuracyj: 1.00
# K¦iPrecisionj: 1.00
# Ä»¦iRecallj: 1.00
# F1XRAiF1 Scorej: 1.00
@Xg5ÅÍAeXgZbgSÌÅàuSÄÌ]¿wWÅ1.00i100jÌ«\Å é±ÆvªmFÅ«Üµ½BñíÉDGÈªÞfÅ·ËBàµÍA¡ñÌf[^ZbgÅÌªÞ^XNÍAÈPß¬½Ì©àµêÜ¹ñB
@ªÞfÌ]¿ÅÍAu³ð¦¾¯ð©ÄÀSµÈ¢v±ÆªåØÅ·B
@á¦ÎA³ðxª1iz«FPositivejÅ éf[^ª100í¸©2µ©È¢êASÄð0iA«FNegativejÆ\ª·é¾¯ÅA³ð¦Í98ÉÈèÜ·B©©¯ãÍ«\É©¦ÄàAdvÈNXi±ÌêÍz«jðêxàoÅ«È¢AñíÉÎÁ½fÉÈÁÄ¢éÂ\«ª éÌÅ·B
@àµz«ªuaC èvð\·ÈçASÄðuaCÈµvÆ»è·éÌÍAë¯ÈfÅ·æËB±Ìæ¤ÈÎèð©¦³È¢½ßÉA³ð¦¾¯ÅÈAÄ»¦AK¦AF1XRAÈÇ¡Ì]¿wWð¹¹ÄmF·éÌª¨©ßÅ·B
@»êÅÍAXg5ÅgÁ½]¿wWÉÂ¢ÄÈPÉÜÆßÜ·BwÒª³¦Ä¨«½¢dvÈwWÅ·ªA®âvZû@ÍÈª·éÌÅAKvÉ¶ÄeÚÌNæðQÆµÄ¾³¢B»ê¼êµ¸ÂáÁÄ¢Äo¦É¢©àµêÜ¹ñªAg¤½ÑÉÈºÌàeð½xà©ÔµÄÝéÆæ¢Åµå¤B
@ÈãÅAWXeBbNñAÉæéñlªÞÌîb©çÀû@ÜÅðwÑÜµ½BÍyWzÆµÄA±êð½NXªÞÉg£µ½u\tg}bNXñAi½WXeBbNñAjvðÐîµÜ·BµæêÄ«½©àµêÜ¹ñªA±±ÜÅÌm¯ðp·êÎX[YÉðÅ«Ü·B±±Å§¿~ÜéÌÍàÁ½¢È¢ÌÅAºÐ±Ì¬êÌÜÜÅãÜÅwÑØÁÄµÜ¢Üµå¤I
@±±ÜÅÐîµÄ«½WXeBbNñAÍA2NXÌªÞÉgíêé½ßAuñibinaryjWXeBbNñAvÆàÄÎêÜ·B±êÉÎµÄA3NXÈãÌ½NXðªÞ·éè@ÍAu½imultinomialjWXeBbNñAvÆÄÎêé±Æª èÜ·B
@»Ìã\IÈè@ªA\tg}bNXñAiSoftmax RegressionjÅ·BWXeBbNñAÆî{IÈdgÝÍ¯¶Å·ªAÈºÌ2ÂÌ_¾¯ªu«·íèÜ·B
@ÂÜèA±Ì2_ð³¦é¾¯ÅA\tg}bNXñAàðÅ«¿á¤Æ¢¤±ÆB±±Åà¤µæ£éûªfR¨¾Å·æËI
@¦¿ÈÝÉA»ÝÌscikit-learnÌLogisticRegressionNXÅÍA½NXªÞðs¤Æ©®IÉu½imultinomialj\tg}bNXñAvû®ªKp³êÜ·B½¾µAOqÌÅK»ASYÅàGê½æ¤ÉA&#39;liblinear&#39;\o[ðg¤êÌÝAu1Î»Ì¼iovrFone-vs-restjvû®ÉÈèÜ·B±Ìû®ÅÍAeNXÉÂ¢ÄÂÊÉñWXeBbNñAðÀs·é½ßA\tg}bNXñAæèàñø¦ÉÈèâ·¢_ÉÓµÄ¾³¢B
@»êÅÍAuu«·¦çêéÖvÆuÏíçÈ¢l¦ûvÉÚµÈªçAWXeBbNñAÆ¯¶¬êÉÁÄA\tg}bNXñAÌdgÝððàµÄ¢«Ü·BÈ¨Ad¡·éªÍÈªµAv_ÉiÁÄÐîµÜ·B
@\tg}bNXñAÌdgÝÅàAÜ¸Í¼Ìfðì¬µÜ·B±ÌfÍAü`ÆWXeBbNÖðgÝí¹½ÖÅµ½B»ÌuWXeBbNÖvðu\tg}bNXÖvÉu«·¦Ü·B
\tg}bNXÖ
@WXeBbNÖÅÍAuNX1i0jvÌtªuNX2i1jvÈÌÅA1ÂÌÖÅ2NXªÌm¦ð\»Å«Üµ½BÅà3NXÈãÅÍA»¤Í¢«Ü¹ñB
@\tg}bNXÖiSoftmax functionjÅÍANX²ÆÉm¦ðvZ·éKvª èÜ·Bá¦Î3NXÈçAuNX1iy1jvuNX2iy2jvuNX3iy3jvÆ¢¤3ÂÌ\ªm¦iyjjðßÜ·B¦jÍNXÔi1`3ÈÇjÅ·B
@»ÌvZ®AÂÜèeNXÉÎ·éü`ÌÊizjj©ç\ªm¦iyjjðßé®ÍÈºÌæ¤ÉÈèÜ·B¦mÍNXÅ·BkÍNXÔi1`3ÈÇjÅ·ªAªêÌai°jÅÍSNXðÎÛÆ·é½ßAAkÍjÆÍÊÌNXÔÆµÄgÁÄ¢Ü·B
@ÄÑAlCsAeªoêµÜµ½ËB±êÍAùzi÷ªjÌvZðµâ··é½ßÅµ½B
@®ªª©çÈÄàCÉµÈÄåävÅ·BWXeBbNÖÆ¯¶æ¤ÉAuNX²ÆÌm¦ðoµÄ¢év\\»ÌÓ¡³¦Â©ßÄ¢êÎOKÅ·B
@ÉA³ðxiuNX1©^2©^3©vjÆA\ªlieNXÌ\ªm¦jÌgYhðvZµÜ·B³ðxÍAzbg\»É·é±ÆÅm¦ªzÆ©È¹Ü·B\ªlàANX²ÆÌ\ªm¦iyjjðxNgÉSÄÜÆßêÎAm¦ªzÉÈèÜ·B±êÅA2ÂÌm¦ªzÌgYhªªêéæ¤ÉÈèÜ·ËB
m¦ªzÌY
@OÌ½ßANXª3Â éêÌm¦ªzOtð¦µÜ·i}14jBWXeBbNñAÌêÆÙÚ¯¶ÅA_ª1{¦½¾¯Å·B
@m¦ªzÌYÍAð·Ggs[Ål»Å«Üµ½Bµ©µA»Ì®ÍA^XNªuñlªÞv©u½NXªÞv©ÅµÙÈéÌÅA±±Å½NXªÞpÌ®ðÐîµÜ·B
@Æ¢ÁÄàAñlªÞpÆ½NXªÞpÅAâÁÄ¢é±ÆÍ¯¶Å·B®Ì©½ÚÍáÁÄàAuÇ¿çàYðªé®Èñ¾vÆvÁÄ¨¯ÎOKÅ·B
½NXªÞpÌNXGgs[
@ÈºÌ®ÅÍAnÍf[^iiÍ»Ì½ÔÚ©jAmÍNXikÍ»ÌNXÔjAlogÍ©RÎilnAêÍlCsAejA°Íað\µÜ·B
@ñlªÞpÅÍAu{ÌÓÅ¶EÉª©êévÆà¾µÜµ½B½NXªÞÅÍA±êªua°ÉæÁÄANXÌ¾¯{³êévÆ¢¤à¾ÉÈèÜ·BÂÜèA°ð{ÌJèÔµÆ©È¹ÎAâÁÄ¢é±ÆÍñlªÞÆ¯¶Æ¢¤í¯Å·B
@YªvZÅ«½çA ÆÍùz~º@ÈÇÌÅK»ASYðgÁÄAÅKÈp[^[ðßé¾¯Å·B±êÅAfÍ®¬Å·B
@Èãª\tg}bNXñAÌdgÝÅ·BWXeBbNñAðµÁ©èwñ¾©ç±»A\tg}bNXñAÌðÍæèÈP¾Á½ÌÅÍÈ¢Åµå¤©B
@ÅãÉAvO~OãÌá¢ÉÂ¢ÄàGêÄ¨«Üµå¤BÆ¢ÁÄàAÙÆñÇá¢Í èÜ¹ñB|CgÍÌ2Â¾¯Å·B
@SÌIÈR[hàeÍAWXeBbNñAÆÙÚ¯¶ÉÈé½ßASÌÌfÚÍÈªµAÙÈéª¾¯ðæèã°Ü·BR[hðÀsµÄÝ½¢ûÍATvm[gubNð²p¾³¢B
i1j3ÂÈãÌNXÖÌÎ
@±±ÅÍAf[^ZbgÉÜÜêéSÄÌNXðgpµÜ·BæÙÇÍuNX3vðOµÄ¢½ÌÅA ç½ßÄ^[QbgÆÈé³ðxðÈºÉ¦µÄ¨«Ü·B
@OfÌuXg2@Winef[^ZbgðÇÝÝR[hávÅÍAmaskÉæÁÄí´í´uNX3vðOµÄ¢Üµ½ªA±ÌªsvÅ·B±±ÅÍSÄÌNXðgp·é½ßAÈºÌæ¤ÉYÌR[hðRgAEgµÄ¾³¢B
# ièÞððµÄSÄÌNXðgp
# mask = (y == 0) | (y == 1)
# X = X[mask]
# y = y[mask]
@±ÌÏX¾¯ÅAfÌPûâ\ªÌR[hÍ»ÌÜÜg¦Ü·B
i2j¡NXÌ]¿XRAÉÎ
@ÅãÌ]¿pÌR[hàÙÚ»ÌÜÜg¦Ü·ªAÙñÌµ¾¯«Á¦éKvª èÜ·B
@Æ¢¤ÌàA½NXªÞÌ]¿wWÅ éK¦^Ä»¦^F1XRAÍANX²ÆÉ]¿liXRAjðvZ·é½ßA»êçð½ÏiaveragejµÄÅIIÈ]¿lðßéKvª é©çÅ·B
@±ÌìÆÍÈPÅAe]¿ÖÉaverage=&#39;macro&#39;Æ¢¤øðÇÁ·é¾¯Å·BXg7Ì¾ªðmFµÄ¾³¢B
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# \ªÊiy_predjÆ³ðxiy_testjðärµÄAe]¿wWðZo
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, average=&#39;macro&#39;)
rec = recall_score(y_test, y_pred, average=&#39;macro&#39;)
f1 = f1_score(y_test, y_pred, average=&#39;macro&#39;)
# ÊðoÍ
print(f&#39;³ð¦iAccuracyj: {acc:.2f}&#39;)
print(f&#39;K¦iPrecisionj: {prec:.2f}&#39;)
print(f&#39;Ä»¦iRecallj: {rec:.2f}&#39;)
print(f&#39;F1XRAiF1 Scorej: {f1:.2f}&#39;)
# ³ð¦iAccuracyj: 1.00
# K¦iPrecisionj: 1.00
# Ä»¦iRecallj: 1.00
# F1XRAiF1 Scorej: 1.00
@¿ÈÝÉ³ð¦iAccuracyjÍAàÆàÆSNXðÜÆßÄ]¿·éwWÈÌÅAaverage=&#39;macro&#39;ÌwèÍsvÅ·i»à»àwèÅ«Ü¹ñjB
@K¦^Ä»¦^F1XRAðvZ·éÖÌøaverageÉÍAôÂ©Ìwèlª èÜ·B»ê¼êÌÓ¡âg¢ª¯wjAbgÆfbgðÈºÉÈÉÜÆßÜ·B
@ÊíÍAXg7Ìæ¤Éaverage=&#39;macro&#39;ðwè·éÌª³ïÅ·B½¾µAf[^ZbgÉNXsÏtª éêÍA³ð¦â}CN½Ï¾¯ÅÍs\ªÈ±Æà èÜ·B}N½ÏâÁd½Ïà¹¹ÄmF·é±ÆÅAæèö½ÅÀÔÉ¦µ½]¿ªÂ\ÉÈèÜ·B
@¡ñÍAPythonÉæéWXeBbNñAiÆ\tg}bNXñAjÌTvÆdgÝAî{IÈvO~Oðà¾µÜµ½Bm¯ðè ³¹é½ßÉA]Tª êÎAöÌÀÍµàâÁÄÝÄ¾³¢B
@ñÍAªÞ^XNÌè@ÆµÄèØððàµÜ·B¨yµÝÉB
@IWFÌªðNbNÜ½Í^bv·éÆ¦ª\¦³êÜ·Bqgª~µ¢êÍAÎFÌªðNbNµÄ¾³¢BßâèÉg¦éIðª\¦³êÜ·B
@ñWXeBbNñAÍAüÍf[^ÆoÍÊÌÖWðuü`ÆWXeBbNÖvÉæÁÄf»µA0©1ÌñlªÞðs¤è@Å·Bscikit-learnÅÍALogisticRegressionNXðgÁÄÀÅ«Ü·B
@WXeBbNÖÍA¼üðS^ÌÈüÉÏ··é±ÆÅA0.0`1.0Ìm¦lðoÍµÜ·B±ÌlÉÎµÄ0.5ÈÇÌèliµ«¢¿jðÝèµAÇ¿çÌNXÉªÞ·é©ð»fµÜ·BOtãÅ±Ì«Eð¦·üÍAè«EÆÄÎêÜ·B
@fÌp[^[ÍAð·Ggs[Æ¢¤¹¸ÖðÅ¬»·éæ¤ÅÞèÉæÁÄßçêAùz~º@ÈÇÌÅK»ASYªgíêÜ·BªÞfÌ«\ð]¿·éÛÉÍA³ð¦AK¦AÄ»¦AF1XRAÆ¢Á½¡ÌwWªp¢çêÜ·B
@\tg}bNXñAÍA½NXªÞÉÎµ½½WXeBbNñAÌêíÅ èAWXeBbNÖÌãíèÉ\tg}bNXÖðgpµÜ·Bî{IÈdgÝÍAWXeBbNñAÆ¤ÊÅ·B
qgF @è«E@@¼ü@@½NX@@LogisticRegression@@K¦@@ñl@@ùz~º@@ü`@@ë·t`d@@ð·Ggs[@@Þx@@LogisticClassification@@ªÞü@@N@@z«¦@@À@@\tg}bNXÖ@@m¦@@VOChÖ@@S@
u@BwKüåv
SÒü¯Af[^ªÍEAIE@BwKEPythonÌ×û@@ITÌDeep InsiderÅwÚ¤
Copyright© Digital Advantage Corp. All Rights Reserved. </article> <!-- ✅ 戻るボタン --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
← 一覧へ戻る
</a> </div> </div> <!-- ✅ base を正しく埋め込む --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- ✅ 戻るリンクを正しく構築 --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("✅ base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("✅ backLink.href:", backLink.href);
      } else {
        console.warn("⚠️ backLink not found");
      }
    </script> </body> </html>