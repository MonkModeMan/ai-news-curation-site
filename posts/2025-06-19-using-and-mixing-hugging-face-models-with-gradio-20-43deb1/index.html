<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>Using &amp; Mixing Hugging Face Models with Gradio 2.0</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/_page_.Ba3Vwl3b.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- ‚úÖ „Çø„Ç§„Éà„É´ --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">üì∞ Using &amp; Mixing Hugging Face Models with Gradio 2.0</h1> <p class="text-sm text-gray-500"> 2021/5/25 ‚Äì Hugging Face Blog  <a href="https://huggingface.co/blog/gradio" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
ÂÖÉË®ò‰∫ã
</a>  </p> </header> <!-- ‚úÖ Êú¨Êñá --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> Using &amp; Mixing Hugging Face Models with Gradio 2.0
Cross-posted from the Gradio blog.
The Hugging Face Model Hub has more than 10,000 machine learning models submitted by users. You‚Äôll find all kinds of natural language processing models that, for example, translate between Finnish and English or recognize Chinese speech. More recently, the Hub has expanded to even include models for image classification and audio processing.
Hugging Face has always worked to make models accessible and easy to use. The transformers
library makes it possible to load a model in a few lines of code. After a model is loaded, it can be used to make predictions on new data programmatically. But it‚Äôs not just programmers that are using machine learning models! An increasingly common scenario in machine learning is demoing models to interdisciplinary teams or letting non-programmers use models (to help discover biases, failure points, etc.).
The Gradio library lets machine learning developers create demos and GUIs from machine learning models very easily, and share them for free with your collaborators as easily as sharing a Google docs link. Now, we‚Äôre excited to share that the Gradio 2.0 library lets you load and use almost any Hugging Face model with a GUI in just 1 line of code. Here‚Äôs an example:
By default, this uses HuggingFace‚Äôs hosted Inference API (you can supply your own API key or use the public access without an API key), or you can also run pip install transformers
and run the model computations locally if you‚Äôd like.
Do you want to customize the demo? You can override any of the default parameters of the Interface class by passing in your own parameters:
But wait, there‚Äôs more! With 10,000 models already on Model Hub, we see models not just as standalone pieces of code, but as lego pieces that can be composed and mixed to create more sophisticated applications and demos.
For example, Gradio lets you load multiple models in parallel (imagine you want to compare 4 different text generation models from Hugging Face to see which one is the best for your use case):
Or put your models in series. This makes it easy to build complex applications built from multiple machine learning models. For example, here we can build an application to translate and summarize Finnish news articles in 3 lines of code:
You can even mix multiple models in series compared to each other in parallel (we‚Äôll let you try that yourself!). To try any of this out, just install Gradio (pip install gradio
) and pick a Hugging Face model you want to try. Start building with Gradio and Hugging Face üß±‚õèÔ∏è </article> <!-- ‚úÖ Êàª„Çã„Éú„Çø„É≥ --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
‚Üê ‰∏ÄË¶ß„Å∏Êàª„Çã
</a> </div> </div> <!-- ‚úÖ base „ÇíÊ≠£„Åó„ÅèÂüã„ÇÅËæº„ÇÄ --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- ‚úÖ Êàª„Çã„É™„É≥„ÇØ„ÇíÊ≠£„Åó„ÅèÊßãÁØâ --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("‚úÖ base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("‚úÖ backLink.href:", backLink.href);
      } else {
        console.warn("‚ö†Ô∏è backLink not found");
      }
    </script> </body> </html>