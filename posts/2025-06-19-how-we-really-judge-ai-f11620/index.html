<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>How we really judge AI</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/_page_.BNX7D8gk.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- âœ… ã‚¿ã‚¤ãƒˆãƒ« --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">ğŸ“° How we really judge AI</h1> <p class="text-sm text-gray-500"> 2025/6/10 â€“ MIT  <a href="https://news.mit.edu/2025/how-we-really-judge-ai-0610" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
å…ƒè¨˜äº‹
</a>  </p> </header> <!-- âœ… æœ¬æ–‡ --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> Suppose you were shown that an artificial intelligence tool offers accurate predictions about some stocks you own. How would you feel about using it? Now, suppose you are applying for a job at a company where the HR department uses an AI system to screen resumes. Would you be comfortable with that?
A new study finds that people are neither entirely enthusiastic nor totally averse to AI. Rather than falling into camps of techno-optimists and Luddites, people are discerning about the practical upshot of using AI, case by case.
â€œWe propose that AI appreciation occurs when AI is perceived as being more capable than humans and personalization is perceived as being unnecessary in a given decision context,â€ says MIT Professor Jackson Lu, co-author of a newly published paper detailing the studyâ€™s results. â€œAI aversion occurs when either of these conditions is not met, and AI appreciation occurs only when both conditions are satisfied.â€
The paper, â€œAI Aversion or Appreciation? A Capabilityâ€“Personalization Framework and a Meta-Analytic Review,â€ appears in Psychological Bulletin. The paper has eight co-authors, including Lu, who is the Career Development Associate Professor of Work and Organization Studies at the MIT Sloan School of Management.
New framework adds insight
Peopleâ€™s reactions to AI have long been subject to extensive debate, often producing seemingly disparate findings. An influential 2015 paper on â€œalgorithm aversionâ€ found that people are less forgiving of AI-generated errors than of human errors, whereas a widely noted 2019 paper on â€œalgorithm appreciationâ€ found that people preferred advice from AI, compared to advice from humans.
To reconcile these mixed findings, Lu and his co-authors conducted a meta-analysis of 163 prior studies that compared peopleâ€™s preferences for AI versus humans. The researchers tested whether the data supported their proposed â€œCapabilityâ€“Personalization Frameworkâ€ â€” the idea that in a given context, both the perceived capability of AI and the perceived necessity for personalization shape our preferences for either AI or humans.
Across the 163 studies, the research team analyzed over 82,000 reactions to 93 distinct â€œdecision contextsâ€ â€” for instance, whether or not participants would feel comfortable with AI being used in cancer diagnoses. The analysis confirmed that the Capabilityâ€“Personalization Framework indeed helps account for peopleâ€™s preferences.
â€œThe meta-analysis supported our theoretical framework,â€ Lu says. â€œBoth dimensions are important: Individuals evaluate whether or not AI is more capable than people at a given task, and whether the task calls for personalization. People will prefer AI only if they think the AI is more capable than humans and the task is nonpersonal.â€
He adds: â€œThe key idea here is that high perceived capability alone does not guarantee AI appreciation. Personalization matters too.â€
For example, people tend to favor AI when it comes to detecting fraud or sorting large datasets â€” areas where AIâ€™s abilities exceed those of humans in speed and scale, and personalization is not required. But they are more resistant to AI in contexts like therapy, job interviews, or medical diagnoses, where they feel a human is better able to recognize their unique circumstances.
â€œPeople have a fundamental desire to see themselves as unique and distinct from other people,â€ Lu says. â€œAI is often viewed as impersonal and operating in a rote manner. Even if the AI is trained on a wealth of data, people feel AI canâ€™t grasp their personal situations. They want a human recruiter, a human doctor who can see them as distinct from other people.â€
Context also matters: From tangibility to unemployment
The study also uncovered other factors that influence individualsâ€™ preferences for AI. For instance, AI appreciation is more pronounced for tangible robots than for intangible algorithms.
Economic context also matters. In countries with lower unemployment, AI appreciation is more pronounced.
â€œIt makes intuitive sense,â€ Lu says. â€œIf you worry about being replaced by AI, youâ€™re less likely to embrace it.â€
Lu is continuing to examine peopleâ€™s complex and evolving attitudes toward AI. While he does not view the current meta-analysis as the last word on the matter, he hopes the Capabilityâ€“Personalization Framework offers a valuable lens for understanding how people evaluate AI across different contexts.
â€œWeâ€™re not claiming perceived capability and personalization are the only two dimensions that matter, but according to our meta-analysis, these two dimensions capture much of what shapes peopleâ€™s preferences for AI versus humans across a wide range of studies,â€ Lu concludes.
In addition to Lu, the paperâ€™s co-authors are Xin Qin, Chen Chen, Hansen Zhou, Xiaowei Dong, and Limei Cao of Sun Yat-sen University; Xiang Zhou of Shenzhen University; and Dongyuan Wu of Fudan University.
The research was supported, in part, by grants to Qin and Wu from the National Natural Science Foundation of China. </article> <!-- âœ… æˆ»ã‚‹ãƒœã‚¿ãƒ³ --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
â† ä¸€è¦§ã¸æˆ»ã‚‹
</a> </div> </div> <!-- âœ… base ã‚’æ­£ã—ãåŸ‹ã‚è¾¼ã‚€ --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- âœ… æˆ»ã‚‹ãƒªãƒ³ã‚¯ã‚’æ­£ã—ãæ§‹ç¯‰ --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("âœ… base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("âœ… backLink.href:", backLink.href);
      } else {
        console.warn("âš ï¸ backLink not found");
      }
    </script> </body> </html>