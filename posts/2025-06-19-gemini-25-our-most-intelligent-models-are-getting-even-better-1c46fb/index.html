<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>Gemini 2.5: Our most intelligent models are getting even better</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/_page_.Ba3Vwl3b.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- ‚úÖ „Çø„Ç§„Éà„É´ --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">üì∞ Gemini 2.5: Our most intelligent models are getting even better</h1> <p class="text-sm text-gray-500"> 2025/5/20 ‚Äì DeepMind Blog  <a href="https://deepmind.google/discover/blog/gemini-25-our-world-leading-model-is-getting-even-better/" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
ÂÖÉË®ò‰∫ã
</a>  </p> </header> <!-- ‚úÖ Êú¨Êñá --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> Gemini 2.5: Our most intelligent models are getting even better
In March, we announced Gemini 2.5 Pro, our most intelligent model yet, and two weeks ago, we brought you our I/O update early for developers to build incredible web apps. Today, we‚Äôre sharing even more updates to our Gemini 2.5 model series:
- Beyond 2.5 Pro‚Äôs incredible performance on academic benchmarks, it‚Äôs now the world-leading model across the WebDev Arena and LMArena leaderboards, and for helping people learn.
- We‚Äôre bringing new capabilities to 2.5 Pro and 2.5 Flash: native audio output for a more natural conversational experience, advanced security safeguards, and Project Mariner‚Äôs computer use capabilities. 2.5 Pro will get even better with Deep Think, an experimental, enhanced reasoning mode for highly-complex math and coding.
- We continue to invest in the developer experience, introducing thought summaries in the Gemini API and in Vertex AI for more transparency, extending thinking budgets to 2.5 Pro for more control, and adding support for MCP tools in the Gemini API and SDK for access to more open source tools.
- 2.5 Flash is now available to everyone in the Gemini app, and we&#39;ll make our updated version generally available in Google AI Studio for developers and in Vertex AI for enterprises in early June, with 2.5 Pro soon after.
This remarkable progress is the result of the relentless effort of teams across Google to improve our technologies, and develop and release them safely and responsibly. Let‚Äôs dive in.
2.5 Pro performs better than ever
We recently updated 2.5 Pro to help developers build richer, interactive web apps. It‚Äôs great to see the positive reaction from users and developers and we‚Äôre continuing to make improvements based on user feedback.
In addition to its strong performance on academic benchmarks, the new 2.5 Pro is now leading the popular coding leaderboard, WebDev Arena, with an ELO score of 1415. It‚Äôs also leading across all leaderboards of the LMArena, which evaluates human preference in various dimensions. And, with its 1 million-token context window, 2.5 Pro has state-of-the-art long context and video understanding performance.
Since incorporating LearnLM, our family of models built with educational experts, 2.5 Pro is also now the leading model for learning. In head-to-head comparisons evaluating its pedagogy and effectiveness, educators and experts preferred Gemini 2.5 Pro over other models across a diverse range of scenarios. And, it outperformed top models on every one of the five principles of learning science used to build AI systems for learning.
Read more in our updated Gemini 2.5 Pro model card and on the Gemini technology page.
Deep Think
Through exploring the frontiers of Gemini‚Äôs thinking capabilities, we‚Äôre starting to test an enhanced reasoning mode called Deep Think that uses new research techniques enabling the model to consider multiple hypotheses before responding.
2.5 Pro Deep Think gets an impressive score on 2025 USAMO, currently one of the hardest math benchmarks. It also leads on LiveCodeBench, a difficult benchmark for competition-level coding, and scores 84.0% on MMMU, which tests multimodal reasoning.
Because we&#39;re defining the frontier with 2.5 Pro DeepThink, we&#39;re taking extra time to conduct more frontier safety evaluations and get further input from safety experts. As part of that, we‚Äôre going to make it available to trusted testers via the Gemini API to get their feedback before making it widely available.
An even better 2.5 Flash
2.5 Flash is our most efficient workhorse model designed for speed and low-cost ‚Äî and it‚Äôs now better across many dimensions. It‚Äôs improved across key benchmarks for reasoning, multimodality, code and long context while getting even more efficient, using 20-30% less tokens in our evaluations.
The new 2.5 Flash is now available for preview in Google AI Studio for developers, in Vertex AI for enterprise and in the Gemini app for everyone. And in early June, it‚Äôll be generally available for production.
Read more in our updated Gemini 2.5 Flash model card and on the Gemini technology page.
New Gemini 2.5 capabilities
Native audio output and improvements to Live API
Today, the Live API is introducing a preview version of audio-visual input and native audio out dialogue, so you can directly build conversational experiences, with a more natural and expressive Gemini.
It also allows the user to steer its tone, accent and style of speaking. For example, you can tell the model to use a dramatic voice when telling a story. And it supports tool use, to be able to search on your behalf.
You can experiment with a set of early features, including:
- Affective Dialogue, in which the model detects emotion in the user&#39;s voice and responds appropriately.
- Proactive Audio, in which the model will ignore background conversations and know when to respond.
- Thinking in the Live API, in which the model leverages Gemini‚Äôs thinking capabilities to support more complex tasks.
We‚Äôre also releasing new previews for text-to-speech in 2.5 Pro and 2.5 Flash. These have first-of-its-kind support for multiple speakers, enabling text-to-speech with two voices via native audio out.
Like Native Audio dialogue, text-to-speech is expressive, and can capture really subtle nuances, such as whispers. It works in over 24 languages and seamlessly switches between them.
This text-to-speech capability will be available later today in the Gemini API.
Computer use
We&#39;re bringing Project Mariner&#39;s computer use capabilities into the Gemini API and Vertex AI. Companies like Automation Anywhere, UiPath, Browserbase, Autotab, The Interaction Company and Cartwheel are exploring its potential, and we&#39;re excited to roll it out more broadly for developers to experiment with this summer.
Better security
We‚Äôve also significantly increased protections against security threats, like indirect prompt injections. This is when malicious instructions are embedded into the data an AI model retrieves. Our new security approach helped significantly increase Gemini‚Äôs protection rate against indirect prompt injection attacks during tool use, making Gemini 2.5 our most secure model family to date.
Read more about our work across safety, responsibility and security, and how we‚Äôre advancing Gemini‚Äôs security safeguards on the Google DeepMind blog.
Enhanced developer experience
Thought summaries
2.5 Pro and Flash will now include thought summaries in the Gemini API and in Vertex AI. Thought summaries take the model‚Äôs raw thoughts and organize them into a clear format with headers, key details and information about model actions, like when they use tools.
We hope that with a more structured, streamlined format on the model‚Äôs thinking process, developers and users will find the interactions with Gemini models easier to understand and debug.
Thinking budgets
We launched 2.5 Flash with thinking budgets to give developers more control over cost by balancing latency and quality. And we‚Äôre extending this capability to 2.5 Pro. This allows you to control the number of tokens a model uses to think before it responds, or even turn its thinking capabilities off.
Gemini 2.5 Pro with budgets will be generally available for stable production use in the coming weeks, along with our generally available model.
MCP support
We added native SDK support for Model Context Protocol (MCP) definitions in the Gemini API for easier integration with open-source tools. We‚Äôre also exploring ways to deploy MCP servers and other hosted tools, making it easier for you to build agentic applications.
We‚Äôre always innovating on new approaches to improve our models and our developer experience, including making them more efficient and performant, and continuing to respond to developer feedback, so please keep it coming! We also continue to double down on the breadth and depth of our fundamental research ‚Äî pushing the frontiers of Gemini‚Äôs capabilities. More to come soon.
Learn more about Gemini and its capabilities on our website. </article> <!-- ‚úÖ Êàª„Çã„Éú„Çø„É≥ --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
‚Üê ‰∏ÄË¶ß„Å∏Êàª„Çã
</a> </div> </div> <!-- ‚úÖ base „ÇíÊ≠£„Åó„ÅèÂüã„ÇÅËæº„ÇÄ --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- ‚úÖ Êàª„Çã„É™„É≥„ÇØ„ÇíÊ≠£„Åó„ÅèÊßãÁØâ --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("‚úÖ base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("‚úÖ backLink.href:", backLink.href);
      } else {
        console.warn("‚ö†Ô∏è backLink not found");
      }
    </script> </body> </html>