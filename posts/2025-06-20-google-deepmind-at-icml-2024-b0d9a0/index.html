<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>Google DeepMind at ICML 2024</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/index.BoXAN-Xr.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- ‚úÖ „Çø„Ç§„Éà„É´ --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">üì∞ Google DeepMind at ICML 2024</h1> <p class="text-sm text-gray-500"> 2024/7/19 ‚Äì DeepMind Blog  <a href="https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
ÂÖÉË®ò‰∫ã
</a>  </p> </header> <!-- ‚úÖ Êú¨Êñá --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> Research
Google DeepMind at ICML 2024
Exploring AGI, the challenges of scaling and the future of multimodal generative AI
Next week the artificial intelligence (AI) community will come together for the 2024 International Conference on Machine Learning (ICML). Running from July 21-27 in Vienna, Austria, the conference is an international platform for showcasing the latest advances, exchanging ideas and shaping the future of AI research.
This year, teams from across Google DeepMind will present more than 80 research papers. At our booth, we‚Äôll also showcase our multimodal on-device model, Gemini Nano, our new family of AI models for education called LearnLM and we‚Äôll demo TacticAI, an AI assistant that can help with football tactics.
Here we introduce some of our oral, spotlight and poster presentations:
Defining the path to AGI
What is artificial general intelligence (AGI)? The phrase describes an AI system that‚Äôs at least as capable as a human at most tasks. As AI models continue to advance, defining what AGI could look like in practice will become increasingly important.
We‚Äôll present a framework for classifying the capabilities and behaviors of AGI models. Depending on their performance, generality and autonomy, our paper categorizes systems ranging from non-AI calculators to emerging AI models and other novel technologies.
We‚Äôll also show that open-endedness is critical to building generalized AI that goes beyond human capabilities. While many recent AI advances were driven by existing Internet-scale data, open-ended systems can generate new discoveries that extend human knowledge.
Scaling AI systems efficiently and responsibly
Developing larger, more capable AI models requires more efficient training methods, closer alignment with human preferences and better privacy safeguards.
We‚Äôll show how using classification instead of regression techniques makes it easier to scale deep reinforcement learning systems and achieve state-of-the-art performance across different domains. Additionally, we propose a novel approach that predicts the distribution of consequences of a reinforcement learning agent&#39;s actions, helping rapidly evaluate new scenarios.
Our researchers present an alignment-maintaining approach that reduces the need for human oversight, and a new approach to fine-tuning large language models (LLMs), based on game theory, better aligns a LLM‚Äôs output with human preferences.
We critique the approach of training models on public data and only fine-tuning with &quot;differentially private&quot; training, and argue this approach may not offer the privacy or utility that is often claimed it does.
New approaches in generative AI and multimodality
Generative AI technologies and multimodal capabilities are expanding the creative possibilities of digital media.
We‚Äôll present VideoPoet, which uses an LLM to generate state-of-the-art video and audio from multimodal inputs including images, text, audio and other video.
And share Genie (generative interactive environments), which can generate a range of playable environments for training AI agents, based on text prompts, images, photos, or sketches.
Finally, we introduce MagicLens, a novel image retrieval system that uses text instructions to retrieve images with richer relations beyond visual similarity.
Supporting the AI community
We‚Äôre proud to sponsor ICML and foster a diverse community in AI and machine learning by supporting initiatives led by Disability in AI, Queer in AI, LatinX in AI and Women in Machine Learning.
If you‚Äôre at the conference, visit the Google DeepMind and Google Research booths to meet our teams, see live demos and find out more about our research. </article> <!-- ‚úÖ Êàª„Çã„Éú„Çø„É≥ --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
‚Üê ‰∏ÄË¶ß„Å∏Êàª„Çã
</a> </div> </div> <!-- ‚úÖ base „ÇíÊ≠£„Åó„ÅèÂüã„ÇÅËæº„ÇÄ --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- ‚úÖ Êàª„Çã„É™„É≥„ÇØ„ÇíÊ≠£„Åó„ÅèÊßãÁØâ --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("‚úÖ base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("‚úÖ backLink.href:", backLink.href);
      } else {
        console.warn("‚ö†Ô∏è backLink not found");
      }
    </script> </body> </html>