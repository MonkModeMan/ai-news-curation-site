<!DOCTYPE html><html lang="ja"> <head><meta charset="UTF-8"><title>Sentence Transformers in the ü§ó Hub</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/ai-news-curation-site/_astro/index.BoXAN-Xr.css"></head> <body class="bg-gray-100 text-gray-800 font-sans px-4 py-6"> <div class="max-w-3xl mx-auto"> <!-- ‚úÖ „Çø„Ç§„Éà„É´ --> <header class="mb-6"> <h1 class="text-3xl font-extrabold text-sky-500 mb-2">üì∞ Sentence Transformers in the ü§ó Hub</h1> <p class="text-sm text-gray-500"> 2021/6/28 ‚Äì Hugging Face Blog  <a href="https://huggingface.co/blog/sentence-transformers-in-the-hub" target="_blank" rel="noopener noreferrer" class="text-sky-500 hover:text-gray-500 no-underline border-b border-transparent hover:border-gray-300 transition">
ÂÖÉË®ò‰∫ã
</a>  </p> </header> <!-- ‚úÖ Êú¨Êñá --> <article class="prose prose-sm sm:prose lg:prose-lg max-w-none bg-white rounded-lg shadow p-6"> Sentence Transformers in the Hugging Face Hub
Over the past few weeks, we&#39;ve built collaborations with many Open Source frameworks in the machine learning ecosystem. One that gets us particularly excited is Sentence Transformers.
Sentence Transformers is a framework for sentence, paragraph and image embeddings. This allows to derive semantically meaningful embeddings (1) which is useful for applications such as semantic search or multi-lingual zero shot classification. As part of Sentence Transformers v2 release, there are a lot of cool new features:
- Sharing your models in the Hub easily.
- Widgets and Inference API for sentence embeddings and sentence similarity.
- Better sentence-embeddings models available (benchmark and models in the Hub).
With over 90 pretrained Sentence Transformers models for more than 100 languages in the Hub, anyone can benefit from them and easily use them. Pre-trained models can be loaded and used directly with few lines of code:
from sentence_transformers import SentenceTransformer
sentences = [&quot;Hello World&quot;, &quot;Hallo Welt&quot;]
model = SentenceTransformer(&#39;sentence-transformers/paraphrase-MiniLM-L6-v2&#39;)
embeddings = model.encode(sentences)
print(embeddings)
But not only this. People will probably want to either demo their models or play with other models easily, so we&#39;re happy to announce the release of two new widgets in the Hub! The first one is the feature-extraction
widget which shows the sentence embedding.
sentence-transformers/distilbert-base-nli-max-tokens
But seeing a bunch of numbers might not be very useful to you (unless you&#39;re able to understand the embeddings from a quick look, which would be impressive!). We&#39;re also introducing a new widget for a common use case of Sentence Transformers: computing sentence similarity.
Of course, on top of the widgets, we also provide API endpoints in our Inference API that you can use to programmatically call your models!
import json
import requests
API_URL = &quot;https://api-inference.huggingface.co/models/sentence-transformers/paraphrase-MiniLM-L6-v2&quot;
headers = {&quot;Authorization&quot;: &quot;Bearer YOUR_TOKEN&quot;}
def query(payload):
response = requests.post(API_URL, headers=headers, json=payload)
return response.json()
data = query(
{
&quot;inputs&quot;: {
&quot;source_sentence&quot;: &quot;That is a happy person&quot;,
&quot;sentences&quot;: [
&quot;That is a happy dog&quot;,
&quot;That is a very happy person&quot;,
&quot;Today is a sunny day&quot;
]
}
}
)
Unleashing the Power of Sharing
So why is this powerful? In a matter of minutes, you can share your trained models with the whole community.
from sentence_transformers import SentenceTransformer
# Load or train a model
model.save_to_hub(&quot;my_new_model&quot;)
Now you will have a repository in the Hub which hosts your model. A model card was automatically created. It describes the architecture by listing the layers and shows how to use the model with both Sentence Transformers
and ü§ó Transformers
. You can also try out the widget and use the Inference API straight away!
If this was not exciting enough, your models will also be easily discoverable by filtering for all Sentence Transformers
models.
What&#39;s next?
Moving forward, we want to make this integration even more useful. In our roadmap, we expect training and evaluation data to be included in the automatically created model card, like is the case in transformers
from version v4.8
.
And what&#39;s next for you? We&#39;re very excited to see your contributions! If you already have a Sentence Transformer
repo in the Hub, you can now enable the widget and Inference API by changing the model card metadata.
---
tags:
- sentence-transformers
- sentence-similarity # Or feature-extraction!
---
If you don&#39;t have any model in the Hub and want to learn more about Sentence Transformers, head to www.SBERT.net!
Would you like to integrate your library to the Hub?
This integration is possible thanks to the huggingface_hub
library which has all our widgets and the API for all our supported libraries. If you would like to integrate your library to the Hub, we have a guide for you!
References
- Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. https://arxiv.org/abs/1908.10084 </article> <!-- ‚úÖ Êàª„Çã„Éú„Çø„É≥ --> <div class="mt-10 text-center"> <a id="backLink" href="#" class="inline-block px-4 py-2 border border-sky-600 text-sky-600 rounded hover:bg-gray-100 transition">
‚Üê ‰∏ÄË¶ß„Å∏Êàª„Çã
</a> </div> </div> <!-- ‚úÖ base „ÇíÊ≠£„Åó„ÅèÂüã„ÇÅËæº„ÇÄ --> <script id="baseScript" data-base="/ai-news-curation-site"></script> <!-- ‚úÖ Êàª„Çã„É™„É≥„ÇØ„ÇíÊ≠£„Åó„ÅèÊßãÁØâ --> <script>
      const base = document.getElementById('baseScript')?.dataset.base || '';
      console.log("‚úÖ base:", base);

      const params = new URL(window.location.href).searchParams;
      const fromPage = params.get("fromPage") || "1";
      const fromSort = params.get("fromSort") || "date";

      const backLink = document.getElementById("backLink");
      if (backLink) {
        backLink.href = `${base}/page/${fromSort}/${fromPage}`;
        console.log("‚úÖ backLink.href:", backLink.href);
      } else {
        console.warn("‚ö†Ô∏è backLink not found");
      }
    </script> </body> </html>